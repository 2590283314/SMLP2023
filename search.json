[
  {
    "objectID": "contrasts_kwdyz11.html",
    "href": "contrasts_kwdyz11.html",
    "title": "Contrast Coding of Visual Attention Effects",
    "section": "",
    "text": "Code\nusing Arrow\nusing Chain\nusing DataFrames\nusing MixedModels\nusing ProgressMeter\nusing StatsBase\nusing StatsModels\nusing StatsModels: ContrastsCoding\n\nProgressMeter.ijulia_behavior(:clear);"
  },
  {
    "objectID": "contrasts_kwdyz11.html#sec-caution",
    "href": "contrasts_kwdyz11.html#sec-caution",
    "title": "Contrast Coding of Visual Attention Effects",
    "section": "A word of caution",
    "text": "A word of caution\nFor a (quasi-)experimental set of data, there is (or should be) a clear a priori theoretical committment to specific hypotheses about differences between factor levels and how these differences enter in interactions with other factors. This specification should be used in the first LMM and reported, irrespective of the outcome. If alternative theories lead to alternative a priori contrast specifications, both analyses are justified. If the observed means render the specification completely irrelevant, the comparisons originally planned could still be reported in a Supplement).\nIn this script, we are working through a large number of different contrasts for the same data. The purpose is to introduce both the preprogrammed (“canned”) and the general options to specify hypotheses about main effects and interactions. Obviously, we do not endorse generating a plot of the means and specifying the contrasts accordingly. This is known as the Texas sharpshooter fallacy. The link leads to an illustration and brief historical account by Wagenmakers (2018).\nIrrespective of how results turn out, there is nothing wrong with specifying a set of post-hoc contrasts to gain a better understanding of what the data are trying to tell us. Of course, in an article or report about the study, the a priori and post-hoc nature of contrast specifications must be made clear. Some kind of alpha-level adjustment (e.g., Bonferroni) may be called for, too. And, of course, there are grey zones.\nThere is quite a bit of statistical literature on contrasts. Two “local” references are:\nBrehm, L., & Alday, P. M., (2022). Contrast coding choices in a decade of mixed models. Journal of Memory and Language, 125, 104334.\n\nURL\nOSF\n\nSchad, D. J., Vasishth, S., Hohenstein, S., & Kliegl, R. (2020). How to capitalize on a priori contrasts in linear (mixed) models: A tutorial. Journal of Memory and Language, 110, 104038.\n\nURL\nOSF\n\nFor further readings see “Further Readings” in Schad et al. (2020)."
  },
  {
    "objectID": "contrasts_kwdyz11.html#sec-data",
    "href": "contrasts_kwdyz11.html#sec-data",
    "title": "Contrast Coding of Visual Attention Effects",
    "section": "Example data",
    "text": "Example data\nWe take the KWDYZ dataset (Kliegl et al., 2010). This is an experiment looking at three effects of visual cueing under four different cue-target relations (CTRs). Two horizontal rectangles are displayed above and below a central fixation point or they displayed in vertical orientation to the left and right of the fixation point. Subjects react to the onset of a small visual target occuring at one of the four ends of the two rectangles. The target is cued validly on 70% of trials by a brief flash of the corner of the rectangle at which it appears; it is cued invalidly at the three other locations 10% of the trials each.\nWe specify three contrasts for the four-level factor CTR that are derived from spatial, object-based, and attractor-like features of attention. They map onto sequential differences between appropriately ordered factor levels.\nWe also have a dataset from a replication and extension of this study (Kliegl, Kuschela, & Laubrock, 2015). Both data sets are available in R-package RePsychLing"
  },
  {
    "objectID": "contrasts_kwdyz11.html#sec-preprocessing",
    "href": "contrasts_kwdyz11.html#sec-preprocessing",
    "title": "Contrast Coding of Visual Attention Effects",
    "section": "Preprocessing",
    "text": "Preprocessing\n\ndat1 = @chain \"./data/kwdyz11.arrow\" begin\n  Arrow.Table\n  DataFrame\n  select!(:subj =&gt; :Subj, :tar =&gt; :CTR, :rt)\nend\ncellmeans = combine(\n  groupby(dat1, [:CTR]),\n  :rt =&gt; mean,\n  :rt =&gt; std,\n  :rt =&gt; length,\n  :rt =&gt; (x -&gt; std(x) / sqrt(length(x))) =&gt; :rt_semean,\n)\n\n4×5 DataFrame\n\n\n\nRow\nCTR\nrt_mean\nrt_std\nrt_length\nrt_semean\n\n\n\nString\nFloat64\nFloat64\nInt64\nFloat64\n\n\n\n\n1\nval\n358.032\n83.4581\n20141\n0.588069\n\n\n2\nsod\n391.267\n92.662\n2863\n1.73177\n\n\n3\ndos\n405.146\n92.6893\n2843\n1.73837\n\n\n4\ndod\n402.3\n95.3914\n2863\n1.78278"
  },
  {
    "objectID": "contrasts_kwdyz11.html#sec-contrasts",
    "href": "contrasts_kwdyz11.html#sec-contrasts",
    "title": "Contrast Coding of Visual Attention Effects",
    "section": "Julia contrast options",
    "text": "Julia contrast options\nWe use the same formula for all analyses\n\nform = @formula rt ~ 1 + CTR + (1 + CTR | Subj)\n\nFormulaTerm\nResponse:\n  rt(unknown)\nPredictors:\n  1\n  CTR(unknown)\n  (CTR,Subj)-&gt;(1 + CTR) | Subj\n\n\nThis is the default order of factor levels.\n\nStatsModels.levels(dat1.CTR)\n\n4-element Vector{String}:\n \"val\"\n \"sod\"\n \"dos\"\n \"dod\"\n\n\nControlling the ordering of levels for contrasts:\n\nkwarg levels to order the levels\nThe first level is set as the baseline; with kwarg base a different level can be specified.\n\n\nSeqDiffCoding\nThe SeqDiffCoding contrast corresponds to MASS::contr.sdif() in R. The assignment of random factors such as Subj to Grouping() is necessary when the sample size is very large. We recommend to include it always, but in this tutorial we do so only in the first example.\n\nform = @formula rt ~ 1 + CTR + (1 + CTR | Subj)\nlevels = [\"val\", \"sod\", \"dos\", \"dod\"]\nm1 = let\n  contrasts = Dict(\n    :CTR =&gt; SeqDiffCoding(; levels),\n    :Subj =&gt; Grouping()\n  )\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n389.7336\n7.0900\n54.97\n&lt;1e-99\n55.1891\n\n\nCTR: sod\n33.7818\n3.2873\n10.28\n&lt;1e-24\n23.2478\n\n\nCTR: dos\n13.9851\n2.3060\n6.06\n&lt;1e-08\n10.7577\n\n\nCTR: dod\n-2.7469\n2.2138\n-1.24\n0.2147\n9.5041\n\n\nResidual\n69.8349\n\n\n\n\n\n\n\n\n\n\n\nHypothesisCoding\nHypothesisCoding is the most general option available. We can implement all “canned” contrasts ourselves. The next example reproduces the test statistcs from SeqDiffCoding - with a minor modification illustrating the flexibility of going beyond the default version.\n\nm1b = let\n  contrasts = Dict(\n    :CTR =&gt; HypothesisCoding(\n      [\n        -1  1 0  0\n         0 -1 1  0\n         0  0 1 -1\n      ];\n      levels,\n      labels=[\"spt\", \"obj\", \"grv\"],\n    ),\n  )\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n389.7336\n7.0958\n54.92\n&lt;1e-99\n55.2349\n\n\nCTR: spt\n33.7817\n3.2880\n10.27\n&lt;1e-24\n23.2536\n\n\nCTR: obj\n13.9852\n2.3063\n6.06\n&lt;1e-08\n10.7608\n\n\nCTR: grv\n2.7470\n2.2142\n1.24\n0.2147\n9.5095\n\n\nResidual\n69.8347\n\n\n\n\n\n\n\n\n\nThe difference to the preprogrammed SeqDiffCoding is that for the third contrast we changed the direction of the contrast such that the sign of the effect is positive when the result is in agreement with theoretical expectation, that is we subtract the fourth level from the third, not the third level from the fourth.\n\n\nDummyCoding\nThi contrast corresponds to contr.treatment() in R\n\nm2 = let\n  contrasts = Dict(:CTR =&gt; DummyCoding(; base=\"val\"))\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n358.0914\n6.1533\n58.20\n&lt;1e-99\n47.9047\n\n\nCTR: dod\n45.0200\n4.3641\n10.32\n&lt;1e-24\n32.2952\n\n\nCTR: dos\n47.7669\n3.5570\n13.43\n&lt;1e-40\n25.5401\n\n\nCTR: sod\n33.7817\n3.2876\n10.28\n&lt;1e-24\n23.2499\n\n\nResidual\n69.8348\n\n\n\n\n\n\n\n\n\nThe DummyCoding contrast has the disadvantage that the intercept returns the mean of the level specified as base, default is the first level, not the GM.\n\n\nYchycaeitCoding\nThe contrasts returned by DummyCoding may be exactly what we want. Can’t we have them, but also have the intercept estimate the GM, rather than the mean of the base level? Yes, we can! We call this “You can have your cake and it eat, too”-Coding (YchycaeitCoding). And we use HpothesisCoding to achieve this outcome.\n\nm2b = let\n  contrasts = Dict(\n    :CTR =&gt; HypothesisCoding(\n      [\n        -1 1 0 0\n        -1 0 1 0\n        -1 0 0 1\n      ];\n      levels,\n      labels=levels[2:end],\n    )\n  )\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n389.7336\n7.0894\n54.97\n&lt;1e-99\n55.1850\n\n\nCTR: sod\n33.7817\n3.2873\n10.28\n&lt;1e-24\n23.2475\n\n\nCTR: dos\n47.7669\n3.5574\n13.43\n&lt;1e-40\n25.5440\n\n\nCTR: dod\n45.0200\n4.3638\n10.32\n&lt;1e-24\n32.2928\n\n\nResidual\n69.8349\n\n\n\n\n\n\n\n\n\nWe can simply relevel the factor or move the column with -1s for a different base.\n\n\nEffectsCoding\nThis contrast corresponds almost to contr.sum() in R.\n\nm3 = let\n  contrasts = Dict(:CTR =&gt; EffectsCoding(; base=\"dod\"))\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n389.7336\n7.0910\n54.96\n&lt;1e-99\n55.1970\n\n\nCTR: dos\n16.1248\n1.4404\n11.20\n&lt;1e-28\n7.3310\n\n\nCTR: sod\n2.1396\n1.3337\n1.60\n0.1087\n6.0066\n\n\nCTR: val\n-31.6422\n2.6421\n-11.98\n&lt;1e-32\n19.9492\n\n\nResidual\n69.8349\n\n\n\n\n\n\n\n\n\nThe “almost” qualification refers to the fact that contr.sum() uses the last factor levels as defaul base level; EffectsCoding uses the first level.\n\n\nHelmertCoding\nHelmertCoding codes each level as the difference from the average of the lower levels. With the default order of CTR levels we get the following test statistics. These contrasts are othogonal.\n\nm4 = let\n  contrasts = Dict(:CTR =&gt; HelmertCoding())\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n389.7336\n7.0927\n54.95\n&lt;1e-99\n55.2103\n\n\nCTR: dos\n1.3735\n1.1077\n1.24\n0.2150\n4.7626\n\n\nCTR: sod\n-4.2039\n0.6847\n-6.14\n&lt;1e-09\n3.3539\n\n\nCTR: val\n-10.5474\n0.8810\n-11.97\n&lt;1e-32\n6.6523\n\n\nResidual\n69.8347\n\n\n\n\n\n\n\n\n\n+ HeC1: (2 - 1)/2           # (391 - 358)/2\n+ HeC2: (3 - (2+1)/2)/3     # (405 - (391 + 358)/2)/3\n+ HeC3: (4 - (3+2+1)/3)/4   # (402 - (405 + 391 + 358)/3)/4\n\n\nReverse HelmertCoding\nReverse HelmertCoding codes each level as the difference from the average of the higher levels. To estimate these effects we simply reverse the order of factor levels. Of course, the contrasts are also orthogonal.\n\nm4b = let\n  levels = reverse(StatsModels.levels(dat1.CTR))\n  contrasts = Dict(:CTR =&gt; HelmertCoding(; levels))\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n389.7336\n7.0927\n54.95\n&lt;1e-99\n55.2103\n\n\nCTR: dos\n1.3735\n1.1077\n1.24\n0.2150\n4.7626\n\n\nCTR: sod\n-4.2039\n0.6847\n-6.14\n&lt;1e-09\n3.3539\n\n\nCTR: val\n-10.5474\n0.8810\n-11.97\n&lt;1e-32\n6.6523\n\n\nResidual\n69.8347\n\n\n\n\n\n\n\n\n\n+ HeC1:(3 - 4)/2            # (405 - 402)/2\n+ HeC2:(2 - (3+4)/2)/3      # (391 - (405 + 402)/2)/3\n+ HeC3:(1 - (2+3+4)/3/4     # (356  -(391 + 405 + 402)/3)/4\n\n\nAnova Coding\nFactorial designs (i.e., lab experiments) are traditionally analyzed with analysis of variance. The test statistics of main effects and interactions are based on an orthogonal set of contrasts. We specify them with HypothesisCoding.\n\nA(2) x B(2)\nAn A(2) x B(2) design can be recast as an F(4) design with the levels (A1-B1, A1-B2, A2-B1, A2-B2). The following contrast specifiction returns estimates for the main effect of A, the main effect of B, and the interaction of A and B. In a figure With A on the x-axis and the levels of B shown as two lines, the interaction tests the null hypothesis that the two lines are parallel. A positive coefficient implies overadditivity (diverging lines toward the right) and a negative coefficient underadditivity (converging lines).\n\nm5 = let\n  contrasts = Dict(\n    :CTR =&gt; HypothesisCoding(\n      [\n        -1 -1 +1 +1          # A\n        -1 +1 -1 +1          # B\n        +1 -1 -1 +1          # A x B\n      ];\n      levels,\n      labels=[\"A\", \"B\", \"AxB\"],\n    ),\n  )\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n389.7336\n7.0914\n54.96\n&lt;1e-99\n55.2004\n\n\nCTR: A\n59.0052\n5.1826\n11.39\n&lt;1e-29\n36.2076\n\n\nCTR: B\n31.0348\n4.6748\n6.64\n&lt;1e-10\n31.7114\n\n\nCTR: AxB\n-36.5287\n3.0927\n-11.81\n&lt;1e-31\n16.0050\n\n\nResidual\n69.8348\n\n\n\n\n\n\n\n\n\nIt is also helpful to see the corresponding layout of the four means for the interaction of A and B (i.e., the third contrast)\n        B1     B2\n   A1   +1     -1\n   A2   -1     +1\nThus, interaction tests whether the difference between main diagonal and minor diagonal is different from zero.\n\n\nA(2) x B(2) x C(2)\nGoing beyond the four level factor; it is also helpful to see the corresponding layout of the eight means for the interaction of A and B and C.\n          C1              C2\n      B1     B2        B1     B2\n A1   +1     -1   A1   -1     +1\n A2   -1     +1   A2   +1     -1\n\n\nA(2) x B(2) x C(3)\nTO BE DONE\n\n\n\nNested coding\nNested contrasts are often specified as follow up as post-hoc tests for ANOVA interactions. They are orthogonal. We specify them with HypothesisCoding.\nAn A(2) x B(2) design can be recast as an F(4) design with the levels (A1-B1, A1-B2, A2-B1, A2-B2). The following contrast specifiction returns an estimate for the main effect of A and the effects of B nested in the two levels of A. In a figure With A on the x-axis and the levels of B shown as two lines, the second contrast tests whether A1-B1 is different from A1-B2 and the third contrast tests whether A2-B1 is different from A2-B2.\n\nm8 = let\n  contrasts = Dict(\n    :CTR =&gt; HypothesisCoding(\n      [\n        -1 -1 +1 +1\n        -1 +1  0  0\n         0  0 +1 -1\n      ];\n      levels,\n      labels=[\"do_so\", \"spt\", \"grv\"],\n    ),\n  )\n  fit(MixedModel, form, dat1; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n389.7336\n7.0899\n54.97\n&lt;1e-99\n55.1887\n\n\nCTR: do_so\n59.0053\n5.1799\n11.39\n&lt;1e-29\n36.1846\n\n\nCTR: spt\n33.7817\n3.2873\n10.28\n&lt;1e-24\n23.2475\n\n\nCTR: grv\n2.7470\n2.2146\n1.24\n0.2148\n9.5150\n\n\nResidual\n69.8349\n\n\n\n\n\n\n\n\n\nThe three contrasts for one main effect and two nested contrasts are orthogonal. There is no test of the interaction (parallelism)."
  },
  {
    "objectID": "contrasts_kwdyz11.html#other-orthogonal-contrasts",
    "href": "contrasts_kwdyz11.html#other-orthogonal-contrasts",
    "title": "Contrast Coding of Visual Attention Effects",
    "section": "Other orthogonal contrasts",
    "text": "Other orthogonal contrasts\nFor factors with more than four levels there are many options for specifying orthogonal contrasts as long as one proceeds in a top-down strictly hiearchical fashion.\nSuppose you have a factor with seven levels and let’s ignore shifting colummns. In this case, you have six options for the first contrast, that is 6 vs. 1, 5 vs.2 , 4 vs. 3, 3 vs. 4, 2 vs. 5, and 1 vs. 6 levels. Then, you specify orthogonal contrasts for partitions with more than 2 elements and so on. That is, you don’t specify a contrast that crosses an earlier partition line.\nIn the following example, after an initial 4 vs 3 partitioning of levels, we specify AnovaCoding for the left and HelmertCoding for the right partition.\n\ncontrasts = Dict(\n  :CTR =&gt; HypothesisCoding(\n    [\n      -1/4 -1/4 -1/4 -1/4 +1/3 +1/3 +1/3\n      -1/2 -1/2 +1/2 +1/2    0    0    0\n      -1/2 +1/2 -1/2 +1/2    0    0    0\n      +1/2 -1/2 -1/2 +1/2    0    0    0\n         0    0    0    0   -1   +1    0\n         0    0    0    0 -1/2 -1/2    1\n    ];\n    levels=[\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\"],\n    labels=[\"c567.1234\", \"B\", \"C\", \"BxC\", \"c6.5\", \"c6.56\"],\n  ),\n);\n\nThere are two rules that hold for all orthogonal contrasts:\n\nThe weights within rows sum to zero.\nFor all pairs of rows, the sum of the products of weights in the same columns sums to zero."
  },
  {
    "objectID": "contrasts_kwdyz11.html#appendix-summary-dave-kleinschmidt",
    "href": "contrasts_kwdyz11.html#appendix-summary-dave-kleinschmidt",
    "title": "Contrast Coding of Visual Attention Effects",
    "section": "Appendix: Summary (Dave Kleinschmidt)",
    "text": "Appendix: Summary (Dave Kleinschmidt)\nStatsModels\nStatsModels.jl provides a few commonly used contrast coding schemes, some less-commonly used schemes, and structs that allow you to manually specify your own, custom schemes.\n\nStandard contrasts\nThe most commonly used contrasts are DummyCoding and EffectsCoding (which are similar to contr.treatment() and contr.sum() in R, respectively).\n\n\n“Exotic” contrasts (rk: well …)\nWe also provide HelmertCoding and SeqDiffCoding (corresponding to base R’s contr.helmert() and MASS::contr.sdif()).\n\n\nManual contrasts\nContrastsCoding()\nThere are two ways to manually specify contrasts. First, you can specify them directly via ContrastsCoding. If you do, it’s good practice to specify the levels corresponding to the rows of the matrix, although they can be omitted in which case they’ll be inferred from the data.\nHypothesisCoding()\nA better way to specify manual contrasts is via HypothesisCoding, where each row of the matrix corresponds to the weights given to the cell means of the levels corresponding to each column (see Schad et al. (2020) for more information)."
  },
  {
    "objectID": "shrinkageplot.html",
    "href": "shrinkageplot.html",
    "title": "More on shrinkage plots",
    "section": "",
    "text": "I have stated that the likelihood criterion used to fit linear mixed-effects can be considered as balancing fidelity to the data (i.e. fits the observed data well) versus model complexity.\nThis is similar to some of the criterion used in Machine Learning (ML), except that the criterion for LMMs has a rigorous mathematical basis.\nIn the shrinkage plot we consider the values of the random-effects coefficients for the fitted values of the model versus those from a model in which there is no penalty for model complexity.\nIf there is strong subject-to-subject variation then the model fit will tend to values of the random effects similar to those without a penalty on complexity.\nIf the random effects term is not contributing much (i.e. it is “inert”) then the random effects will be shrunk considerably towards zero in some directions.\nCode\nusing CairoMakie\nusing DataFrames\nusing LinearAlgebra\nusing MixedModels\nusing MixedModelsMakie\nusing Random\nusing ProgressMeter\n\nProgressMeter.ijulia_behavior(:clear);\nLoad the kb07 data set (don’t tell Reinhold that I used these data).\nkb07 = MixedModels.dataset(:kb07)\n\nArrow.Table with 1789 rows, 7 columns, and schema:\n :subj      String\n :item      String\n :spkr      String\n :prec      String\n :load      String\n :rt_trunc  Int16\n :rt_raw    Int16\ncontrasts = Dict(\n  :subj =&gt; Grouping(),\n  :item =&gt; Grouping(),\n  :spkr =&gt; HelmertCoding(),\n  :prec =&gt; HelmertCoding(),\n  :load =&gt; HelmertCoding(),\n)\nm1 = let\n  form = @formula(\n    rt_trunc ~\n      1 +\n      spkr * prec * load +\n      (1 + spkr + prec + load | subj) +\n      (1 + spkr + prec + load | item)\n  )\n  fit(MixedModel, form, kb07; contrasts)\nend\n\nMinimizing 883   Time: 0:00:00 ( 1.02 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\nσ_item\n\n\n\n\n(Intercept)\n2181.6729\n77.2879\n28.23\n&lt;1e-99\n301.7871\n362.0938\n\n\nspkr: old\n67.7484\n18.2976\n3.70\n0.0002\n43.1536\n40.6843\n\n\nprec: maintain\n-333.9212\n47.1387\n-7.08\n&lt;1e-11\n62.0318\n246.8048\n\n\nload: yes\n78.7702\n19.5373\n4.03\n&lt;1e-04\n65.1901\n42.3299\n\n\nspkr: old & prec: maintain\n-21.9655\n15.8058\n-1.39\n0.1646\n\n\n\n\nspkr: old & load: yes\n18.3844\n15.8058\n1.16\n0.2448\n\n\n\n\nprec: maintain & load: yes\n4.5340\n15.8058\n0.29\n0.7742\n\n\n\n\nspkr: old & prec: maintain & load: yes\n23.6073\n15.8058\n1.49\n0.1353\n\n\n\n\nResidual\n668.4871\nVarCorr(m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\nsubj\n(Intercept)\n91075.4527\n301.7871\n\n\n\n\n\n\nspkr: old\n1862.2358\n43.1536\n+0.78\n\n\n\n\n\nprec: maintain\n3847.9447\n62.0318\n-0.59\n+0.03\n\n\n\n\nload: yes\n4249.7506\n65.1901\n+0.36\n+0.82\n+0.53\n\n\nitem\n(Intercept)\n131111.9379\n362.0938\n\n\n\n\n\n\nspkr: old\n1655.2134\n40.6843\n+0.44\n\n\n\n\n\nprec: maintain\n60912.6143\n246.8048\n-0.69\n+0.35\n\n\n\n\nload: yes\n1791.8243\n42.3299\n+0.32\n+0.16\n-0.14\n\n\nResidual\n\n446875.0375\n668.4871\nissingular(m1)\n\ntrue\nprint(m1)\n\nLinear mixed model fit by maximum likelihood\n rt_trunc ~ 1 + spkr + prec + load + spkr & prec + spkr & load + prec & load + spkr & prec & load + (1 + spkr + prec + load | subj) + (1 + spkr + prec + load | item)\n    logLik   -2 logLik      AIC         AICc        BIC     \n -14318.5614  28637.1228  28695.1228  28696.1120  28854.3157\n\nVariance components:\n             Column       Variance  Std.Dev.   Corr.\nsubj     (Intercept)      91075.4527 301.7871\n         spkr: old         1862.2358  43.1536 +0.78\n         prec: maintain    3847.9447  62.0318 -0.59 +0.03\n         load: yes         4249.7506  65.1901 +0.36 +0.82 +0.53\nitem     (Intercept)     131111.9379 362.0938\n         spkr: old         1655.2134  40.6843 +0.44\n         prec: maintain   60912.6143 246.8048 -0.69 +0.35\n         load: yes         1791.8243  42.3299 +0.32 +0.16 -0.14\nResidual                 446875.0375 668.4871\n Number of obs: 1789; levels of grouping factors: 56, 32\n\n  Fixed-effects parameters:\n───────────────────────────────────────────────────────────────────────────────\n                                             Coef.  Std. Error      z  Pr(&gt;|z|)\n───────────────────────────────────────────────────────────────────────────────\n(Intercept)                             2181.67        77.2879  28.23    &lt;1e-99\nspkr: old                                 67.7484      18.2976   3.70    0.0002\nprec: maintain                          -333.921       47.1387  -7.08    &lt;1e-11\nload: yes                                 78.7702      19.5373   4.03    &lt;1e-04\nspkr: old & prec: maintain               -21.9655      15.8058  -1.39    0.1646\nspkr: old & load: yes                     18.3844      15.8058   1.16    0.2448\nprec: maintain & load: yes                 4.53396     15.8058   0.29    0.7742\nspkr: old & prec: maintain & load: yes    23.6073      15.8058   1.49    0.1353\n───────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "shrinkageplot.html#expressing-the-covariance-of-random-effects",
    "href": "shrinkageplot.html#expressing-the-covariance-of-random-effects",
    "title": "More on shrinkage plots",
    "section": "Expressing the covariance of random effects",
    "text": "Expressing the covariance of random effects\nEarlier today we mentioned that the parameters being optimized are from a “matrix square root” of the covariance matrix for the random effects. There is one such lower triangular matrix for each grouping factor.\n\nl1 = first(m1.λ)   # Cholesky factor of relative covariance for subj\n\n4×4 LowerTriangular{Float64, Matrix{Float64}}:\n  0.451448    ⋅          ⋅          ⋅ \n  0.050253   0.04052     ⋅          ⋅ \n -0.0550429  0.0722936  0.0188335   ⋅ \n  0.035184   0.0839591  0.0349697  0.0\n\n\nNotice the zero on the diagonal. A triangular matrix with zeros on the diagonal is singular.\n\nl2 = last(m1.λ)    # this one is not singular\n\n4×4 LowerTriangular{Float64, Matrix{Float64}}:\n  0.541662    ⋅           ⋅          ⋅ \n  0.0268487  0.054618     ⋅          ⋅ \n -0.252947   0.267973    0.022725    ⋅ \n  0.0200293  0.00134156  0.0600041  0.00249229\n\n\nTo regenerate the covariance matrix we need to know that the covariance is not the square of l1, it is l1 * l1' (so that the result is symmetric) and multiplied by σ̂²\n\nΣ₁ = varest(m1) .* (l1 * l1')\n\n4×4 Matrix{Float64}:\n  91075.5   10138.1     -11104.4     7098.06\n  10138.1    1862.24        72.9585  2310.4\n -11104.4      72.9585    3847.94    2141.28\n   7098.06   2310.4       2141.28    4249.75\n\n\n\ndiag(Σ₁)  # compare to the variance column in the VarCorr output\n\n4-element Vector{Float64}:\n 91075.4526880853\n  1862.2357643775592\n  3847.944710938748\n  4249.75056147619\n\n\n\nsqrt.(diag(Σ₁))\n\n4-element Vector{Float64}:\n 301.7870982797066\n  43.15362979376775\n  62.03180402776263\n  65.19011091780862"
  },
  {
    "objectID": "shrinkageplot.html#shrinkage-plots",
    "href": "shrinkageplot.html#shrinkage-plots",
    "title": "More on shrinkage plots",
    "section": "Shrinkage plots",
    "text": "Shrinkage plots\n\n\nCode\nshrinkageplot(m1)\n\n\n\n\n\nFigure 1: Shrinkage plot of model m1\n\n\n\n\nThe upper left panel shows the perfect negative correlation for those two components of the random effects.\n\nshrinkageplot(m1, :item)\n\n\n\n\n\nX1 = Int.(m1.X')\n\n8×1789 Matrix{Int64}:\n  1   1   1   1   1  1   1   1   1   1  …   1   1   1   1   1   1   1  1   1\n -1   1   1  -1  -1  1   1  -1  -1   1      1  -1  -1   1   1  -1  -1  1   1\n -1   1  -1   1  -1  1  -1   1  -1   1     -1   1  -1   1  -1   1  -1  1  -1\n  1  -1  -1  -1  -1  1   1   1   1  -1      1   1   1  -1  -1  -1  -1  1   1\n  1   1  -1  -1   1  1  -1  -1   1   1     -1  -1   1   1  -1  -1   1  1  -1\n -1  -1  -1   1   1  1   1  -1  -1  -1  …   1  -1  -1  -1  -1   1   1  1   1\n -1  -1   1  -1   1  1  -1   1  -1  -1     -1   1  -1  -1   1  -1   1  1  -1\n  1  -1   1   1  -1  1  -1  -1   1  -1     -1  -1   1  -1   1   1  -1  1  -1\n\n\n\nX1 * X1'\n\n8×8 Matrix{Int64}:\n 1789    -1    -1     3    -3     1     1     3\n   -1  1789    -3     1    -1     3     3     1\n   -1    -3  1789     1    -1     3     3     1\n    3     1     1  1789     3    -1    -1    -3\n   -3    -1    -1     3  1789     1     1     3\n    1     3     3    -1     1  1789    -3    -1\n    1     3     3    -1     1    -3  1789    -1\n    3     1     1    -3     3    -1    -1  1789"
  },
  {
    "objectID": "shrinkageplot.html#how-to-interpret-a-shrinkage-plot",
    "href": "shrinkageplot.html#how-to-interpret-a-shrinkage-plot",
    "title": "More on shrinkage plots",
    "section": "How to interpret a shrinkage plot",
    "text": "How to interpret a shrinkage plot\n\nExtreme shrinkage (shrunk to a line or to a point) is easy to interpret - the term is not providing benefit and can be removed.\nWhen the range of the blue dots (shrunk values) is comparable to those of the red dots (unshrunk) it indicates that the term after shrinkage is about as strong as without shrinkage.\nBy itself, this doesn’t mean that the term is important. In some ways you need to get a feeling for the absolute magnitude of the random effects in addition to the relative magnitude.\nSmall magnitude and small relative magnitude indicate you can drop that term"
  },
  {
    "objectID": "shrinkageplot.html#conclusions-from-these-plots",
    "href": "shrinkageplot.html#conclusions-from-these-plots",
    "title": "More on shrinkage plots",
    "section": "Conclusions from these plots",
    "text": "Conclusions from these plots\n\nOnly the intercept for the subj appears to be contributing explanatory power\nFor the item both the intercept and the spkr appear to be contributing\n\n\nm2 = let\n  form = @formula(\n    rt_trunc ~\n      1 + prec * spkr * load + (1 | subj) + (1 + prec | item)\n  )\n  fit(MixedModel, form, kb07; contrasts)\nend\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_item\nσ_subj\n\n\n\n\n(Intercept)\n2181.7582\n77.4709\n28.16\n&lt;1e-99\n364.7286\n298.1109\n\n\nprec: maintain\n-333.8582\n47.4629\n-7.03\n&lt;1e-11\n252.6687\n\n\n\nspkr: old\n67.8114\n16.0526\n4.22\n&lt;1e-04\n\n\n\n\nload: yes\n78.6849\n16.0525\n4.90\n&lt;1e-06\n\n\n\n\nprec: maintain & spkr: old\n-21.8802\n16.0525\n-1.36\n0.1729\n\n\n\n\nprec: maintain & load: yes\n4.4710\n16.0526\n0.28\n0.7806\n\n\n\n\nspkr: old & load: yes\n18.3214\n16.0526\n1.14\n0.2537\n\n\n\n\nprec: maintain & spkr: old & load: yes\n23.5219\n16.0525\n1.47\n0.1428\n\n\n\n\nResidual\n678.9318\n\n\n\n\n\n\n\n\n\n\n\nVarCorr(m2)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\nitem\n(Intercept)\n133026.917\n364.729\n\n\n\n\nprec: maintain\n63841.496\n252.669\n-0.70\n\n\nsubj\n(Intercept)\n88870.081\n298.111\n\n\n\nResidual\n\n460948.432\n678.932\n\n\n\n\n\n\n\n\nCode\nshrinkageplot(m2)\n\n\n\n\n\nFigure 2: Shrinkage plot of model m2\n\n\n\n\n\nm3 = let\n  form = @formula(\n    rt_trunc ~\n      1 + prec + spkr + load + (1 | subj) + (1 + prec | item)\n  )\n  fit(MixedModel, form, kb07; contrasts)\nend\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_item\nσ_subj\n\n\n\n\n(Intercept)\n2181.8526\n77.4681\n28.16\n&lt;1e-99\n364.7125\n298.0259\n\n\nprec: maintain\n-333.7906\n47.4472\n-7.03\n&lt;1e-11\n252.5212\n\n\n\nspkr: old\n67.8790\n16.0785\n4.22\n&lt;1e-04\n\n\n\n\nload: yes\n78.5904\n16.0785\n4.89\n&lt;1e-05\n\n\n\n\nResidual\n680.0319\n\n\n\n\n\n\n\n\n\n\n\nVarCorr(m3)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\nitem\n(Intercept)\n133015.243\n364.713\n\n\n\n\nprec: maintain\n63766.936\n252.521\n-0.70\n\n\nsubj\n(Intercept)\n88819.436\n298.026\n\n\n\nResidual\n\n462443.388\n680.032\n\n\n\n\n\n\n\nrng = Random.seed!(1234321);\n\n\nm3btstrp = parametricbootstrap(rng, 2000, m3);\n\n\nDataFrame(shortestcovint(m3btstrp))\n\n9×5 DataFrame\n\n\n\nRow\ntype\ngroup\nnames\nlower\nupper\n\n\n\nString\nString?\nString?\nFloat64\nFloat64\n\n\n\n\n1\nβ\nmissing\n(Intercept)\n2013.95\n2319.53\n\n\n2\nβ\nmissing\nprec: maintain\n-429.807\n-241.429\n\n\n3\nβ\nmissing\nspkr: old\n35.3339\n95.7272\n\n\n4\nβ\nmissing\nload: yes\n47.067\n111.04\n\n\n5\nσ\nitem\n(Intercept)\n267.788\n452.9\n\n\n6\nσ\nitem\nprec: maintain\n171.547\n314.702\n\n\n7\nρ\nitem\n(Intercept), prec: maintain\n-0.89308\n-0.457084\n\n\n8\nσ\nsubj\n(Intercept)\n235.921\n364.717\n\n\n9\nσ\nresidual\nmissing\n657.736\n703.06\n\n\n\n\n\n\n\nridgeplot(m3btstrp)\n\n\n\n\nFigure 3: Ridge plot of the fixed-effects coefficients from the bootstrap sample\n\n\n\n\n\n\nridgeplot(m3btstrp; show_intercept=false)\nFigure 4: ?(caption)\n\n\n\nm4 = let\n  form = @formula(\n    rt_trunc ~\n      1 + prec + spkr + load + (1 + prec | item) + (1 | subj)\n  )\n  fit(MixedModel, form, kb07; contrasts)\nend\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_item\nσ_subj\n\n\n\n\n(Intercept)\n2181.8526\n77.4681\n28.16\n&lt;1e-99\n364.7125\n298.0259\n\n\nprec: maintain\n-333.7906\n47.4472\n-7.03\n&lt;1e-11\n252.5212\n\n\n\nspkr: old\n67.8790\n16.0785\n4.22\n&lt;1e-04\n\n\n\n\nload: yes\n78.5904\n16.0785\n4.89\n&lt;1e-05\n\n\n\n\nResidual\n680.0319\n\n\n\n\n\n\n\n\n\n\n\nm4bstrp = parametricbootstrap(rng, 2000, m4);\n\n\nridgeplot(m4bstrp; show_intercept=false)\n\n\n\n\n\nDataFrame(shortestcovint(m4bstrp))\n\n9×5 DataFrame\n\n\n\nRow\ntype\ngroup\nnames\nlower\nupper\n\n\n\nString\nString?\nString?\nFloat64\nFloat64\n\n\n\n\n1\nβ\nmissing\n(Intercept)\n2008.72\n2319.8\n\n\n2\nβ\nmissing\nprec: maintain\n-433.808\n-248.858\n\n\n3\nβ\nmissing\nspkr: old\n35.4729\n97.9576\n\n\n4\nβ\nmissing\nload: yes\n47.0078\n108.437\n\n\n5\nσ\nitem\n(Intercept)\n261.52\n444.426\n\n\n6\nσ\nitem\nprec: maintain\n177.437\n318.846\n\n\n7\nρ\nitem\n(Intercept), prec: maintain\n-0.898522\n-0.477346\n\n\n8\nσ\nsubj\n(Intercept)\n229.031\n356.407\n\n\n9\nσ\nresidual\nmissing\n656.917\n701.946\n\n\n\n\n\n\n\nVarCorr(m4)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\nitem\n(Intercept)\n133015.243\n364.713\n\n\n\n\nprec: maintain\n63766.936\n252.521\n-0.70\n\n\nsubj\n(Intercept)\n88819.436\n298.026\n\n\n\nResidual\n\n462443.388\n680.032\n\n\n\n\n\n\n\n\nCode\nlet mods = [m1, m2, m4]\n  DataFrame(;\n    geomdof=(sum ∘ leverage).(mods),\n    npar=dof.(mods),\n    deviance=deviance.(mods),\n    AIC=aic.(mods),\n    BIC=bic.(mods),\n    AICc=aicc.(mods),\n  )\nend\n\n\n3×6 DataFrame\n\n\n\nRow\ngeomdof\nnpar\ndeviance\nAIC\nBIC\nAICc\n\n\n\nFloat64\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n131.655\n29\n28637.1\n28695.1\n28854.3\n28696.1\n\n\n2\n107.543\n13\n28658.5\n28684.5\n28755.8\n28684.7\n\n\n3\n103.478\n9\n28663.9\n28681.9\n28731.3\n28682.0\n\n\n\n\n\n\n\nscatter(fitted(m4), residuals(m4))\n\n\n\n\nFigure 5: Residuals versus fitted values for model m4"
  },
  {
    "objectID": "kwdyz11.html",
    "href": "kwdyz11.html",
    "title": "RePsychLing Kliegl et al. (2010)",
    "section": "",
    "text": "We take the kwdyz11.arrow dataset (Kliegl et al., 2010) from an experiment looking at three effects of visual cueing under four different cue-target relations (CTRs). Two horizontal rectangles are displayed above and below a central fixation point or they displayed in vertical orientation to the left and right of the fixation point. Subjects react to the onset of a small visual target occuring at one of the four ends of the two rectangles. The target is cued validly on 70% of trials by a brief flash of the corner of the rectangle at which it appears; it is cued invalidly at the three other locations 10% of the trials each.\nWe specify three contrasts for the four-level factor CTR that are derived from spatial, object-based, and attractor-like features of attention. They map onto sequential differences between appropriately ordered factor levels. At the level of fixed effects, there is the noteworthy result, that the attraction effect was estimated at 2 ms, that is clearly not significant. Nevertheless, there was a highly reliable variance component (VC) estimated for this effect. Moreover, the reliable individual differences in the attraction effect were negatively correlated with those in the spatial effect.\nUnfortunately, a few years after the publication, we determined that the reported LMM is actually singular and that the singularity is linked to a theoretically critical correlation parameter (CP) between the spatial effect and the attraction effect. Fortunately, there is also a larger dataset kkl15.arrow from a replication and extension of this study (Kliegl et al., 2015), analyzed with kkl15.jl notebook. The critical CP (along with other fixed effects and CPs) was replicated in this study.\nA more comprehensive analysis was reported in the parsimonious mixed-model paper (Bates et al., 2015). Data and R scripts are also available in R-package RePsychLing. In this and the complementary kkl15.jl scripts, we provide some corresponding analyses with MixedModels.jl."
  },
  {
    "objectID": "kwdyz11.html#background",
    "href": "kwdyz11.html#background",
    "title": "RePsychLing Kliegl et al. (2010)",
    "section": "",
    "text": "We take the kwdyz11.arrow dataset (Kliegl et al., 2010) from an experiment looking at three effects of visual cueing under four different cue-target relations (CTRs). Two horizontal rectangles are displayed above and below a central fixation point or they displayed in vertical orientation to the left and right of the fixation point. Subjects react to the onset of a small visual target occuring at one of the four ends of the two rectangles. The target is cued validly on 70% of trials by a brief flash of the corner of the rectangle at which it appears; it is cued invalidly at the three other locations 10% of the trials each.\nWe specify three contrasts for the four-level factor CTR that are derived from spatial, object-based, and attractor-like features of attention. They map onto sequential differences between appropriately ordered factor levels. At the level of fixed effects, there is the noteworthy result, that the attraction effect was estimated at 2 ms, that is clearly not significant. Nevertheless, there was a highly reliable variance component (VC) estimated for this effect. Moreover, the reliable individual differences in the attraction effect were negatively correlated with those in the spatial effect.\nUnfortunately, a few years after the publication, we determined that the reported LMM is actually singular and that the singularity is linked to a theoretically critical correlation parameter (CP) between the spatial effect and the attraction effect. Fortunately, there is also a larger dataset kkl15.arrow from a replication and extension of this study (Kliegl et al., 2015), analyzed with kkl15.jl notebook. The critical CP (along with other fixed effects and CPs) was replicated in this study.\nA more comprehensive analysis was reported in the parsimonious mixed-model paper (Bates et al., 2015). Data and R scripts are also available in R-package RePsychLing. In this and the complementary kkl15.jl scripts, we provide some corresponding analyses with MixedModels.jl."
  },
  {
    "objectID": "kwdyz11.html#packages",
    "href": "kwdyz11.html#packages",
    "title": "RePsychLing Kliegl et al. (2010)",
    "section": "Packages",
    "text": "Packages\n\n\nCode\nusing Arrow\nusing AlgebraOfGraphics\nusing CairoMakie\nusing CategoricalArrays\nusing Chain\nusing DataFrames\nusing DataFrameMacros\nusing MixedModels\nusing MixedModelsMakie\nusing ProgressMeter\nusing Random\nusing StatsBase\nusing Statistics\nusing AlgebraOfGraphics: density\nusing AlgebraOfGraphics: boxplot\n\nCairoMakie.activate!(; type=\"svg\")\nProgressMeter.ijulia_behavior(:clear);"
  },
  {
    "objectID": "kwdyz11.html#read-data-compute-and-plot-densities-and-means",
    "href": "kwdyz11.html#read-data-compute-and-plot-densities-and-means",
    "title": "RePsychLing Kliegl et al. (2010)",
    "section": "Read data, compute and plot densities and means",
    "text": "Read data, compute and plot densities and means\n\n\nCode\ndat = @chain \"./data/kwdyz11.arrow\" begin\n  Arrow.Table\n  DataFrame\n  select(\n    :subj =&gt;\n      (s -&gt; categorical(string.('S', lpad.(s, 2, '0')))) =&gt; :Subj,\n    :tar =&gt; categorical =&gt; :CTR,\n    :rt,\n    :rt =&gt; (x -&gt; log.(x)) =&gt; :lrt,\n  )\nend\nlevels!(dat.CTR, [\"val\", \"sod\", \"dos\", \"dod\"])\ndescribe(dat)\n\n\n4×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nSubj\n\nS01\n\nS61\n0\nCategoricalValue{String, UInt32}\n\n\n2\nCTR\n\nval\n\ndod\n0\nCategoricalValue{String, UInt32}\n\n\n3\nrt\n370.426\n150.1\n358.6\n705.7\n0\nFloat64\n\n\n4\nlrt\n5.886\n5.0113\n5.88221\n6.55919\n0\nFloat64\n\n\n\n\n\n\nWe recommend to code the levels/units of random factor / grouping variable not as a number, but as a string starting with a letter and of the same length for all levels/units.\nWe also recommend to sort levels of factors into a meaningful order, that is overwrite the default alphabetic ordering. This is also a good place to choose alternative names for variables in the context of the present analysis.\nThe LMM analysis is based on log-transformed reaction times lrt, indicated by a boxcox() check of model residuals. With the exception of diagnostic plots of model residuals, the analysis of untransformed reaction times did not lead to different results and exhibited the same problems of model identification (see Kliegl et al., 2010).\nComparative density plots of all response times by cue-target relation, Figure 1, show the times for valid cues to be faster than for the other conditions.\n\n\nCode\ndraw(\n  data(dat) *\n  mapping(\n    :lrt =&gt; \"log(Reaction time [ms])\";\n    color=:CTR =&gt;\n      renamer(\"val\" =&gt; \"valid cue\", \"sod\" =&gt; \"some obj/diff pos\", \"dos\" =&gt; \"diff obj/same pos\", \"dod\" =&gt; \"diff obj/diff pos\") =&gt; \"Cue-target relation\",\n  ) *\n  density(),\n)\n\n\n\n\n\nFigure 1: Comparative density plots of log reaction time for different cue-target relations.\n\n\n\n\nAn alternative visualization without overlap of the conditions can be accomplished with ridge plots.\nTo be done\nFor the next set of plots we average subjects’ data within the four experimental conditions. This table could be used as input for a repeated-measures ANOVA.\n\ndat_subj = combine(\n  groupby(dat, [:Subj, :CTR]),\n  :rt =&gt; length =&gt; :n,\n  :rt =&gt; mean =&gt; :rt_m,\n  :lrt =&gt; mean =&gt; :lrt_m,\n)\n\n244×5 DataFrame219 rows omitted\n\n\n\nRow\nSubj\nCTR\nn\nrt_m\nlrt_m\n\n\n\nCat…\nCat…\nInt64\nFloat64\nFloat64\n\n\n\n\n1\nS01\nval\n330\n413.332\n6.01272\n\n\n2\nS01\nsod\n48\n437.721\n6.0682\n\n\n3\nS01\ndos\n47\n443.366\n6.08269\n\n\n4\nS01\ndod\n45\n434.316\n6.06079\n\n\n5\nS02\nval\n333\n365.899\n5.8751\n\n\n6\nS02\nsod\n47\n396.149\n5.95916\n\n\n7\nS02\ndos\n46\n439.487\n6.06949\n\n\n8\nS02\ndod\n48\n441.042\n6.06883\n\n\n9\nS03\nval\n336\n371.446\n5.90489\n\n\n10\nS03\nsod\n46\n446.854\n6.09464\n\n\n11\nS03\ndos\n48\n471.302\n6.14287\n\n\n12\nS03\ndod\n47\n476.532\n6.15706\n\n\n13\nS04\nval\n336\n403.181\n5.99124\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n233\nS59\nval\n330\n313.032\n5.72433\n\n\n234\nS59\nsod\n46\n304.852\n5.70367\n\n\n235\nS59\ndos\n48\n342.612\n5.80927\n\n\n236\nS59\ndod\n47\n308.191\n5.71206\n\n\n237\nS60\nval\n330\n372.835\n5.90832\n\n\n238\nS60\nsod\n48\n382.088\n5.93183\n\n\n239\nS60\ndos\n44\n395.109\n5.96919\n\n\n240\nS60\ndod\n47\n387.689\n5.95208\n\n\n241\nS61\nval\n320\n312.374\n5.72542\n\n\n242\nS61\nsod\n45\n383.002\n5.92798\n\n\n243\nS61\ndos\n45\n357.998\n5.85563\n\n\n244\nS61\ndod\n46\n391.087\n5.95344\n\n\n\n\n\n\n\n\nCode\nboxplot(\n  dat_subj.CTR.refs,\n  dat_subj.lrt_m;\n  orientation=:horizontal,\n  show_notch=true,\n  axis=(;\n    yticks=(\n      1:4,\n      [\n        \"valid cue\",\n        \"same obj/diff pos\",\n        \"diff obj/same pos\",\n        \"diff obj/diff pos\",\n      ],\n    ),\n  ),\n  figure=(; resolution=(800, 300)),\n)\n\n\n\n\n\nFigure 2: Comparative boxplots of log response time by cue-target relation.\n\n\n\n\nMean of log reaction times for four cue-target relations. Targets appeared at (a) the cued position (valid) in a rectangle, (b) in the same rectangle cue, but at its other end, (c) on the second rectangle, but at a corresponding horizontal/vertical physical distance, or (d) at the other end of the second rectangle, that is \\(\\sqrt{2}\\) of horizontal/vertical distance diagonally across from the cue, that is also at larger physical distance compared to (c).\nA better alternative to the boxplot is a dotplot. It also displays subjects’ condition means.\nTo be done"
  },
  {
    "objectID": "kwdyz11.html#linear-mixed-model",
    "href": "kwdyz11.html#linear-mixed-model",
    "title": "RePsychLing Kliegl et al. (2010)",
    "section": "Linear mixed model",
    "text": "Linear mixed model\n\ncontrasts = Dict(\n  :CTR =&gt; SeqDiffCoding(; levels=[\"val\", \"sod\", \"dos\", \"dod\"]),\n  :Subj =&gt; Grouping(),\n)\nm1 = let\n  form = @formula(lrt ~ 1 + CTR + (1 + CTR | Subj))\n  fit(MixedModel, form, dat; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n5.9358\n0.0185\n320.53\n&lt;1e-99\n0.1441\n\n\nCTR: sod\n0.0878\n0.0084\n10.48\n&lt;1e-24\n0.0582\n\n\nCTR: dos\n0.0366\n0.0062\n5.92\n&lt;1e-08\n0.0274\n\n\nCTR: dod\n-0.0086\n0.0060\n-1.43\n0.1515\n0.0249\n\n\nResidual\n0.1920\n\n\n\n\n\n\n\n\n\n\nVarCorr(m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\nSubj\n(Intercept)\n0.0207652\n0.1441015\n\n\n\n\n\n\nCTR: sod\n0.0033852\n0.0581828\n+0.48\n\n\n\n\n\nCTR: dos\n0.0007532\n0.0274453\n-0.24\n-0.15\n\n\n\n\nCTR: dod\n0.0006223\n0.0249461\n+0.30\n+0.93\n-0.43\n\n\nResidual\n\n0.0368543\n0.1919748\n\n\n\n\n\n\n\n\n\nissingular(m1)\n\ntrue\n\n\nLMM m1 is not fully supported by the data; it is overparameterized. This is also visible in the PCA: only three, not four PCS are needed to account for all the variance and covariance in the random-effect structure. The problem is the +.93 CP for spatial sod and attraction dod effects.\n\nfirst(MixedModels.PCA(m1))\n\n\nPrincipal components based on correlation matrix\n (Intercept)   1.0     .      .      .\n CTR: sod      0.48   1.0     .      .\n CTR: dos     -0.24  -0.15   1.0     .\n CTR: dod      0.3    0.93  -0.43   1.0\n\nNormalized cumulative variances:\n[0.5887, 0.8096, 1.0, 1.0]\n\nComponent loadings\n                PC1   PC2    PC3    PC4\n (Intercept)  -0.4   0.04   0.9    0.17\n CTR: sod     -0.6   0.4   -0.16  -0.68\n CTR: dos      0.33  0.91   0.06   0.23\n CTR: dod     -0.61  0.08  -0.41   0.68"
  },
  {
    "objectID": "kwdyz11.html#diagnostic-plots-of-lmm-residuals",
    "href": "kwdyz11.html#diagnostic-plots-of-lmm-residuals",
    "title": "RePsychLing Kliegl et al. (2010)",
    "section": "Diagnostic plots of LMM residuals",
    "text": "Diagnostic plots of LMM residuals\nDo model residuals meet LMM assumptions? Classic plots are\n\nResidual over fitted\nQuantiles of model residuals over theoretical quantiles of normal distribution\n\n\nResidual-over-fitted plot\nThe slant in residuals show a lower and upper boundary of reaction times, that is we have have too few short and too few long residuals. Not ideal, but at least width of the residual band looks similar across the fitted values, that is there is no evidence for heteroskedasticity.\n\n\nCode\nCairoMakie.activate!(; type=\"png\")\nset_aog_theme!()\ndraw(\n  data((; f=fitted(m1), r=residuals(m1))) *\n  mapping(:f =&gt; \"Fitted values\", :r =&gt; \"Residual from model m1\") *\n  visual(Scatter);\n)\n\n\n\n\n\nFigure 3: Residuals versus the fitted values for model m1 of the log response time.\n\n\n\n\nWith many observations the scatterplot is not that informative. Contour plots or heatmaps may be an alternative.\n\n\nCode\nCairoMakie.activate!(; type=\"png\")\ndraw(\n  data((; f=fitted(m1), r=residuals(m1))) *\n  mapping(\n    :f =&gt; \"Fitted log response time\", :r =&gt; \"Residual from model m1\"\n  ) *\n  density();\n)\n\n\n\n\n\nFigure 4: Heatmap of residuals versus fitted values for model m1\n\n\n\n\n\n\nQ-Q plot\nThe plot of quantiles of model residuals over corresponding quantiles of the normal distribution should yield a straight line along the main diagonal.\n\nqqnorm(residuals(m1); qqline=:none)\n\n\n\n\n\n\nObserved and theoretical normal distribution\nThe violation of expectation is again due to the fact that the distribution of residuals is much narrower than expected from a normal distribution, as shown in Figure 5. Overall, it does not look too bad.\n\n\nCode\nlet\n  n = nrow(dat)\n  dat_rz = DataFrame(;\n    value=vcat(residuals(m1) ./ std(residuals(m1)), randn(n)),\n    curve=vcat(fill.(\"residual\", n), fill.(\"normal\", n)),\n  )\n  draw(\n    data(dat_rz) *\n    mapping(:value =&gt; \"Standardized residuals\"; color=:curve) *\n    density(; bandwidth=0.1);\n  )\nend\n\n\n\n\n\nFigure 5: Kernel density plot of the standardized residuals from model m1 compared to a Gaussian"
  },
  {
    "objectID": "kwdyz11.html#conditional-modes",
    "href": "kwdyz11.html#conditional-modes",
    "title": "RePsychLing Kliegl et al. (2010)",
    "section": "Conditional modes",
    "text": "Conditional modes\nNow we move on to visualizations that are based on model parameters and subjects’ data, that is “predictions” of the LMM for subject’s GM and experimental effects. Three important plots are\n\nOverlay\nCaterpillar\nShrinkage\n\n\nOverlay\nThe first plot overlays shrinkage-corrected conditional modes of the random effects with within-subject-based and pooled GMs and experimental effects.\nTo be done\n\n\nCaterpillar plot\nThe caterpillar plot, Figure 6, also reveals the high correlation between spatial sod and attraction dod effects.\n\n\nCode\ncaterpillar!(\n  Figure(; resolution=(800, 1000)), ranefinfo(m1, :Subj); orderby=2\n)\n\n\n\n\n\nFigure 6: Prediction intervals on the random effects for Subj in model m1\n\n\n\n\n\n\nShrinkage plot\nFigure 7 provides more evidence for a problem with the visualization of the spatial sod and attraction dod CP. The corresponding panel illustrates an implosion of conditional modes.\n\n\nCode\nshrinkageplot!(Figure(; resolution=(1000, 1000)), m1)\n\n\n\n\n\nFigure 7: Shrinkage plot of the conditional means of the random effects for model m1"
  },
  {
    "objectID": "kwdyz11.html#parametric-bootstrap",
    "href": "kwdyz11.html#parametric-bootstrap",
    "title": "RePsychLing Kliegl et al. (2010)",
    "section": "Parametric bootstrap",
    "text": "Parametric bootstrap\nHere we\n\ngenerate a bootstrap sample\ncompute shortest covergage intervals for the LMM parameters\nplot densities of bootstrapped parameter estimates for residual, fixed effects, variance components, and correlation parameters\n\n\nGenerate a bootstrap sample\nWe generate 2500 samples for the 15 model parameters (4 fixed effect, 4 VCs, 6 CPs, and 1 residual).\n\n\nCode\nRandom.seed!(1234321)\nsamp = parametricbootstrap(2500, m1; hide_progress=true)\ndat2 = DataFrame(samp.allpars)\nfirst(dat2, 10)\n\n\n10×5 DataFrame\n\n\n\nRow\niter\ntype\ngroup\nnames\nvalue\n\n\n\nInt64\nString\nString?\nString?\nFloat64\n\n\n\n\n1\n1\nβ\nmissing\n(Intercept)\n5.93392\n\n\n2\n1\nβ\nmissing\nCTR: sod\n0.0864217\n\n\n3\n1\nβ\nmissing\nCTR: dos\n0.0488901\n\n\n4\n1\nβ\nmissing\nCTR: dod\n-0.0121857\n\n\n5\n1\nσ\nSubj\n(Intercept)\n0.132942\n\n\n6\n1\nσ\nSubj\nCTR: sod\n0.0497421\n\n\n7\n1\nρ\nSubj\n(Intercept), CTR: sod\n0.604961\n\n\n8\n1\nσ\nSubj\nCTR: dos\n0.0278888\n\n\n9\n1\nρ\nSubj\n(Intercept), CTR: dos\n-0.254434\n\n\n10\n1\nρ\nSubj\nCTR: sod, CTR: dos\n0.0548647\n\n\n\n\n\n\n\nnrow(dat2) # 2500 estimates for each of 15 model parameters\n\n37500\n\n\n\n\nShortest coverage interval\nThe upper limit of the interval for the critical CP CTR: sod, CTR: dod is hitting the upper wall of a perfect correlation. This is evidence of singularity. The other intervals do not exhibit such pathologies; they appear to be ok.\n\n\nCode\nDataFrame(shortestcovint(samp))\n\n\n15×5 DataFrame\n\n\n\nRow\ntype\ngroup\nnames\nlower\nupper\n\n\n\nString\nString?\nString?\nFloat64\nFloat64\n\n\n\n\n1\nβ\nmissing\n(Intercept)\n5.89917\n5.97256\n\n\n2\nβ\nmissing\nCTR: sod\n0.0719301\n0.104589\n\n\n3\nβ\nmissing\nCTR: dos\n0.025117\n0.0491667\n\n\n4\nβ\nmissing\nCTR: dod\n-0.0207182\n0.0026827\n\n\n5\nσ\nSubj\n(Intercept)\n0.116563\n0.16857\n\n\n6\nσ\nSubj\nCTR: sod\n0.0445734\n0.0698861\n\n\n7\nρ\nSubj\n(Intercept), CTR: sod\n0.243675\n0.712995\n\n\n8\nσ\nSubj\nCTR: dos\n0.00942323\n0.0410137\n\n\n9\nρ\nSubj\n(Intercept), CTR: dos\n-0.999921\n0.170089\n\n\n10\nρ\nSubj\nCTR: sod, CTR: dos\n-0.726973\n0.492909\n\n\n11\nσ\nSubj\nCTR: dod\n0.0132921\n0.0376006\n\n\n12\nρ\nSubj\n(Intercept), CTR: dod\n-0.132581\n0.740569\n\n\n13\nρ\nSubj\nCTR: sod, CTR: dod\n0.57382\n0.999995\n\n\n14\nρ\nSubj\nCTR: dos, CTR: dod\n-0.894741\n0.435649\n\n\n15\nσ\nresidual\nmissing\n0.19051\n0.19359\n\n\n\n\n\n\n\n\nComparative density plots of bootstrapped parameter estimates\n\nResidual\n\n\nCode\ndraw(\n  data(@subset(dat2, :type == \"σ\", ismissing(:names))) *\n  mapping(:value =&gt; \"Residual standard deviation\") *\n  density();\n)\n\n\n\n\n\nFigure 8: ?(caption)\n\n\n\n\n\n\nFixed effects (w/o GM)\nThe shortest coverage interval for the GM ranges from 376 to 404 ms. To keep the plot range small we do not inlcude its density here.\n\n\nCode\nlabels = [\n  \"CTR: sod\" =&gt; \"spatial effect\",\n  \"CTR: dos\" =&gt; \"object effect\",\n  \"CTR: dod\" =&gt; \"attraction effect\",\n  \"(Intercept)\" =&gt; \"grand mean\",\n]\ndraw(\n  data(@subset(dat2, :type == \"β\" && :names ≠ \"(Intercept)\")) *\n  mapping(\n    :value =&gt; \"Experimental effect size [ms]\";\n    color=:names =&gt; renamer(labels) =&gt; \"Experimental effects\",\n  ) *\n  density();\n)\n\n\n\n\n\nFigure 9: Comparative density plots of the fixed-effects parameters for model m1\n\n\n\n\nThe densitiies correspond nicely with the shortest coverage intervals.\n\n\nVariance components (VCs)\n\n\nCode\ndraw(\n  data(@subset(dat2, :type == \"σ\" && :group == \"Subj\")) *\n  mapping(\n    :value =&gt; \"Standard deviations [ms]\";\n    color=:names =&gt; renamer(labels) =&gt; \"Variance components\",\n  ) *\n  density();\n)\n\n\n\n\n\nFigure 10: Comparative density plots of the variance components for model m1\n\n\n\n\nThe VC are all very nicely defined.\n\n\nCorrelation parameters (CPs)\n\n\nCode\nlet\n  labels = [\n    \"(Intercept), CTR: sod\" =&gt; \"GM, spatial\",\n    \"(Intercept), CTR: dos\" =&gt; \"GM, object\",\n    \"CTR: sod, CTR: dos\" =&gt; \"spatial, object\",\n    \"(Intercept), CTR: dod\" =&gt; \"GM, attraction\",\n    \"CTR: sod, CTR: dod\" =&gt; \"spatial, attraction\",\n    \"CTR: dos, CTR: dod\" =&gt; \"object, attraction\",\n  ]\n  draw(\n    data(@subset(dat2, :type == \"ρ\")) *\n    mapping(\n      :value =&gt; \"Correlation\";\n      color=:names =&gt; renamer(labels) =&gt; \"Correlation parameters\",\n    ) *\n    density();\n  )\nend\n\n\n\n\n\nFigure 11: Comparative density plots of the correlation parameters for model m1\n\n\n\n\nTwo of the CPs stand out positively. First, the correlation between GM and the spatial effect is well defined. Second, as discussed throughout this script, the CP between spatial and attraction effect is close to the 1.0 border and clearly not well defined. Therefore, this CP will be replicated with a larger sample in script kkl15.jl (Kliegl et al., 2015)."
  },
  {
    "objectID": "glmm.html",
    "href": "glmm.html",
    "title": "Generalized linear mixed models",
    "section": "",
    "text": "Load the packages to be used\nCode\nusing AlgebraOfGraphics\nusing CairoMakie\nusing DataFrameMacros\nusing DataFrames\nusing MixedModels\nusing MixedModelsMakie\nusing ProgressMeter\n\nCairoMakie.activate!(; type=\"svg\");\nProgressMeter.ijulia_behavior(:clear);\ndatadir = joinpath(@__DIR__, \"data\");"
  },
  {
    "objectID": "glmm.html#matrix-notation-for-the-sleepstudy-model",
    "href": "glmm.html#matrix-notation-for-the-sleepstudy-model",
    "title": "Generalized linear mixed models",
    "section": "Matrix notation for the sleepstudy model",
    "text": "Matrix notation for the sleepstudy model\n\nsleepstudy = DataFrame(MixedModels.dataset(:sleepstudy))\n\n180×3 DataFrame155 rows omitted\n\n\n\nRow\nsubj\ndays\nreaction\n\n\n\nString\nInt8\nFloat64\n\n\n\n\n1\nS308\n0\n249.56\n\n\n2\nS308\n1\n258.705\n\n\n3\nS308\n2\n250.801\n\n\n4\nS308\n3\n321.44\n\n\n5\nS308\n4\n356.852\n\n\n6\nS308\n5\n414.69\n\n\n7\nS308\n6\n382.204\n\n\n8\nS308\n7\n290.149\n\n\n9\nS308\n8\n430.585\n\n\n10\nS308\n9\n466.353\n\n\n11\nS309\n0\n222.734\n\n\n12\nS309\n1\n205.266\n\n\n13\nS309\n2\n202.978\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n169\nS371\n8\n350.781\n\n\n170\nS371\n9\n369.469\n\n\n171\nS372\n0\n269.412\n\n\n172\nS372\n1\n273.474\n\n\n173\nS372\n2\n297.597\n\n\n174\nS372\n3\n310.632\n\n\n175\nS372\n4\n287.173\n\n\n176\nS372\n5\n329.608\n\n\n177\nS372\n6\n334.482\n\n\n178\nS372\n7\n343.22\n\n\n179\nS372\n8\n369.142\n\n\n180\nS372\n9\n364.124\n\n\n\n\n\n\n\ncontrasts = Dict(:subj =&gt; Grouping())\nm1 = let\n  form = @formula(reaction ~ 1 + days + (1 + days | subj))\n  fit(MixedModel, form, sleepstudy; contrasts)\nend\nprintln(m1)\n\nLinear mixed model fit by maximum likelihood\n reaction ~ 1 + days + (1 + days | subj)\n   logLik   -2 logLik     AIC       AICc        BIC    \n  -875.9697  1751.9393  1763.9393  1764.4249  1783.0971\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\nsubj     (Intercept)  565.51067 23.78047\n         days          32.68212  5.71683 +0.08\nResidual              654.94145 25.59182\n Number of obs: 180; levels of grouping factors: 18\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n                Coef.  Std. Error      z  Pr(&gt;|z|)\n──────────────────────────────────────────────────\n(Intercept)  251.405      6.63226  37.91    &lt;1e-99\ndays          10.4673     1.50224   6.97    &lt;1e-11\n──────────────────────────────────────────────────\n\n\nThe response vector, y, has 180 elements. The fixed-effects coefficient vector, β, has 2 elements and the fixed-effects model matrix, X, is of size 180 × 2.\n\nm1.y\n\n180-element view(::Matrix{Float64}, :, 3) with eltype Float64:\n 249.56\n 258.7047\n 250.8006\n 321.4398\n 356.8519\n 414.6901\n 382.2038\n 290.1486\n 430.5853\n 466.3535\n 222.7339\n 205.2658\n 202.9778\n   ⋮\n 350.7807\n 369.4692\n 269.4117\n 273.474\n 297.5968\n 310.6316\n 287.1726\n 329.6076\n 334.4818\n 343.2199\n 369.1417\n 364.1236\n\n\n\nm1.β\n\n2-element Vector{Float64}:\n 251.40510484848414\n  10.46728595959568\n\n\n\nm1.X\n\n180×2 Matrix{Float64}:\n 1.0  0.0\n 1.0  1.0\n 1.0  2.0\n 1.0  3.0\n 1.0  4.0\n 1.0  5.0\n 1.0  6.0\n 1.0  7.0\n 1.0  8.0\n 1.0  9.0\n 1.0  0.0\n 1.0  1.0\n 1.0  2.0\n ⋮    \n 1.0  8.0\n 1.0  9.0\n 1.0  0.0\n 1.0  1.0\n 1.0  2.0\n 1.0  3.0\n 1.0  4.0\n 1.0  5.0\n 1.0  6.0\n 1.0  7.0\n 1.0  8.0\n 1.0  9.0\n\n\nThe second column of X is just the days vector and the first column is all 1’s.\nThere are 36 random effects, 2 for each of the 18 levels of subj. The “estimates” (technically, the conditional means or conditional modes) are returned as a vector of matrices, one matrix for each grouping factor. In this case there is only one grouping factor for the random effects so there is one one matrix which contains 18 intercept random effects and 18 slope random effects.\n\nm1.b\n\n1-element Vector{Matrix{Float64}}:\n [2.8158180863879005 -40.04844125547803 … 0.7232621646562781 12.118907819971193; 9.075511889252148 -8.644079482408275 … -0.9710526563521795 1.3106980518574347]\n\n\n\nfirst(m1.b)   # only one grouping factor\n\n2×18 Matrix{Float64}:\n 2.81582  -40.0484   -38.4331  22.8321   …  -24.7101   0.723262  12.1189\n 9.07551   -8.64408   -5.5134  -4.65872       4.6597  -0.971053   1.3107\n\n\nThere is a model matrix, Z, for the random effects. In general it has one chunk of columns for the first grouping factor, a chunk of columns for the second grouping factor, etc.\nIn this case there is only one grouping factor.\n\nInt.(first(m1.reterms))\n\n180×36 Matrix{Int64}:\n 1  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n 1  1  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 1  2  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 1  3  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 1  4  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 1  5  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n 1  6  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 1  7  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 1  8  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 1  9  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  1  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  2  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n ⋮              ⋮              ⋮        ⋱     ⋮              ⋮              ⋮\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  1  8  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  1  9  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  1  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  1\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  2\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  3\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  4\n 0  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  1  5\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  6\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  7\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  8\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  9\n\n\nThe defining property of a linear model or linear mixed model is that the fitted values are linear combinations of the fixed-effects parameters and the random effects. We can write the fitted values as\n\nm1.X * m1.β + only(m1.reterms) * vec(only(m1.b))\n\n180-element Vector{Float64}:\n 254.22092293487205\n 273.7637207837199\n 293.3065186325677\n 312.84931648141554\n 332.3921143302634\n 351.93491217911117\n 371.477710027959\n 391.02050787680685\n 410.5633057256547\n 430.1061035745025\n 211.35666359300612\n 213.17987007019354\n 215.00307654738089\n   ⋮\n 328.0982334390884\n 337.5944667423319\n 263.5240126684553\n 275.3019966799085\n 287.0799806913615\n 298.8579647028147\n 310.63594871426784\n 322.4139327257209\n 334.19191673717404\n 345.96990074862714\n 357.74788476008024\n 369.5258687715334\n\n\n\nfitted(m1)   # just to check that these are indeed the same as calculated above\n\n180-element Vector{Float64}:\n 254.22092293487205\n 273.76372078371986\n 293.30651863256764\n 312.8493164814155\n 332.3921143302633\n 351.93491217911117\n 371.477710027959\n 391.02050787680685\n 410.56330572565463\n 430.10610357450247\n 211.35666359300612\n 213.17987007019354\n 215.0030765473809\n   ⋮\n 328.0982334390884\n 337.5944667423319\n 263.5240126684553\n 275.3019966799085\n 287.0799806913615\n 298.8579647028147\n 310.6359487142678\n 322.4139327257209\n 334.19191673717404\n 345.96990074862714\n 357.74788476008024\n 369.52586877153334\n\n\nIn symbols we would write the linear predictor expression as \\[\n\\boldsymbol{\\eta} = \\mathbf{X}\\boldsymbol{\\beta} +\\mathbf{Z b}\n\\] where \\(\\boldsymbol{\\eta}\\) has 180 elements, \\(\\boldsymbol{\\beta}\\) has 2 elements, \\(\\bf b\\) has 36 elements, \\(\\bf X\\) is of size 180 × 2 and \\(\\bf Z\\) is of size 180 × 36.\nFor a linear model or linear mixed model the linear predictor is the mean response, \\(\\boldsymbol\\mu\\). That is, we can write the probability model in terms of a 180-dimensional random variable, \\(\\mathcal Y\\), for the response and a 36-dimensional random variable, \\(\\mathcal B\\), for the random effects as \\[\n\\begin{aligned}\n(\\mathcal{Y} | \\mathcal{B}=\\bf{b}) &\\sim\\mathcal{N}(\\bf{ X\\boldsymbol\\beta + Z b},\\sigma^2\\bf{I})\\\\\\\\\n\\mathcal{B}&\\sim\\mathcal{N}(\\bf{0},\\boldsymbol{\\Sigma}_{\\boldsymbol\\theta}) .\n\\end{aligned}\n\\] where \\(\\boldsymbol{\\Sigma}_\\boldsymbol{\\theta}\\) is a 36 × 36 symmetric covariance matrix that has a special form - it consists of 18 diagonal blocks, each of size 2 × 2 and all the same.\nRecall that this symmetric matrix can be constructed from the parameters \\(\\boldsymbol\\theta\\), which generate the lower triangular matrix \\(\\boldsymbol\\lambda\\), and the estimate \\(\\widehat{\\sigma^2}\\).\n\nm1.θ\n\n3-element Vector{Float64}:\n 0.9292213132463749\n 0.0181683611765396\n 0.2226448780526805\n\n\n\nλ = only(m1.λ)  # with multiple grouping factors there will be multiple λ's\n\n2×2 LinearAlgebra.LowerTriangular{Float64, Matrix{Float64}}:\n 0.929221    ⋅ \n 0.0181684  0.222645\n\n\n\nΣ = varest(m1) * (λ * λ')\n\n2×2 Matrix{Float64}:\n 565.511  11.057\n  11.057  32.6821\n\n\nCompare the diagonal elements to the Variance column of\n\nVarCorr(m1)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\nsubj\n(Intercept)\n565.51067\n23.78047\n\n\n\n\ndays\n32.68212\n5.71683\n+0.08\n\n\nResidual\n\n654.94145\n25.59182"
  },
  {
    "objectID": "glmm.html#linear-predictors-in-lmms-and-glmms",
    "href": "glmm.html#linear-predictors-in-lmms-and-glmms",
    "title": "Generalized linear mixed models",
    "section": "Linear predictors in LMMs and GLMMs",
    "text": "Linear predictors in LMMs and GLMMs\nWriting the model for \\(\\mathcal Y\\) as \\[\n(\\mathcal{Y} | \\mathcal{B}=\\bf{b})\\sim\\mathcal{N}(\\bf{ X\\boldsymbol\\beta + Z b},\\sigma^2\\bf{I})\n\\] may seem like over-mathematization (or “overkill”, if you prefer) relative to expressions like \\[\ny_i = \\beta_1 x_{i,1} + \\beta_2 x_{i,2}+ b_1 z_{i,1} +\\dots+b_{36} z_{i,36}+\\epsilon_i\n\\] but this more abstract form is necessary for generalizations.\nThe way that I read the first form is\n\n\n\n\n\n\nThe conditional distribution of the response vector, \\(\\mathcal Y\\), given that the random effects vector, \\(\\mathcal B =\\bf b\\), is a multivariate normal (or Gaussian) distribution whose mean, \\(\\boldsymbol\\mu\\), is the linear predictor, \\(\\boldsymbol\\eta=\\bf{X\\boldsymbol\\beta+Zb}\\), and whose covariance matrix is \\(\\sigma^2\\bf I\\). That is, conditional on \\(\\bf b\\), the elements of \\(\\mathcal Y\\) are independent normal random variables with constant variance, \\(\\sigma^2\\), and means of the form \\(\\boldsymbol\\mu = \\boldsymbol\\eta = \\bf{X\\boldsymbol\\beta+Zb}\\).\n\n\n\nSo the only things that differ in the distributions of the \\(y_i\\)’s are the means and they are determined by this linear predictor, \\(\\boldsymbol\\eta = \\bf{X\\boldsymbol\\beta+Zb}\\)."
  },
  {
    "objectID": "glmm.html#generalized-linear-mixed-models",
    "href": "glmm.html#generalized-linear-mixed-models",
    "title": "Generalized linear mixed models",
    "section": "Generalized Linear Mixed Models",
    "text": "Generalized Linear Mixed Models\nConsider first a GLMM for a vector, \\(\\bf y\\), of binary (i.e. yes/no) responses. The probability model for the conditional distribution \\(\\mathcal Y|\\mathcal B=\\bf b\\) consists of independent Bernoulli distributions where the mean, \\(\\mu_i\\), for the i’th response is again determined by the i’th element of a linear predictor, \\(\\boldsymbol\\eta = \\mathbf{X}\\boldsymbol\\beta+\\mathbf{Z b}\\).\nHowever, in this case we will run into trouble if we try to make \\(\\boldsymbol\\mu=\\boldsymbol\\eta\\) because \\(\\mu_i\\) is the probability of “success” for the i’th response and must be between 0 and 1. We can’t guarantee that the i’th component of \\(\\boldsymbol\\eta\\) will be between 0 and 1. To get around this problem we apply a transformation to take \\(\\eta_i\\) to \\(\\mu_i\\). For historical reasons this transformation is called the inverse link, written \\(g^{-1}\\), and the opposite transformation - from the probability scale to an unbounded scale - is called the link, g.\nEach probability distribution in the exponential family (which is most of the important ones), has a canonical link which comes from the form of the distribution itself. The details aren’t as important as recognizing that the distribution itself determines a preferred link function.\nFor the Bernoulli distribution, the canonical link is the logit or log-odds function, \\[\n\\eta = g(\\mu) = \\log\\left(\\frac{\\mu}{1-\\mu}\\right),\n\\] (it’s called log-odds because it is the logarithm of the odds ratio, \\(p/(1-p)\\)) and the canonical inverse link is the logistic \\[\n\\mu=g^{-1}(\\eta)=\\frac{1}{1+\\exp(-\\eta)}.\n\\] This is why fitting a binary response is sometimes called logistic regression.\nFor later use we define a Julia logistic function. See this presentation for more information than you could possible want to know on how Julia converts code like this to run on the processor.\n\nincrement(x) = x + one(x)\nlogistic(η) = inv(increment(exp(-η)))\n\nlogistic (generic function with 1 method)\n\n\nTo reiterate, the probability model for a Generalized Linear Mixed Model (GLMM) is \\[\n\\begin{aligned}\n(\\mathcal{Y} | \\mathcal{B}=\\bf{b}) &\\sim\\mathcal{D}(\\bf{g^{-1}(X\\boldsymbol\\beta + Z b)},\\phi)\\\\\\\\\n\\mathcal{B}&\\sim\\mathcal{N}(\\bf{0},\\Sigma_{\\boldsymbol\\theta}) .\n\\end{aligned}\n\\] where \\(\\mathcal{D}\\) is the distribution family (such as Bernoulli or Poisson), \\(g^{-1}\\) is the inverse link and \\(\\phi\\) is a scale parameter for \\(\\mathcal{D}\\) if it has one. The important cases of the Bernoulli and Poisson distributions don’t have a scale parameter - once you know the mean you know everything you need to know about the distribution. (For those following the presentation, this poem by John Keats is the one with the couplet “Beauty is truth, truth beauty - that is all ye know on earth and all ye need to know.”)\n\nAn example of a Bernoulli GLMM\nThe contra dataset in the MixedModels package is from a survey on the use of artificial contraception by women in Bangladesh.\n\ncontra = DataFrame(MixedModels.dataset(:contra))\n\n1934×5 DataFrame1909 rows omitted\n\n\n\nRow\ndist\nurban\nlivch\nage\nuse\n\n\n\nString\nString\nString\nFloat64\nString\n\n\n\n\n1\nD01\nY\n3+\n18.44\nN\n\n\n2\nD01\nY\n0\n-5.56\nN\n\n\n3\nD01\nY\n2\n1.44\nN\n\n\n4\nD01\nY\n3+\n8.44\nN\n\n\n5\nD01\nY\n0\n-13.56\nN\n\n\n6\nD01\nY\n0\n-11.56\nN\n\n\n7\nD01\nY\n3+\n18.44\nN\n\n\n8\nD01\nY\n3+\n-3.56\nN\n\n\n9\nD01\nY\n1\n-5.56\nN\n\n\n10\nD01\nY\n3+\n1.44\nN\n\n\n11\nD01\nY\n0\n-11.56\nY\n\n\n12\nD01\nY\n0\n-2.56\nN\n\n\n13\nD01\nY\n1\n-4.56\nN\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n1923\nD61\nN\n0\n-11.56\nY\n\n\n1924\nD61\nN\n3+\n1.44\nN\n\n\n1925\nD61\nN\n1\n-5.56\nN\n\n\n1926\nD61\nN\n3+\n14.44\nN\n\n\n1927\nD61\nN\n3+\n19.44\nN\n\n\n1928\nD61\nN\n2\n-9.56\nY\n\n\n1929\nD61\nN\n2\n-2.56\nN\n\n\n1930\nD61\nN\n3+\n14.44\nN\n\n\n1931\nD61\nN\n2\n-4.56\nN\n\n\n1932\nD61\nN\n3+\n14.44\nN\n\n\n1933\nD61\nN\n0\n-13.56\nN\n\n\n1934\nD61\nN\n3+\n10.44\nN\n\n\n\n\n\n\n\ncombine(groupby(contra, :dist), nrow)\n\n60×2 DataFrame35 rows omitted\n\n\n\nRow\ndist\nnrow\n\n\n\nString\nInt64\n\n\n\n\n1\nD01\n117\n\n\n2\nD02\n20\n\n\n3\nD03\n2\n\n\n4\nD04\n30\n\n\n5\nD05\n39\n\n\n6\nD06\n65\n\n\n7\nD07\n18\n\n\n8\nD08\n37\n\n\n9\nD09\n23\n\n\n10\nD10\n13\n\n\n11\nD11\n21\n\n\n12\nD12\n29\n\n\n13\nD13\n24\n\n\n⋮\n⋮\n⋮\n\n\n49\nD49\n4\n\n\n50\nD50\n19\n\n\n51\nD51\n37\n\n\n52\nD52\n61\n\n\n53\nD53\n19\n\n\n54\nD55\n6\n\n\n55\nD56\n45\n\n\n56\nD57\n27\n\n\n57\nD58\n33\n\n\n58\nD59\n10\n\n\n59\nD60\n32\n\n\n60\nD61\n42\n\n\n\n\n\n\nThe information recorded included woman’s age, the number of live children she has, whether she lives in an urban or rural setting, and the political district in which she lives.\nThe age was centered. Unfortunately, the version of the data to which I had access did not record what the centering value was.\nA data plot, drawn using lattice graphics in R, shows that the probability of contraception use is not linear in age - it is low for younger women, higher for women in the middle of the range (assumed to be women in late 20’s to early 30’s) and low again for older women (late 30’s to early 40’s in this survey).\nIf we fit a model with only the age term in the fixed effects, that term will not be significant. This doesn’t mean that there is no “age effect”, it only means that there is no significant linear effect for age.\n\n\nCode\ndraw(\n  data(\n    @transform(\n      contra,\n      :numuse = Int(:use == \"Y\"),\n      :urb = ifelse(:urban == \"Y\", \"Urban\", \"Rural\")\n    )\n  ) *\n  mapping(\n    :age =&gt; \"Centered age (yr)\",\n    :numuse =&gt; \"Frequency of contraception use\";\n    col=:urb,\n    color=:livch,\n  ) *\n  smooth();\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\n\nFigure 1: Smoothed relative frequency of contraception use versus centered age for women in the 1989 Bangladesh Fertility Survey\n\n\n\n\n\ncontrasts = Dict(\n  :dist =&gt; Grouping(),\n  :urban =&gt; HelmertCoding(),\n  :livch =&gt; DummyCoding(), # default, but no harm in being explicit\n)\nnAGQ = 9\ndist = Bernoulli()\ngm1 = let\n  form = @formula(\n    use ~ 1 + age + abs2(age) + urban + livch + (1 | dist)\n  )\n  fit(MixedModel, form, contra, dist; nAGQ, contrasts)\nend\n\nMinimizing 214   Time: 0:00:00 ( 1.98 ms/it)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_dist\n\n\n\n\n(Intercept)\n-0.6871\n0.1686\n-4.08\n&lt;1e-04\n0.4786\n\n\nage\n0.0035\n0.0092\n0.38\n0.7021\n\n\n\nabs2(age)\n-0.0046\n0.0007\n-6.29\n&lt;1e-09\n\n\n\nurban: Y\n0.3484\n0.0600\n5.81\n&lt;1e-08\n\n\n\nlivch: 1\n0.8151\n0.1622\n5.02\n&lt;1e-06\n\n\n\nlivch: 2\n0.9165\n0.1851\n4.95\n&lt;1e-06\n\n\n\nlivch: 3+\n0.9153\n0.1858\n4.93\n&lt;1e-06\n\n\n\n\n\n\nNotice that the linear term for age is not significant but the quadratic term for age is highly significant. We usually retain the lower order term, even if it is not significant, if the higher order term is significant.\nNotice also that the parameter estimates for the treatment contrasts for livch are similar. Thus the distinction of 1, 2, or 3+ childen is not as important as the contrast between having any children and not having any. Those women who already have children are more likely to use artificial contraception.\nFurthermore, the women without children have a different probability vs age profile than the women with children. To allow for this we define a binary children factor and incorporate an age&children interaction.\n\nVarCorr(gm1)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\n\n\n\n\ndist\n(Intercept)\n0.229094\n0.478638\n\n\n\n\n\nNotice that there is no “residual” variance being estimated. This is because the Bernoulli distribution doesn’t have a scale parameter.\n\n\nConvert livch to a binary factor\n\n@transform!(contra, :children = :livch ≠ \"0\")\n# add the associated contrast specifier\ncontrasts[:children] = EffectsCoding()\n\nEffectsCoding(nothing, nothing)\n\n\n\ngm2 = let\n  form = @formula(\n    use ~\n      1 +\n      age * children +\n      abs2(age) +\n      children +\n      urban +\n      (1 | dist)\n  )\n  fit(MixedModel, form, contra, dist; nAGQ, contrasts)\nend\n\nMinimizing 146   Time: 0:00:00 ( 1.02 ms/it)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_dist\n\n\n\n\n(Intercept)\n-0.3614\n0.1275\n-2.84\n0.0046\n0.4757\n\n\nage\n-0.0131\n0.0110\n-1.19\n0.2351\n\n\n\nchildren: true\n0.6054\n0.1035\n5.85\n&lt;1e-08\n\n\n\nabs2(age)\n-0.0058\n0.0008\n-6.89\n&lt;1e-11\n\n\n\nurban: Y\n0.3567\n0.0602\n5.93\n&lt;1e-08\n\n\n\nage & children: true\n0.0342\n0.0127\n2.69\n0.0072\n\n\n\n\n\n\n\n\nCode\nlet\n  mods = [gm2, gm1]\n  DataFrame(;\n    model=[:gm2, :gm1],\n    npar=dof.(mods),\n    deviance=deviance.(mods),\n    AIC=aic.(mods),\n    BIC=bic.(mods),\n    AICc=aicc.(mods),\n  )\nend\n\n\n2×6 DataFrame\n\n\n\nRow\nmodel\nnpar\ndeviance\nAIC\nBIC\nAICc\n\n\n\nSymbol\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\ngm2\n7\n2364.92\n2379.18\n2418.15\n2379.24\n\n\n2\ngm1\n8\n2372.46\n2388.73\n2433.27\n2388.81\n\n\n\n\n\n\nBecause these models are not nested, we cannot do a likelihood ratio test. Nevertheless we see that the deviance is much lower in the model with age & children even though the 3 levels of livch have been collapsed into a single level of children. There is a substantial decrease in the deviance even though there are fewer parameters in model gm2 than in gm1. This decrease is because the flexibility of the model - its ability to model the behavior of the response - is being put to better use in gm2 than in gm1.\nAt present the calculation of the geomdof as sum(influence(m)) is not correctly defined in our code for a GLMM so we need to do some more work before we can examine those values.\n\n\nUsing urban&dist as a grouping factor\nIt turns out that there can be more difference between urban and rural settings within the same political district than there is between districts. To model this difference we build a model with urban&dist as a grouping factor.\n\ngm3 = let\n  form = @formula(\n    use ~\n      1 +\n      age * children +\n      abs2(age) +\n      children +\n      urban +\n      (1 | urban & dist)\n  )\n  fit(MixedModel, form, contra, dist; nAGQ, contrasts)\nend\n\nMinimizing 157   Time: 0:00:00 ( 0.93 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_urban & dist\n\n\n\n\n(Intercept)\n-0.3415\n0.1269\n-2.69\n0.0071\n0.5761\n\n\nage\n-0.0129\n0.0112\n-1.16\n0.2471\n\n\n\nchildren: true\n0.6064\n0.1045\n5.80\n&lt;1e-08\n\n\n\nabs2(age)\n-0.0056\n0.0008\n-6.66\n&lt;1e-10\n\n\n\nurban: Y\n0.3936\n0.0859\n4.58\n&lt;1e-05\n\n\n\nage & children: true\n0.0332\n0.0128\n2.59\n0.0096\n\n\n\n\n\n\n\n\nCode\nlet\n  mods = [gm3, gm2, gm1]\n  DataFrame(;\n    model=[:gm3, :gm2, :gm1],\n    npar=dof.(mods),\n    deviance=deviance.(mods),\n    AIC=aic.(mods),\n    BIC=bic.(mods),\n    AICc=aicc.(mods),\n  )\nend\n\n\n3×6 DataFrame\n\n\n\nRow\nmodel\nnpar\ndeviance\nAIC\nBIC\nAICc\n\n\n\nSymbol\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\ngm3\n7\n2353.82\n2368.48\n2407.46\n2368.54\n\n\n2\ngm2\n7\n2364.92\n2379.18\n2418.15\n2379.24\n\n\n3\ngm1\n8\n2372.46\n2388.73\n2433.27\n2388.81\n\n\n\n\n\n\nNotice that the parameter count in gm3 is the same as that of gm2 - the thing that has changed is the number of levels of the grouping factor- resulting in a much lower deviance for gm3. This reinforces the idea that a simple count of the number of parameters to be estimated does not always reflect the complexity of the model.\n\ngm2\n\n\n\n\n\nEst.\nSE\nz\np\nσ_dist\n\n\n\n\n(Intercept)\n-0.3614\n0.1275\n-2.84\n0.0046\n0.4757\n\n\nage\n-0.0131\n0.0110\n-1.19\n0.2351\n\n\n\nchildren: true\n0.6054\n0.1035\n5.85\n&lt;1e-08\n\n\n\nabs2(age)\n-0.0058\n0.0008\n-6.89\n&lt;1e-11\n\n\n\nurban: Y\n0.3567\n0.0602\n5.93\n&lt;1e-08\n\n\n\nage & children: true\n0.0342\n0.0127\n2.69\n0.0072\n\n\n\n\n\n\n\ngm3\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_urban & dist\n\n\n\n\n(Intercept)\n-0.3415\n0.1269\n-2.69\n0.0071\n0.5761\n\n\nage\n-0.0129\n0.0112\n-1.16\n0.2471\n\n\n\nchildren: true\n0.6064\n0.1045\n5.80\n&lt;1e-08\n\n\n\nabs2(age)\n-0.0056\n0.0008\n-6.66\n&lt;1e-10\n\n\n\nurban: Y\n0.3936\n0.0859\n4.58\n&lt;1e-05\n\n\n\nage & children: true\n0.0332\n0.0128\n2.59\n0.0096\n\n\n\n\n\n\nThe coefficient for age may be regarded as insignificant but we retain it for two reasons: we have a term of age² (written abs2(age)) in the model and we have a significant interaction age & children in the model.\n\n\nPredictions for some subgroups\nFor a “typical” district (random effect near zero) the predictions on the linear predictor scale for a woman whose age is near the centering value (i.e. centered age of zero) are:\n\nusing Effects\ndesign = Dict(\n  :children =&gt; [true, false], :urban =&gt; [\"Y\", \"N\"], :age =&gt; [0.0]\n)\npreds = effects(design, gm3)\n\n4×7 DataFrame\n\n\n\nRow\nchildren\nage\nurban\nuse: Y\nerr\nlower\nupper\n\n\n\nBool\nFloat64\nString\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\ntrue\n0.0\nY\n0.658575\n0.150531\n0.508045\n0.809106\n\n\n2\nfalse\n0.0\nY\n-0.554319\n0.230477\n-0.784795\n-0.323842\n\n\n3\ntrue\n0.0\nN\n-0.128618\n0.113018\n-0.241636\n-0.0156005\n\n\n4\nfalse\n0.0\nN\n-1.34151\n0.221575\n-1.56309\n-1.11994\n\n\n\n\n\n\nConverting these η values to probabilities yields\n\nlogistic.(preds[!, \"use: Y\"])\n\n4-element Vector{Float64}:\n 0.6589402981066934\n 0.3648630189943811\n 0.46788970324953494\n 0.20726147184793126"
  },
  {
    "objectID": "glmm.html#summarizing-the-results",
    "href": "glmm.html#summarizing-the-results",
    "title": "Generalized linear mixed models",
    "section": "Summarizing the results",
    "text": "Summarizing the results\n\nFrom the data plot we can see a quadratic trend in the probability by age.\nThe patterns for women with children are similar and we do not need to distinguish between 1, 2, and 3+ children.\nWe do distinguish between those women who do not have children and those with children. This shows up in a signficant age & children interaction term."
  },
  {
    "objectID": "largescaledesigned.html",
    "href": "largescaledesigned.html",
    "title": "A large-scale designed experiment",
    "section": "",
    "text": "Load the packages to be used.\nCode\nusing AlgebraOfGraphics\nusing Arrow\nusing CairoMakie\nusing Chain\nusing DataFrameMacros\nusing DataFrames\nusing Effects\nusing MixedModels\nusing MixedModelsMakie\nusing ProgressMeter\nusing StandardizedPredictors\nusing StatsBase\n\ndatadir(paths::AbstractString...) = joinpath(@__DIR__, \"data\", paths...)\nCairoMakie.activate!(; type=\"svg\");\nProgressMeter.ijulia_behavior(:clear);\nThe English Lexicon Project (Balota et al., 2007) was a large-scale multicenter study to examine properties of English words. It incorporated both a lexical decision task and a word recognition task. Different groups of subjects participated in the different tasks."
  },
  {
    "objectID": "largescaledesigned.html#trial-level-data-from-the-ldt",
    "href": "largescaledesigned.html#trial-level-data-from-the-ldt",
    "title": "A large-scale designed experiment",
    "section": "Trial-level data from the LDT",
    "text": "Trial-level data from the LDT\nIn the lexical decision task the study participant is shown a character string, under carefully controlled conditions, and responds according to whether they identify the string as a word or not. Two responses are recorded: whether the choice of word/non-word is correct and the time that elapsed between exposure to the string and registering a decision.\nSeveral covariates, some relating to the subject and some relating to the target, were recorded. Initially we consider only the trial-level data.\n\nldttrial = Arrow.Table(datadir(\"ELP_ldt_trial.arrow\"))\n\nArrow.Table with 2745952 rows, 5 columns, and schema:\n :subj  Int16\n :seq   Int16\n :acc   Union{Missing, Bool}\n :rt    Int16\n :item  String\n\nwith metadata given by a Base.ImmutableDict{String, String} with 3 entries:\n  \"title\"     =&gt; \"Trial-level data from Lexical Discrimination Task in the Engl…\n  \"reference\" =&gt; \"Balota et al. (2007), The English Lexicon Project, Behavior R…\n  \"source\"    =&gt; \"https://osf.io/n63s2\"\n\n\nThe two response variables are acc - the accuracy of the response - and rt, the response time in milliseconds. There is one trial-level covariate, seq, the sequence number of the trial within subj. Each subject participated in two sessions on different days, with 2000 trials recorded on the first day.\nNotice the metadata with a citation and a URL for the OSF project.\nWe convert to a DataFrame and add a Boolean column s2 which is true for trials in the second session.\n\nldttrial = @transform!(DataFrame(ldttrial), :s2 = :seq &gt; 2000)\ndescribe(ldttrial)\n\n6×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nType\n\n\n\n\n1\nsubj\n409.31\n1\n409.0\n816\n0\nInt16\n\n\n2\nseq\n1687.21\n1\n1687.0\n3374\n0\nInt16\n\n\n3\nacc\n0.85604\nfalse\n1.0\ntrue\n1370\nUnion{Missing, Bool}\n\n\n4\nrt\n846.325\n-16160\n732.0\n32061\n0\nInt16\n\n\n5\nitem\n\nAarod\n\nzuss\n0\nString\n\n\n6\ns2\n0.407128\nfalse\n0.0\ntrue\n0\nBool"
  },
  {
    "objectID": "largescaledesigned.html#sec-ldtinitialexplore",
    "href": "largescaledesigned.html#sec-ldtinitialexplore",
    "title": "A large-scale designed experiment",
    "section": "Initial data exploration",
    "text": "Initial data exploration\nFrom the basic summary of ldttrial we can see that there are some questionable response times — negative values and values over 32 seconds.\nBecause of obvious outliers we will use the median response time, which is not strongly influenced by outliers, rather than the mean response time when summarizing by item or by subject.\nAlso, there are missing values of the accuracy. We should check if these are associated with particular subjects or particular items.\n\nSummaries by item\nTo summarize by item we group the trials by item and use combine to produce the various summary statistics. As we will create similar summaries by subject, we incorporate an ‘i’ in the names of these summaries (and an ‘s’ in the name of the summaries by subject) to be able to identify the grouping used.\n\nbyitem = @chain ldttrial begin\n  groupby(:item)\n  @combine(\n    :ni = length(:acc),               # no. of obs\n    :imiss = count(ismissing, :acc),  # no. of missing acc\n    :iacc = count(skipmissing(:acc)), # no. of accurate\n    :imedianrt = median(:rt),\n  )\n  @transform!(\n    :wrdlen = Int8(length(:item)),\n    :ipropacc = :iacc / :ni\n  )\nend\n\n80962×7 DataFrame80937 rows omitted\n\n\n\nRow\nitem\nni\nimiss\niacc\nimedianrt\nwrdlen\nipropacc\n\n\n\nString\nInt64\nInt64\nInt64\nFloat64\nInt8\nFloat64\n\n\n\n\n1\na\n35\n0\n26\n743.0\n1\n0.742857\n\n\n2\ne\n35\n0\n19\n824.0\n1\n0.542857\n\n\n3\naah\n34\n0\n21\n770.5\n3\n0.617647\n\n\n4\naal\n34\n0\n32\n702.5\n3\n0.941176\n\n\n5\nAaron\n33\n0\n31\n625.0\n5\n0.939394\n\n\n6\nAarod\n33\n0\n23\n810.0\n5\n0.69697\n\n\n7\naback\n34\n0\n15\n710.0\n5\n0.441176\n\n\n8\nahack\n34\n0\n34\n662.0\n5\n1.0\n\n\n9\nabacus\n34\n0\n17\n671.5\n6\n0.5\n\n\n10\nalacus\n34\n0\n29\n640.0\n6\n0.852941\n\n\n11\nabandon\n34\n0\n32\n641.0\n7\n0.941176\n\n\n12\nacandon\n34\n0\n33\n725.5\n7\n0.970588\n\n\n13\nabandoned\n34\n0\n31\n667.5\n9\n0.911765\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n80951\nzoology\n33\n0\n32\n623.0\n7\n0.969697\n\n\n80952\npoology\n33\n0\n32\n757.0\n7\n0.969697\n\n\n80953\nzoom\n35\n0\n34\n548.0\n4\n0.971429\n\n\n80954\nzool\n35\n0\n30\n633.0\n4\n0.857143\n\n\n80955\nzooming\n33\n0\n29\n617.0\n7\n0.878788\n\n\n80956\nsooming\n33\n0\n30\n721.0\n7\n0.909091\n\n\n80957\nzooms\n33\n0\n30\n598.0\n5\n0.909091\n\n\n80958\ncooms\n33\n0\n31\n660.0\n5\n0.939394\n\n\n80959\nzucchini\n34\n0\n29\n781.5\n8\n0.852941\n\n\n80960\nhucchini\n34\n0\n32\n727.5\n8\n0.941176\n\n\n80961\nZurich\n34\n0\n21\n731.5\n6\n0.617647\n\n\n80962\nZurach\n34\n0\n26\n811.0\n6\n0.764706\n\n\n\n\n\n\nIt can be seen that the items occur in word/nonword pairs and the pairs are sorted alphabetically by the word in the pair (ignoring case). We can add the word/nonword status for the items as\n\nbyitem.isword = isodd.(eachindex(byitem.item))\ndescribe(byitem)\n\n8×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nitem\n\nAarod\n\nzuss\n0\nString\n\n\n2\nni\n33.9166\n30\n34.0\n37\n0\nInt64\n\n\n3\nimiss\n0.0169215\n0\n0.0\n2\n0\nInt64\n\n\n4\niacc\n29.0194\n0\n31.0\n37\n0\nInt64\n\n\n5\nimedianrt\n753.069\n458.0\n737.5\n1691.0\n0\nFloat64\n\n\n6\nwrdlen\n7.9988\n1\n8.0\n21\n0\nInt8\n\n\n7\nipropacc\n0.855616\n0.0\n0.911765\n1.0\n0\nFloat64\n\n\n8\nisword\n0.5\nfalse\n0.5\ntrue\n0\nBool\n\n\n\n\n\n\nThis table shows that some of the items were never identified correctly. These are\n\nfilter(:iacc =&gt; iszero, byitem)\n\n9×8 DataFrame\n\n\n\nRow\nitem\nni\nimiss\niacc\nimedianrt\nwrdlen\nipropacc\nisword\n\n\n\nString\nInt64\nInt64\nInt64\nFloat64\nInt8\nFloat64\nBool\n\n\n\n\n1\nbaobab\n34\n0\n0\n616.5\n6\n0.0\ntrue\n\n\n2\nhaulage\n34\n0\n0\n708.5\n7\n0.0\ntrue\n\n\n3\nleitmotif\n35\n0\n0\n688.0\n9\n0.0\ntrue\n\n\n4\nmiasmal\n35\n0\n0\n774.0\n7\n0.0\ntrue\n\n\n5\npeahen\n34\n0\n0\n684.0\n6\n0.0\ntrue\n\n\n6\nplosive\n34\n0\n0\n663.0\n7\n0.0\ntrue\n\n\n7\nplugugly\n33\n0\n0\n709.0\n8\n0.0\ntrue\n\n\n8\nposhest\n34\n0\n0\n740.0\n7\n0.0\ntrue\n\n\n9\nservo\n33\n0\n0\n697.0\n5\n0.0\ntrue\n\n\n\n\n\n\nNotice that these are all words but somewhat obscure words such that none of the subjects exposed to the word identified it correctly.\nWe can incorporate characteristics like wrdlen and isword back into the original trial table with a “left join”. This operation joins two tables by values in a common column. It is called a left join because the left (or first) table takes precedence, in the sense that every row in the left table is present in the result. If there is no matching row in the second table then missing values are inserted for the columns from the right table in the result.\n\ndescribe(\n  leftjoin!(\n    ldttrial,\n    select(byitem, :item, :wrdlen, :isword);\n    on=:item,\n  ),\n)\n\n8×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nType\n\n\n\n\n1\nsubj\n409.31\n1\n409.0\n816\n0\nInt16\n\n\n2\nseq\n1687.21\n1\n1687.0\n3374\n0\nInt16\n\n\n3\nacc\n0.85604\nfalse\n1.0\ntrue\n1370\nUnion{Missing, Bool}\n\n\n4\nrt\n846.325\n-16160\n732.0\n32061\n0\nInt16\n\n\n5\nitem\n\nAarod\n\nzuss\n0\nString\n\n\n6\ns2\n0.407128\nfalse\n0.0\ntrue\n0\nBool\n\n\n7\nwrdlen\n7.99835\n1\n8.0\n21\n0\nUnion{Missing, Int8}\n\n\n8\nisword\n0.499995\nfalse\n0.0\ntrue\n0\nUnion{Missing, Bool}\n\n\n\n\n\n\nNotice that the wrdlen and isword variables in this table allow for missing values, because they are derived from the second argument, but there are no missing values for these variables. If there is no need to allow for missing values, there is a slight advantage in disallowing them in the element type, because the code to check for and handle missing values is not needed.\nThis could be done separately for each column or for the whole data frame, as in\n\ndescribe(disallowmissing!(ldttrial; error=false))\n\n8×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nType\n\n\n\n\n1\nsubj\n409.31\n1\n409.0\n816\n0\nInt16\n\n\n2\nseq\n1687.21\n1\n1687.0\n3374\n0\nInt16\n\n\n3\nacc\n0.85604\nfalse\n1.0\ntrue\n1370\nUnion{Missing, Bool}\n\n\n4\nrt\n846.325\n-16160\n732.0\n32061\n0\nInt16\n\n\n5\nitem\n\nAarod\n\nzuss\n0\nString\n\n\n6\ns2\n0.407128\nfalse\n0.0\ntrue\n0\nBool\n\n\n7\nwrdlen\n7.99835\n1\n8.0\n21\n0\nInt8\n\n\n8\nisword\n0.499995\nfalse\n0.0\ntrue\n0\nBool\n\n\n\n\n\n\n\n\n\n\n\n\nNamed argument “error”\n\n\n\n\n\nThe named argument error=false is required because there is one column, acc, that does incorporate missing values. If error=false were not given then the error thrown when trying to disallowmissing on the acc column would be propagated and the top-level call would fail.\n\n\n\nA barchart of the word length counts, Figure 1, shows that the majority of the items are between 3 and 14 characters.\n\n\nCode\nlet\n  wlen = 1:21\n  draw(\n    data((; wrdlen=wlen, count=counts(byitem.wrdlen, wlen))) *\n    mapping(:wrdlen =&gt; \"Length of word\", :count) *\n    visual(BarPlot),\n  )\nend\n\n\n\n\n\nFigure 1: Histogram of word lengths in the items used in the lexical decision task.\n\n\n\n\nTo examine trends in accuracy by word length we create a plot of the response versus word length using just a scatterplot smoother. It would not be meaningful to plot the raw data because that would just provide horizontal lines at \\(\\pm 1\\). Instead we add the smoother to show the trend and omit the raw data points.\nThe resulting plot, Figure 2, shows the accuracy of identifying words is more-or-less constant at around 84%, but accuracy decreases with increasing word length for the nonwords.\n\n\nCode\ndraw(\n  data(@subset(ldttrial, !ismissing(:acc))) *\n  mapping(\n    :wrdlen =&gt; \"Word length\",\n    :acc =&gt; \"Accuracy\";\n    color=:isword,\n  ) * smooth(; span=0.75, degree=2, npoints=200);\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\n\nFigure 2: Smoothed curves of accuracy versus word length in the lexical decision task.\n\n\n\n\nFigure 2 may be a bit misleading because the largest discrepancies in proportion of accurate identifications of words and nonwords occur for the longest words, of which there are few. Over 95% of the words are between 4 and 13 characters in length\n\ncount(x -&gt; 4 ≤ x ≤ 13, byitem.wrdlen) / nrow(byitem)\n\n0.9654899829549666\n\n\nIf we restrict the smoother curves to this range, as in Figure 3,\n\n\nCode\ndraw(\n  data(@subset(ldttrial, !ismissing(:acc), 4 ≤ :wrdlen ≤ 13)) *\n  mapping(\n    :wrdlen =&gt; \"Word length\",\n    :acc =&gt; \"Accuracy\";\n    color=:isword,\n  ) * smooth();\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\n\nFigure 3: Smoothed curves of accuracy versus word length in the range 4 to 13 characters in the lexical decision task.\n\n\n\n\nthe differences are less dramatic.\nAnother way to visualize these results is by plotting the proportion accurate versus word-length separately for words and non-words with the area of each marker proportional to the number of observations for that combinations (Figure 4).\n\n\nCode\nlet\n  itemsummry = combine(\n    groupby(byitem, [:wrdlen, :isword]),\n    :ni =&gt; sum,\n    :imiss =&gt; sum,\n    :iacc =&gt; sum,\n  )\n  @transform!(\n    itemsummry,\n    :iacc_mean = :iacc_sum / (:ni_sum - :imiss_sum)\n  )\n  @transform!(itemsummry, :msz = sqrt((:ni_sum - :imiss_sum) / 800))\n  draw(\n    data(itemsummry) * mapping(\n      :wrdlen =&gt; \"Word length\",\n      :iacc_mean =&gt; \"Proportion accurate\";\n      color=:isword,\n      markersize=:msz,\n    );\n    figure=(; resolution=(800, 450)),\n  )\nend\n\n\n\n\n\nFigure 4: Proportion of accurate trials in the LDT versus word length separately for words and non-words. The area of the marker is proportional to the number of observations represented.\n\n\n\n\nThe pattern in the range of word lengths with non-negligible counts (there are points in the plot down to word lengths of 1 and up to word lengths of 21 but these points are very small) is that the accuracy for words is nearly constant at about 84% and the accuracy fof nonwords is slightly higher until lengths of 13, at which point it falls off a bit.\n\n\nSummaries by subject\nA summary of accuracy and median response time by subject\n\nbysubj = @chain ldttrial begin\n  groupby(:subj)\n  @combine(\n    :ns = length(:acc),               # no. of obs\n    :smiss = count(ismissing, :acc),  # no. of missing acc\n    :sacc = count(skipmissing(:acc)), # no. of accurate\n    :smedianrt = median(:rt),\n  )\n  @transform!(:spropacc = :sacc / :ns)\nend\n\n814×6 DataFrame789 rows omitted\n\n\n\nRow\nsubj\nns\nsmiss\nsacc\nsmedianrt\nspropacc\n\n\n\nInt16\nInt64\nInt64\nInt64\nFloat64\nFloat64\n\n\n\n\n1\n1\n3374\n0\n3158\n554.0\n0.935981\n\n\n2\n2\n3372\n1\n3031\n960.0\n0.898873\n\n\n3\n3\n3372\n3\n3006\n813.0\n0.891459\n\n\n4\n4\n3374\n1\n3062\n619.0\n0.907528\n\n\n5\n5\n3374\n0\n2574\n677.0\n0.762893\n\n\n6\n6\n3374\n0\n2927\n855.0\n0.867516\n\n\n7\n7\n3374\n4\n2877\n918.5\n0.852697\n\n\n8\n8\n3372\n1\n2731\n1310.0\n0.809905\n\n\n9\n9\n3374\n13\n2669\n657.0\n0.791049\n\n\n10\n10\n3374\n0\n2722\n757.0\n0.806758\n\n\n11\n11\n3374\n0\n2894\n632.0\n0.857736\n\n\n12\n12\n3374\n4\n2979\n692.0\n0.882928\n\n\n13\n13\n3374\n2\n2980\n1114.0\n0.883225\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n803\n805\n3374\n5\n2881\n534.0\n0.853883\n\n\n804\n806\n3374\n1\n3097\n841.5\n0.917902\n\n\n805\n807\n3374\n3\n2994\n704.0\n0.887374\n\n\n806\n808\n3374\n2\n2751\n630.5\n0.815353\n\n\n807\n809\n3372\n4\n2603\n627.0\n0.771945\n\n\n808\n810\n3374\n1\n3242\n603.5\n0.960877\n\n\n809\n811\n3374\n2\n2861\n827.0\n0.847955\n\n\n810\n812\n3372\n6\n3012\n471.0\n0.893238\n\n\n811\n813\n3372\n4\n2932\n823.0\n0.869514\n\n\n812\n814\n3374\n1\n3070\n773.0\n0.909899\n\n\n813\n815\n3374\n1\n3024\n602.0\n0.896266\n\n\n814\n816\n3374\n0\n2950\n733.0\n0.874333\n\n\n\n\n\n\nshows some anomalies\n\ndescribe(bysubj)\n\n6×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nFloat64\nReal\nFloat64\nReal\nInt64\nDataType\n\n\n\n\n1\nsubj\n409.311\n1\n409.5\n816\n0\nInt16\n\n\n2\nns\n3373.41\n3370\n3374.0\n3374\n0\nInt64\n\n\n3\nsmiss\n1.68305\n0\n1.0\n22\n0\nInt64\n\n\n4\nsacc\n2886.33\n1727\n2928.0\n3286\n0\nInt64\n\n\n5\nsmedianrt\n760.992\n205.0\n735.0\n1804.0\n0\nFloat64\n\n\n6\nspropacc\n0.855613\n0.511855\n0.868031\n0.973918\n0\nFloat64\n\n\n\n\n\n\nFirst, some subjects are accurate on only about half of their trials, which is the proportion that would be expected from random guessing. A plot of the median response time versus proportion accurate, Figure 5, shows that the subjects with lower accuracy are some of the fastest responders, further indicating that these subjects are sacrificing accuracy for speed.\n\n\nCode\ndraw(\n  data(bysubj) *\n  mapping(\n    :spropacc =&gt; \"Proportion accurate\",\n    :smedianrt =&gt; \"Median response time (ms)\",\n  ) *\n  (visual(Scatter) + smooth())\n)\n\n\n\n\n\nFigure 5: Median response time versus proportion accurate by subject in the LDT.\n\n\n\n\nAs described in Balota et al. (2007), the participants performed the trials in blocks of 250 followed by a short break. During the break they were given feedback concerning accuracy and response latency in the previous block of trials. If the accuracy was less than 80% the participant was encouraged to improve their accuracy. Similarly, if the mean response latency was greater than 1000 ms, the participant was encouraged to decrease their response time. During the trials immediate feedback was given if the response was incorrect.\nNevertheless, approximately 15% of the subjects were unable to maintain 80% accuracy on their trials\n\ncount(&lt;(0.8), bysubj.spropacc) / nrow(bysubj)\n\n0.15233415233415235\n\n\nand there is some association of faster response times with low accuracy. The majority of the subjects whose median response time is less than 500 ms. are accurate on less than 75% of their trials. Another way of characterizing the relationship is that none of the subjects with 90% accuracy or greater had a median response time less than 500 ms.\n\nminimum(@subset(bysubj, :spropacc &gt; 0.9).smedianrt)\n\n505.0\n\n\nIt is common in analyses of response latency in a lexical discrimination task to consider only the latencies on correct identifications and to trim outliers. In Balota et al. (2007) a two-stage outlier removal strategy was used; first removing responses less than 200 ms or greater than 3000 ms then removing responses more than three standard deviations from the participant’s mean response.\nAs described in Section 1.2.3 we will analyze these data on a speed scale (the inverse of response time) using only the first-stage outlier removal of response latencies less than 200 ms or greater than 3000 ms. On the speed scale the limits are 0.333 per second up to 5 per second.\nTo examine the effects of the fast but inaccurate responders we will fit models to the data from all the participants and to the data from the 85% of participants who maintained an overall accuracy of 80% or greater.\n\npruned = @chain ldttrial begin\n  @subset(!ismissing(:acc), 200 ≤ :rt ≤ 3000,)\n  leftjoin!(select(bysubj, :subj, :spropacc); on=:subj)\n  dropmissing!\nend\nsize(pruned)\n\n(2714311, 9)\n\n\n\ndescribe(pruned)\n\n9×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nsubj\n409.802\n1\n410.0\n816\n0\nInt16\n\n\n2\nseq\n1684.56\n1\n1684.0\n3374\n0\nInt16\n\n\n3\nacc\n0.859884\nfalse\n1.0\ntrue\n0\nBool\n\n\n4\nrt\n838.712\n200\n733.0\n3000\n0\nInt16\n\n\n5\nitem\n\nAarod\n\nzuss\n0\nString\n\n\n6\ns2\n0.40663\nfalse\n0.0\ntrue\n0\nBool\n\n\n7\nwrdlen\n7.99244\n1\n8.0\n21\n0\nInt8\n\n\n8\nisword\n0.500126\nfalse\n1.0\ntrue\n0\nBool\n\n\n9\nspropacc\n0.857169\n0.511855\n0.869295\n0.973918\n0\nFloat64\n\n\n\n\n\n\n\n\nChoice of response scale\nAs we have indicated, generally the response times are analyzed for the correct identifications only. Furthermore, unrealistically large or small response times are eliminated. For this example we only use the responses between 200 and 3000 ms.\nA density plot of the pruned response times, Figure 6, shows they are skewed to the right.\n\n\nCode\ndraw(\n  data(pruned) *\n  mapping(:rt =&gt; \"Response time (ms.) for correct responses\") *\n  AlgebraOfGraphics.density();\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\n\nFigure 6: Kernel density plot of the pruned response times (ms.) in the LDT.\n\n\n\n\nIn such cases it is common to transform the response to a scale such as the logarithm of the response time or to the speed of the response, which is the inverse of the response time.\nThe density of the response speed, in responses per second, is shown in Figure 7.\n\n\nCode\ndraw(\n  data(pruned) *\n  mapping(\n    :rt =&gt; (x -&gt; 1000 / x) =&gt; \"Response speed (s⁻¹) for correct responses\") *\n  AlgebraOfGraphics.density();\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\n\nFigure 7: Kernel density plot of the pruned response speed in the LDT.\n\n\n\n\nFigure 6 and Figure 7 indicate that it may be more reasonable to establish a lower bound of 1/3 second (333 ms) on the response latency, corresponding to an upper bound of 3 per second on the response speed. However, only about one half of one percent of the correct responses have latencies in the range of 200 ms. to 333 ms.\n\ncount(\n  r -&gt; !ismissing(r.acc) && 200 &lt; r.rt &lt; 333,\n  eachrow(ldttrial),\n) / count(!ismissing, ldttrial.acc)\n\n0.005867195806137328\n\n\nso the exact position of the lower cut-off point on the response latencies is unlikely to be very important.\n\n\n\n\n\n\nUsing inline transformations vs defining new columns\n\n\n\n\n\nIf you examine the code for (fit-elpldtspeeddens?), you will see that the conversion from rt to speed is done inline rather than creating and storing a new variable in the DataFrame.\nI prefer to keep the DataFrame simple with the integer variables (e.g. :rt) if possible.\nI recommend using the StandardizedPredictors.jl capabilities to center numeric variables or convert to zscores.\n\n\n\n\n\nTransformation of response and the form of the model\nAs noted in Box & Cox (1964), a transformation of the response that produces a more Gaussian distribution often will also produce a simpler model structure. For example, Figure 8 shows the smoothed relationship between word length and response time for words and non-words separately,\n\n\nCode\ndraw(\n  data(pruned) *\n  mapping(\n    :wrdlen =&gt; \"Word length\",\n    :rt =&gt; \"Response time (ms)\";\n    :color =&gt; :isword,\n  ) * smooth()\n)\n\n\n\n\n\nFigure 8: Scatterplot smooths of response time versus word length in the LDT.\n\n\n\n\nand Figure 9 shows the similar relationships for speed\n\n\nCode\ndraw(\n  data(pruned) *\n  mapping(\n    :wrdlen =&gt; \"Word length\",\n    :rt =&gt; (x -&gt; 1000/x) =&gt; \"Speed of response (s⁻¹)\";\n    :color =&gt; :isword,\n  ) * smooth()\n)\n\n\n\n\n\nFigure 9: Scatterplot smooths of response speed versus word length in the LDT.\n\n\n\n\nFor the most part the smoother lines in Figure 9 are reasonably straight. The small amount of curvature is associated with short word lengths, say less than 4 characters, of which there are comparatively few in the study.\nFigure 10 shows a “violin plot” - the empirical density of the response speed by word length separately for words and nonwords. The lines on the plot are fit by linear regression.\n\n\nCode\nlet\n  plt = data(@subset(pruned, :wrdlen &gt; 3, :wrdlen &lt; 14))\n  plt *= mapping(\n    :wrdlen =&gt; \"Word length\",\n    :rt =&gt; (x -&gt; 1000/x) =&gt; \"Speed of response (s⁻¹)\",\n    color=:isword,\n    side=:isword,\n  )\n  plt *= (visual(Violin) + linear(; interval=:confidence))\n  draw(plt, axis=(; limits=(nothing, (0.0, 2.8))))\nend\n\n\n\n\n\nFigure 10: Empirical density of response speed versus word length by word/non-word status, with lines fit by linear regression to each group."
  },
  {
    "objectID": "largescaledesigned.html#sec-ldtinitialmodel",
    "href": "largescaledesigned.html#sec-ldtinitialmodel",
    "title": "A large-scale designed experiment",
    "section": "Models with scalar random effects",
    "text": "Models with scalar random effects\nA major purpose of the English Lexicon Project is to characterize the items (words or nonwords) according to the observed accuracy of identification and to response latency, taking into account subject-to-subject variability, and to relate these to lexical characteristics of the items.\nIn Balota et al. (2007) the item response latency is characterized by the average response latency from the correct trials after outlier removal.\nMixed-effects models allow us greater flexibility and, we hope, precision in characterizing the items by controlling for subject-to-subject variability and for item characteristics such as word/nonword and item length.\nWe begin with a model that has scalar random effects for item and for subject and incorporates fixed-effects for word/nonword and for item length and for the interaction of these terms.\n\nEstablish the contrasts\nBecause there are a large number of items in the data set it is important to assign a Grouping() contrast to item (and, less importantly, to subj). For the isword factor we will use an EffectsCoding contrast with the base level as false. The non-words are assigned -1 in this contrast and the words are assigned +1. The wrdlen covariate is on its original scale but centered at 8 characters.\nThus the (Intercept) coefficient is the predicted speed of response for a typical subject and typical item (without regard to word/non-word status) of 8 characters.\nSet these contrasts\n\ncontrasts = Dict(\n  :subj =&gt; Grouping(),\n  :item =&gt; Grouping(),\n  :isword =&gt; EffectsCoding(; base=false),\n  :wrdlen =&gt; Center(8),\n)\n\nDict{Symbol, Any} with 4 entries:\n  :item   =&gt; Grouping()\n  :wrdlen =&gt; Center(8)\n  :isword =&gt; EffectsCoding(false, nothing)\n  :subj   =&gt; Grouping()\n\n\nand fit a first model with simple, scalar, random effects for subj and item.\n\nelm01 = let\n  form = @formula(\n    1000 / rt ~ 1 + isword * wrdlen + (1 | item) + (1 | subj)\n  )\n  fit(MixedModel, form, pruned; contrasts)\nend\n\nMinimizing 53    Time: 0:00:05 ( 0.10  s/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_item\nσ_subj\n\n\n\n\n(Intercept)\n1.3758\n0.0090\n153.69\n&lt;1e-99\n0.1185\n0.2550\n\n\nisword: true\n0.0625\n0.0005\n131.35\n&lt;1e-99\n\n\n\n\nwrdlen(centered: 8)\n-0.0436\n0.0002\n-225.38\n&lt;1e-99\n\n\n\n\nisword: true & wrdlen(centered: 8)\n-0.0056\n0.0002\n-28.83\n&lt;1e-99\n\n\n\n\nResidual\n0.3781\n\n\n\n\n\n\n\n\n\n\nThe predicted response speed by word length and word/nonword status can be summarized as\n\neffects(Dict(:isword =&gt; [false, true], :wrdlen =&gt; 4:2:12), elm01)\n\n10×6 DataFrame\n\n\n\nRow\nwrdlen\nisword\n1000 / rt\nerr\nlower\nupper\n\n\n\nInt64\nBool\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n4\nfalse\n1.46555\n0.00903111\n1.45652\n1.47458\n\n\n2\n6\nfalse\n1.38947\n0.00898124\n1.38049\n1.39845\n\n\n3\n8\nfalse\n1.31338\n0.00896459\n1.30442\n1.32235\n\n\n4\n10\nfalse\n1.2373\n0.00898133\n1.22832\n1.24628\n\n\n5\n12\nfalse\n1.16121\n0.00903129\n1.15218\n1.17025\n\n\n6\n4\ntrue\n1.6351\n0.0090311\n1.62607\n1.64413\n\n\n7\n6\ntrue\n1.5367\n0.00898124\n1.52772\n1.54569\n\n\n8\n8\ntrue\n1.43831\n0.00896459\n1.42934\n1.44727\n\n\n9\n10\ntrue\n1.33991\n0.00898133\n1.33092\n1.34889\n\n\n10\n12\ntrue\n1.24151\n0.00903127\n1.23248\n1.25054\n\n\n\n\n\n\nIf we restrict to only those subjects with 80% accuracy or greater the model becomes\n\nelm02 = let\n  form = @formula(\n    1000 / rt ~ 1 + isword * wrdlen + (1 | item) + (1 | subj)\n  )\n  dat = @subset(pruned, :spropacc &gt; 0.8)\n  fit(MixedModel, form, dat; contrasts)\nend\n\nMinimizing 53    Time: 0:00:03 (71.57 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_item\nσ_subj\n\n\n\n\n(Intercept)\n1.3611\n0.0088\n153.98\n&lt;1e-99\n0.1247\n0.2318\n\n\nisword: true\n0.0656\n0.0005\n133.73\n&lt;1e-99\n\n\n\n\nwrdlen(centered: 8)\n-0.0444\n0.0002\n-222.65\n&lt;1e-99\n\n\n\n\nisword: true & wrdlen(centered: 8)\n-0.0057\n0.0002\n-28.73\n&lt;1e-99\n\n\n\n\nResidual\n0.3342\n\n\n\n\n\n\n\n\n\n\n\neffects(Dict(:isword =&gt; [false, true], :wrdlen =&gt; 4:2:12), elm02)\n\n10×6 DataFrame\n\n\n\nRow\nwrdlen\nisword\n1000 / rt\nerr\nlower\nupper\n\n\n\nInt64\nBool\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n4\nfalse\n1.45036\n0.00892466\n1.44144\n1.45929\n\n\n2\n6\nfalse\n1.37297\n0.00887101\n1.3641\n1.38184\n\n\n3\n8\nfalse\n1.29557\n0.00885308\n1.28672\n1.30443\n\n\n4\n10\nfalse\n1.21818\n0.0088711\n1.20931\n1.22705\n\n\n5\n12\nfalse\n1.14078\n0.00892486\n1.13186\n1.14971\n\n\n6\n4\ntrue\n1.62735\n0.00892465\n1.61842\n1.63627\n\n\n7\n6\ntrue\n1.52702\n0.008871\n1.51815\n1.53589\n\n\n8\n8\ntrue\n1.4267\n0.00885308\n1.41784\n1.43555\n\n\n9\n10\ntrue\n1.32637\n0.00887109\n1.3175\n1.33524\n\n\n10\n12\ntrue\n1.22605\n0.00892483\n1.21712\n1.23497\n\n\n\n\n\n\nThe differences in the fixed-effects parameter estimates between a model fit to the full data set and one fit to the data from accurate responders only, are small.\nHowever, the random effects for the item, while highly correlated, are not perfectly correlated.\n\n\nCode\nCairoMakie.activate!(; type=\"png\")\ndisallowmissing!(\n  leftjoin!(\n    byitem,\n    leftjoin!(\n      rename!(DataFrame(raneftables(elm01)[:item]), [:item, :elm01]),\n      rename!(DataFrame(raneftables(elm02)[:item]), [:item, :elm02]);\n      on=:item,\n    ),\n    on=:item,\n  ),\n)\ndisallowmissing!(\n  leftjoin!(\n    bysubj,\n    leftjoin!(\n      rename!(DataFrame(raneftables(elm01)[:subj]), [:subj, :elm01]),\n      rename!(DataFrame(raneftables(elm02)[:subj]), [:subj, :elm02]);\n      on=:subj,\n    ),\n    on=:subj,\n  ); error=false,\n)\ndraw(\n  data(byitem) * mapping(\n    :elm01 =&gt; \"Conditional means of item random effects for model elm01\",\n    :elm02 =&gt; \"Conditional means of item random effects for model elm02\";\n    color=:isword,\n  ) * visual(Scatter; alpha=0.2);\n  axis=(; width=600, height=600),\n)\n\n\n\n\n\nFigure 11: Conditional means of scalar random effects for item in model elm01, fit to the pruned data, versus those for model elm02, fit to the pruned data with inaccurate subjects removed.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAdjust the alpha on Figure 11.\n\n\nFigure 11 is exactly of the form that would be expected in a sample from a correlated multivariate Gaussian distribution. The correlation of the two sets of conditional means is about 96%.\n\ncor(Matrix(select(byitem, :elm01, :elm02)))\n\n2×2 Matrix{Float64}:\n 1.0       0.958655\n 0.958655  1.0\n\n\nThese models take only a few seconds to fit on a modern laptop computer, which is quite remarkable given the size of the data set and the number of random effects.\nThe amount of time to fit more complex models will be much greater so we may want to move those fits to more powerful server computers. We can split the tasks of fitting and analyzing a model between computers by saving the optimization summary after the model fit and later creating the MixedModel object followed by restoring the optsum object.\n\nsaveoptsum(\"./fits/elm01.json\", elm01);\n\n\nelm01a = restoreoptsum!(\n  let\n    form = @formula(\n      1000 / rt ~ 1 + isword * wrdlen + (1 | item) + (1 | subj)\n    )\n    MixedModel(form, pruned; contrasts)\n  end,\n  \"./fits/elm01.json\",\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_item\nσ_subj\n\n\n\n\n(Intercept)\n1.3758\n0.0090\n153.69\n&lt;1e-99\n0.1185\n0.2550\n\n\nisword: true\n0.0625\n0.0005\n131.35\n&lt;1e-99\n\n\n\n\nwrdlen(centered: 8)\n-0.0436\n0.0002\n-225.38\n&lt;1e-99\n\n\n\n\nisword: true & wrdlen(centered: 8)\n-0.0056\n0.0002\n-28.83\n&lt;1e-99\n\n\n\n\nResidual\n0.3781\n\n\n\n\n\n\n\n\n\n\nOther covariates associated with the item are available as\n\nelpldtitem = DataFrame(Arrow.Table(datadir(\"ELP_ldt_item.arrow\")))\ndescribe(elpldtitem)\n\n9×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nType\n\n\n\n\n1\nitem\n\nAarod\n\nzuss\n0\nString\n\n\n2\nOrtho_N\n1.53309\n0\n1.0\n25\n0\nInt8\n\n\n3\nBG_Sum\n13938.4\n11\n13026.0\n59803\n177\nUnion{Missing, Int32}\n\n\n4\nBG_Mean\n1921.25\n5.5\n1907.0\n6910.0\n177\nUnion{Missing, Float32}\n\n\n5\nBG_Freq_By_Pos\n2043.08\n0\n1928.0\n6985\n4\nUnion{Missing, Int16}\n\n\n6\nitemno\n40481.5\n1\n40481.5\n80962\n0\nInt32\n\n\n7\nisword\n0.5\nfalse\n0.5\ntrue\n0\nBool\n\n\n8\nwrdlen\n7.9988\n1\n8.0\n21\n0\nInt8\n\n\n9\npairno\n20241.0\n1\n20241.0\n40481\n0\nInt32\n\n\n\n\n\n\nand those associated with the subject are\n\nelpldtsubj = DataFrame(Arrow.Table(datadir(\"ELP_ldt_subj.arrow\")))\ndescribe(elpldtsubj)\n\n20×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nAny\nAny\nInt64\nType\n\n\n\n\n1\nsubj\n409.311\n1\n409.5\n816\n0\nInt16\n\n\n2\nuniv\n\nKansas\n\nWayne State\n0\nString\n\n\n3\nsex\n\nf\n\nm\n8\nUnion{Missing, String}\n\n\n4\nDOB\n\n1938-06-07\n\n1984-11-14\n0\nDate\n\n\n5\nMEQ\n44.4932\n19.0\n44.0\n75.0\n8\nUnion{Missing, Float32}\n\n\n6\nvision\n5.51169\n0\n6.0\n7\n1\nUnion{Missing, Int8}\n\n\n7\nhearing\n5.86101\n0\n6.0\n7\n1\nUnion{Missing, Int8}\n\n\n8\neducatn\n8.89681\n1\n12.0\n28\n0\nInt8\n\n\n9\nncorrct\n29.8505\n5\n30.0\n40\n18\nUnion{Missing, Int8}\n\n\n10\nrawscor\n31.9925\n13\n32.0\n40\n18\nUnion{Missing, Int8}\n\n\n11\nvocabAge\n17.8123\n10.3\n17.8\n21.0\n19\nUnion{Missing, Float32}\n\n\n12\nshipTime\n3.0861\n0\n3.0\n9\n1\nUnion{Missing, Int8}\n\n\n13\nreadTime\n2.50215\n0.0\n2.0\n15.0\n1\nUnion{Missing, Float32}\n\n\n14\npreshlth\n5.48708\n0\n6.0\n7\n1\nUnion{Missing, Int8}\n\n\n15\npasthlth\n4.92989\n0\n5.0\n7\n1\nUnion{Missing, Int8}\n\n\n16\nS1start\n\n2001-03-16T13:49:27\n2001-10-16T11:38:28.500\n2003-07-29T18:48:44\n0\nDateTime\n\n\n17\nS2start\n\n2001-03-19T10:00:35\n2001-10-19T14:24:19.500\n2003-07-30T13:07:45\n0\nDateTime\n\n\n18\nMEQstrt\n\n2001-03-22T18:32:00\n2001-10-23T11:26:13\n2003-07-30T14:30:49\n7\nUnion{Missing, DateTime}\n\n\n19\nfilename\n\n101DATA.LDT\n\nData998.LDT\n0\nString\n\n\n20\nfrstLang\n\nEnglish\n\nother\n8\nUnion{Missing, String}\n\n\n\n\n\n\nFor the simple model elm01 the estimated standard deviation of the random effects for subject is greater than that of the random effects for item, a common occurrence. A caterpillar plot, Figure 12,\n\n\nCode\nqqcaterpillar!(\n  Figure(resolution=(800, 650)),\n  ranefinfo(elm01, :subj),\n)\n\n\n\n\n\nFigure 12: Conditional means and 95% prediction intervals for subject random effects in elm01.\n\n\n\n\nshows definite distinctions between subjects because the widths of the prediction intervals are small compared to the range of the conditional modes. Also, there is at least one outlier with a conditional mode over 1.0.\nFigure 13 is the corresponding caterpillar plot for model elm02 fit to the data with inaccurate responders eliminated.\n\n\nCode\nqqcaterpillar!(\n  Figure(resolution=(800, 650)),\n  ranefinfo(elm02, :subj),\n)\n\n\n\n\n\nFigure 13: Conditional means and 95% prediction intervals for subject random effects in elm02."
  },
  {
    "objectID": "largescaledesigned.html#random-effects-from-the-simple-model-related-to-covariates",
    "href": "largescaledesigned.html#random-effects-from-the-simple-model-related-to-covariates",
    "title": "A large-scale designed experiment",
    "section": "Random effects from the simple model related to covariates",
    "text": "Random effects from the simple model related to covariates\nThe random effects “estimates” (technically they are “conditional means”) from the simple model elm01 provide a measure of how much the item or subject differs from the population. (We use elm01 because the main difference between elm01 and elm02 are that some subjects were dropped before fitting elm02.)\nFor the item its length and word/non-word status have already been incorporated in the model. At this point the subjects are just being treated as a homogeneous population.\nThe random effects conditional means have been extracted and incorporated in the byitem and bysubj tables. Now add selected demographic and item-specific measures.\n\nitemextended = leftjoin(\n  byitem,\n  select(elpldtitem, 1:5);\n  on = :item,\n)\nsubjextended = leftjoin(\n  bysubj,\n  select(elpldtsubj, 1:3, :vocabAge);\n  on=:subj,\n)\n\n814×11 DataFrame789 rows omitted\n\n\n\nRow\nsubj\nns\nsmiss\nsacc\nsmedianrt\nspropacc\nelm01\nelm02\nuniv\nsex\nvocabAge\n\n\n\nInt16\nInt64\nInt64\nInt64\nFloat64\nFloat64\nFloat64\nFloat64?\nString?\nString?\nFloat32?\n\n\n\n\n1\n1\n3374\n0\n3158\n554.0\n0.935981\n0.411459\n0.426624\nMorehead\nm\n19.8\n\n\n2\n2\n3372\n1\n3031\n960.0\n0.898873\n-0.30907\n-0.293732\nMorehead\nf\n17.8\n\n\n3\n3\n3372\n3\n3006\n813.0\n0.891459\n-0.153078\n-0.139436\nMorehead\nf\n18.2\n\n\n4\n4\n3374\n1\n3062\n619.0\n0.907528\n0.213047\n0.22754\nMorehead\nf\n18.6\n\n\n5\n5\n3374\n0\n2574\n677.0\n0.762893\n0.0850349\nmissing\nMorehead\nf\n16.2\n\n\n6\n6\n3374\n0\n2927\n855.0\n0.867516\n-0.207356\n-0.192651\nMorehead\nf\n17.8\n\n\n7\n7\n3374\n4\n2877\n918.5\n0.852697\n-0.182201\n-0.166357\nMorehead\nf\n17.4\n\n\n8\n8\n3372\n1\n2731\n1310.0\n0.809905\n-0.541434\n-0.526828\nMorehead\nm\n16.2\n\n\n9\n9\n3374\n13\n2669\n657.0\n0.791049\n0.154926\nmissing\nMorehead\nf\n16.6\n\n\n10\n10\n3374\n0\n2722\n757.0\n0.806758\n-0.0541104\n-0.0403266\nMorehead\nf\n17.0\n\n\n11\n11\n3374\n0\n2894\n632.0\n0.857736\n0.217734\n0.231618\nMorehead\nf\n17.4\n\n\n12\n12\n3374\n4\n2979\n692.0\n0.882928\n0.062351\n0.0770981\nMorehead\nm\n18.2\n\n\n13\n13\n3374\n2\n2980\n1114.0\n0.883225\n-0.409761\n-0.3956\nMorehead\nf\n18.2\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n803\n805\n3374\n5\n2881\n534.0\n0.853883\n0.480461\n0.495683\nWash. Univ\nm\n19.0\n\n\n804\n806\n3374\n1\n3097\n841.5\n0.917902\n-0.1888\n-0.173376\nWash. Univ\nm\n19.8\n\n\n805\n807\n3374\n3\n2994\n704.0\n0.887374\n0.01919\n0.0338241\nWash. Univ\nm\n17.4\n\n\n806\n808\n3374\n2\n2751\n630.5\n0.815353\n0.199416\n0.214299\nWash. Univ\nf\n18.6\n\n\n807\n809\n3372\n4\n2603\n627.0\n0.771945\n0.2277\nmissing\nWash. Univ\nm\n15.1\n\n\n808\n810\n3374\n1\n3242\n603.5\n0.960877\n0.252522\n0.266822\nWash. Univ\nm\n19.8\n\n\n809\n811\n3374\n2\n2861\n827.0\n0.847955\n-0.158097\n-0.143568\nWash. Univ\nf\n16.2\n\n\n810\n812\n3372\n6\n3012\n471.0\n0.893238\n0.748427\n0.76354\nWash. Univ\nf\n19.8\n\n\n811\n813\n3372\n4\n2932\n823.0\n0.869514\n-0.167166\n-0.153846\nWash. Univ\nm\n17.4\n\n\n812\n814\n3374\n1\n3070\n773.0\n0.909899\n-0.0753662\n-0.0606956\nWash. Univ\nf\n18.6\n\n\n813\n815\n3374\n1\n3024\n602.0\n0.896266\n0.249134\n0.2643\nWash. Univ\nf\n18.6\n\n\n814\n816\n3374\n0\n2950\n733.0\n0.874333\n-0.0364596\n-0.0222916\nWash. Univ\nf\n17.8\n\n\n\n\n\n\nAs shown in Figure 14, there does not seem to be a strong relationship between vocabulary age and speed of response by subject.\n\n\nCode\ndraw(\n  data(dropmissing(select(subjextended, :elm01, :vocabAge, :sex))) *\n  mapping(\n    :vocabAge =&gt; \"Vocabulary age (yr) of subject\",\n    :elm01 =&gt; \"Random effect in model elm01\";\n    color=:sex,\n  ) * visual(Scatter; alpha=0.6)\n)\n\n\n\n\n\nFigure 14: Random effect for subject in model elm01 versus vocabulary age\n\n\n\n\n\n\nCode\ndraw(\n  data(dropmissing(select(subjextended, :elm01, :univ))) *\n  mapping(\n    :elm01 =&gt; \"Random effect in model elm01\";\n    color=:univ =&gt; \"University\",\n  ) * AlgebraOfGraphics.density()\n)\n\n\n\n\n\nFigure 15: Estimated density of random effects for subject in model elm01 by university\n\n\n\n\n\n\nCode\ndraw(\n  data(dropmissing(select(subjextended, :elm02, :univ))) *\n  mapping(\n    :elm02 =&gt; \"Random effect in model elm02 (accurate responders only)\";\n    color=:univ =&gt; \"University\",\n  ) * AlgebraOfGraphics.density()\n)\n\n\n\n\n\nFigure 16: Estimated density of random effects for subject in model elm02, fit to accurate responders only, by university\n\n\n\n\n\n\nCode\nCairoMakie.activate!(; type=\"png\")\ndraw(\n  data(dropmissing(select(itemextended, :elm01, :BG_Mean, :isword))) *\n  mapping(\n    :BG_Mean =&gt; \"Mean bigram frequency\",\n    :elm01 =&gt; \"Random effect in model elm01\";\n    color=:isword,\n  ) * visual(Scatter; alpha=0.2)\n)\n\n\n\n\n\nFigure 17: Random effect in model elm01 versus mean bigram frequency, by word/nonword status"
  },
  {
    "objectID": "sleepstudy_speed.html",
    "href": "sleepstudy_speed.html",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "",
    "text": "Belenky et al. (2003) reported effects of sleep deprivation across a 14-day study of 30-to-40-year old men and women holding commercial vehicle driving licenses. Their analyses are based on a subset of tasks and ratings from very large and comprehensive test and questionnaire battery (Balkin et al., 2000).\nInitially 66 subjects were assigned to one of four time-in-bed (TIB) groups with 9 hours (22:00-07:00) of sleep augmentation or 7 hours (24:00-07:00), 5 hours (02:00-07:00), and 3 hours (04:00-0:00) of sleep restrictions per night, respectively. The final sample comprised 56 subjects. The Psychomotor Vigilance Test (PVT) measures simple reaction time to a visual stimulus, presented approximately 10 times ⁄ minute (interstimulus interval varied from 2 to 10 s in 2-s increments) for 10 min and implemented in a thumb-operated, hand-held device (Dinges & Powell, 1985).\nDesign\nThe study comprised 2 training days (T1, T2), one day with baseline measures (B), seven days with sleep deprivation (E1 to E7), and four recovery days (R1 to R4). T1 and T2 were devoted to training on the performance tests and familiarization with study procedures. PVT baseline testing commenced on the morning of the third day (B) and testing continued for the duration of the study (E1–E7, R1–R3; no measures were taken on R4). Bed times during T, B, and R days were 8 hours (23:00-07:00).\nTest schedule within days\nThe PVT (along with the Stanford Sleepiness Scale) was administered as a battery four times per day (09:00, 12:00, 15:00, and 21:00 h); the battery included other tests not reported here (see Balkin et al., 2000). The sleep latency test was administered at 09:40 and 15:30 h for all groups. Subjects in the 3- and 5-h TIB groups performed an additional battery at 00:00 h and 02:00 h to occupy their additional time awake. The PVT and SSS were administered in this battery; however, as data from the 00:00 and 02:00 h sessions were not common to all TIB groups, these data were not included in the statistical analyses reported in the paper.\nStatistical analyses\nThe authors analyzed response speed, that is (1/RT)*1000 – completely warranted according to a Box-Cox check of the current data – with mixed-model ANOVAs using group as between- and day as within-subject factors. The ANOVA was followed up with simple tests of the design effects implemented over days for each of the four groups.\nCurrent data\nThe current data distributed with the RData collection is attributed to the 3-hour TIB group, but the means do not agree at all with those reported for this group in (Belenky et al., 2003, fig. 3) where the 3-hour TIB group is also based on only 13 (not 18) subjects. Specifically, the current data show a much smaller slow-down of response speed across E1 to E7 and do not reflect the recovery during R1 to R3. The currrent data also cover only 10 not 11 days, but it looks like only R3 is missing. The closest match of the current means was with the average of the 3-hour and 7-hour TIB groups; if only males were included, this would amount to 18 subjects. (This conjecture is based only on visual inspection of graphs.)"
  },
  {
    "objectID": "sleepstudy_speed.html#background",
    "href": "sleepstudy_speed.html#background",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "",
    "text": "Belenky et al. (2003) reported effects of sleep deprivation across a 14-day study of 30-to-40-year old men and women holding commercial vehicle driving licenses. Their analyses are based on a subset of tasks and ratings from very large and comprehensive test and questionnaire battery (Balkin et al., 2000).\nInitially 66 subjects were assigned to one of four time-in-bed (TIB) groups with 9 hours (22:00-07:00) of sleep augmentation or 7 hours (24:00-07:00), 5 hours (02:00-07:00), and 3 hours (04:00-0:00) of sleep restrictions per night, respectively. The final sample comprised 56 subjects. The Psychomotor Vigilance Test (PVT) measures simple reaction time to a visual stimulus, presented approximately 10 times ⁄ minute (interstimulus interval varied from 2 to 10 s in 2-s increments) for 10 min and implemented in a thumb-operated, hand-held device (Dinges & Powell, 1985).\nDesign\nThe study comprised 2 training days (T1, T2), one day with baseline measures (B), seven days with sleep deprivation (E1 to E7), and four recovery days (R1 to R4). T1 and T2 were devoted to training on the performance tests and familiarization with study procedures. PVT baseline testing commenced on the morning of the third day (B) and testing continued for the duration of the study (E1–E7, R1–R3; no measures were taken on R4). Bed times during T, B, and R days were 8 hours (23:00-07:00).\nTest schedule within days\nThe PVT (along with the Stanford Sleepiness Scale) was administered as a battery four times per day (09:00, 12:00, 15:00, and 21:00 h); the battery included other tests not reported here (see Balkin et al., 2000). The sleep latency test was administered at 09:40 and 15:30 h for all groups. Subjects in the 3- and 5-h TIB groups performed an additional battery at 00:00 h and 02:00 h to occupy their additional time awake. The PVT and SSS were administered in this battery; however, as data from the 00:00 and 02:00 h sessions were not common to all TIB groups, these data were not included in the statistical analyses reported in the paper.\nStatistical analyses\nThe authors analyzed response speed, that is (1/RT)*1000 – completely warranted according to a Box-Cox check of the current data – with mixed-model ANOVAs using group as between- and day as within-subject factors. The ANOVA was followed up with simple tests of the design effects implemented over days for each of the four groups.\nCurrent data\nThe current data distributed with the RData collection is attributed to the 3-hour TIB group, but the means do not agree at all with those reported for this group in (Belenky et al., 2003, fig. 3) where the 3-hour TIB group is also based on only 13 (not 18) subjects. Specifically, the current data show a much smaller slow-down of response speed across E1 to E7 and do not reflect the recovery during R1 to R3. The currrent data also cover only 10 not 11 days, but it looks like only R3 is missing. The closest match of the current means was with the average of the 3-hour and 7-hour TIB groups; if only males were included, this would amount to 18 subjects. (This conjecture is based only on visual inspection of graphs.)"
  },
  {
    "objectID": "sleepstudy_speed.html#setup",
    "href": "sleepstudy_speed.html#setup",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "Setup",
    "text": "Setup\nFirst we attach the various packages needed, define a few helper functions, read the data, and get everything in the desired shape.\n\n\nCode\nusing CairoMakie         # device driver for static (SVG, PDF, PNG) plots\nusing Chain              # like pipes but cleaner\nusing DataFrameMacros\nusing DataFrames\nusing MixedModels\nusing MixedModelsMakie   # plots specific to mixed-effects models using Makie\n\nusing ProgressMeter\n\nCairoMakie.activate!(; type=\"svg\")\nProgressMeter.ijulia_behavior(:clear);"
  },
  {
    "objectID": "sleepstudy_speed.html#preprocessing",
    "href": "sleepstudy_speed.html#preprocessing",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe sleepstudy data are one of the datasets available with recent versions of the MixedModels package. We carry out some preprocessing to have the dataframe in the desired shape:\n\nCapitalize random factor Subj\nCompute speed as an alternative dependent variable from reaction, warranted by a ‘boxcox’ check of residuals.\nCreate a GroupedDataFrame by levels of Subj (the original dataframe is available as gdf.parent, which we name df)\n\n\ngdf = @chain MixedModels.dataset(:sleepstudy) begin\n  DataFrame\n  rename!(:subj =&gt; :Subj, :days =&gt; :day)\n  @transform!(:speed = 1000 / :reaction)\n  groupby(:Subj)\nend\n\nGroupedDataFrame with 18 groups based on key: SubjFirst Group (10 rows): Subj = \"S308\"\n\n\n\nRow\nSubj\nday\nreaction\nspeed\n\n\n\nString\nInt8\nFloat64\nFloat64\n\n\n\n\n1\nS308\n0\n249.56\n4.00705\n\n\n2\nS308\n1\n258.705\n3.86541\n\n\n3\nS308\n2\n250.801\n3.98723\n\n\n4\nS308\n3\n321.44\n3.111\n\n\n5\nS308\n4\n356.852\n2.80228\n\n\n6\nS308\n5\n414.69\n2.41144\n\n\n7\nS308\n6\n382.204\n2.61641\n\n\n8\nS308\n7\n290.149\n3.44651\n\n\n9\nS308\n8\n430.585\n2.32242\n\n\n10\nS308\n9\n466.353\n2.1443\n\n\n\n⋮\n\n\nLast Group (10 rows): Subj = \"S372\"\n\n\n\n\n\n\n\n\n\nRow\nSubj\nday\nreaction\nspeed\n\n\n\nString\nInt8\nFloat64\nFloat64\n\n\n\n\n1\nS372\n0\n269.412\n3.71179\n\n\n2\nS372\n1\n273.474\n3.65665\n\n\n3\nS372\n2\n297.597\n3.36025\n\n\n4\nS372\n3\n310.632\n3.21925\n\n\n5\nS372\n4\n287.173\n3.48223\n\n\n6\nS372\n5\n329.608\n3.03391\n\n\n7\nS372\n6\n334.482\n2.9897\n\n\n8\nS372\n7\n343.22\n2.91358\n\n\n9\nS372\n8\n369.142\n2.70899\n\n\n10\nS372\n9\n364.124\n2.74632\n\n\n\n\n\n\n\n\ndf = gdf.parent\ndescribe(df)\n\n4×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nSubj\n\nS308\n\nS372\n0\nString\n\n\n2\nday\n4.5\n0\n4.5\n9\n0\nInt8\n\n\n3\nreaction\n298.508\n194.332\n288.651\n466.353\n0\nFloat64\n\n\n4\nspeed\n3.46634\n2.1443\n3.46443\n5.14583\n0\nFloat64"
  },
  {
    "objectID": "sleepstudy_speed.html#estimates-for-pooled-data",
    "href": "sleepstudy_speed.html#estimates-for-pooled-data",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "Estimates for pooled data",
    "text": "Estimates for pooled data\nIn the first analysis we ignore the dependency of observations due to repeated measures from the same subjects. We pool all the data and estimate the regression of 180 speed scores on the nine days of the experiment.\n\npooledcoef = simplelinreg(df.day, df.speed)  # produces a Tuple\n\n(3.9658119747831484, -0.110993592321997)"
  },
  {
    "objectID": "sleepstudy_speed.html#within-subject-effects",
    "href": "sleepstudy_speed.html#within-subject-effects",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "Within-subject effects",
    "text": "Within-subject effects\nIn the second analysis we estimate coefficients for each Subj without regard of the information available from the complete set of data. We do not “borrow strength” to adjust for differences due to between-Subj variability and due to being far from the population mean.\n\nWithin-subject simple regressions\nApplying combine to a grouped data frame like gdf produces a DataFrame with a row for each group. The permutation ord provides an ordering for the groups by increasing intercept (predicted response at day 0).\n\nwithin = combine(gdf, [:day, :speed] =&gt; simplelinreg =&gt; :coef)\n\n18×2 DataFrame\n\n\n\nRow\nSubj\ncoef\n\n\n\nString\nTuple…\n\n\n\n\n1\nS308\n(3.94806, -0.194812)\n\n\n2\nS309\n(4.87022, -0.0475185)\n\n\n3\nS310\n(4.90606, -0.120054)\n\n\n4\nS330\n(3.4449, -0.0291309)\n\n\n5\nS331\n(3.47647, -0.0498047)\n\n\n6\nS332\n(3.84436, -0.105511)\n\n\n7\nS333\n(3.60159, -0.0917378)\n\n\n8\nS334\n(4.04528, -0.133527)\n\n\n9\nS335\n(3.80451, 0.0455771)\n\n\n10\nS337\n(3.34374, -0.137744)\n\n\n11\nS349\n(4.46855, -0.170885)\n\n\n12\nS350\n(4.21414, -0.20151)\n\n\n13\nS351\n(3.80469, -0.0728582)\n\n\n14\nS352\n(3.68634, -0.144957)\n\n\n15\nS369\n(3.85384, -0.120531)\n\n\n16\nS370\n(4.52679, -0.215965)\n\n\n17\nS371\n(3.853, -0.0936243)\n\n\n18\nS372\n(3.69208, -0.113292)\n\n\n\n\n\n\nFigure 1 shows the reaction speed versus days of sleep deprivation by subject. The panels are arranged by increasing initial reaction speed starting at the lower left and proceeding across rows.\n\n\nCode\nlet\n  ord = sortperm(first.(within.coef))\n  labs = values(only.(keys(gdf)))[ord]       # labels for panels\n  f = clevelandaxes!(Figure(; resolution=(1000, 750)), labs, (2, 9))\n  for (axs, sdf) in zip(f.content, gdf[ord]) # iterate over the panels and groups\n    scatter!(axs, sdf.day, sdf.speed)      # add the points\n    coef = simplelinreg(sdf.day, sdf.speed)\n    abline!(axs, first(coef), last(coef))  # add the regression line\n  end\n  f\nend\n\n\n┌ Warning: abline! is deprecated and will be removed in the future. Use ablines / ablines! instead.\n│   caller = top-level scope at In[7]:8\n└ @ Core ./In[7]:8\n\n\n\n\n\nFigure 1: Reaction speed (s⁻¹) versus days of sleep deprivation by subject"
  },
  {
    "objectID": "sleepstudy_speed.html#basic-lmm",
    "href": "sleepstudy_speed.html#basic-lmm",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "Basic LMM",
    "text": "Basic LMM\n\ncontrasts = Dict(:Subj =&gt; Grouping())\nm1 = let\n  form = @formula speed ~ 1 + day + (1 + day | Subj)\n  fit(MixedModel, form, df; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n3.9658\n0.1056\n37.55\n&lt;1e-99\n0.4190\n\n\nday\n-0.1110\n0.0151\n-7.37\n&lt;1e-12\n0.0566\n\n\nResidual\n0.2698\n\n\n\n\n\n\n\n\n\nThis model includes fixed effects for the intercept which estimates the average speed on the baseline day of the experiment prior to sleep deprivation, and the slowing per day of sleep deprivation. In this case about -0.11/second.\nThe random effects represent shifts from the typical behavior for each subject.The shift in the intercept has a standard deviation of about 0.42/s.\nThe within-subject correlation of the random effects for intercept and slope is small, -0.18, indicating that a simpler model with a correlation parameter (CP) forced to/ assumed to be zero may be sufficient."
  },
  {
    "objectID": "sleepstudy_speed.html#no-correlation-parameter-zcp-lmm",
    "href": "sleepstudy_speed.html#no-correlation-parameter-zcp-lmm",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "No correlation parameter: zcp LMM",
    "text": "No correlation parameter: zcp LMM\nThe zerocorr function applied to a random-effects term estimates one parameter less than LMM m1– the CP is now fixed to zero.\n\nm2 = let\n  form = @formula speed ~ 1 + day + zerocorr(1 + day | Subj)\n  fit(MixedModel, form, df; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n3.9658\n0.1033\n38.38\n&lt;1e-99\n0.4085\n\n\nday\n-0.1110\n0.0147\n-7.53\n&lt;1e-13\n0.0550\n\n\nResidual\n0.2706\n\n\n\n\n\n\n\n\n\nLMM m2 has a slghtly lower log-likelihood than LMM m1 but also one fewer parameters. A likelihood-ratio test is used to compare these nested models.\n\n\nCode\nMixedModels.likelihoodratiotest(m2, m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nspeed ~ 1 + day + zerocorr(1 + day | Subj)\n5\n125\n\n\n\n\n\nspeed ~ 1 + day + (1 + day | Subj)\n6\n125\n0\n1\n0.5192\n\n\n\n\n\nAlternatively, the AIC, AICc, and BIC values can be compared. They are on a scale where “smaller is better”. All three model-fit statistics prefer the zcpLMM m2.\n\n\nCode\nlet\n  mods = [m2, m1]\n  DataFrame(;\n    dof=dof.(mods),\n    deviance=deviance.(mods),\n    AIC=aic.(mods),\n    AICc=aicc.(mods),\n    BIC=bic.(mods),\n  )\nend\n\n\n2×5 DataFrame\n\n\n\nRow\ndof\ndeviance\nAIC\nAICc\nBIC\n\n\n\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n5\n125.379\n135.379\n135.724\n151.344\n\n\n2\n6\n124.964\n136.964\n137.45\n156.122"
  },
  {
    "objectID": "sleepstudy_speed.html#conditional-modes-of-the-random-effects",
    "href": "sleepstudy_speed.html#conditional-modes-of-the-random-effects",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "Conditional modes of the random effects",
    "text": "Conditional modes of the random effects\nThe third set of estimates are their conditional modes. They represent a compromise between their own data and the model parameters. When distributional assumptions hold, predictions based on these estimates are more accurate than either the pooled or the within-subject estimates. Here we “borrow strength” to improve the accuracy of prediction."
  },
  {
    "objectID": "sleepstudy_speed.html#caterpillar-plots-effect-profiles",
    "href": "sleepstudy_speed.html#caterpillar-plots-effect-profiles",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "Caterpillar plots (effect profiles)",
    "text": "Caterpillar plots (effect profiles)\n\n\nCode\ncaterpillar(m2)\n\n\n\n\n\nFigure 2: Prediction intervals on the random effects in model m2"
  },
  {
    "objectID": "sleepstudy_speed.html#shrinkage-plot",
    "href": "sleepstudy_speed.html#shrinkage-plot",
    "title": "The sleepstudy: Speed - for a change …",
    "section": "Shrinkage plot",
    "text": "Shrinkage plot\n\n\nCode\nshrinkageplot!(Figure(; resolution=(500, 500)), m2)\n\n\n\n\n\nFigure 3: Shrinkage plot of the means of the random effects in model m2"
  },
  {
    "objectID": "pkg.html",
    "href": "pkg.html",
    "title": "Package management and reproducible environments",
    "section": "",
    "text": "Julius Krumbiegel also has a great blog post with more details on Julia environments.\nJulia packages can be configured (in a file called Project.toml) on a per-project basis. The packaged sources and compiled versions are stored in a central location, e.g. ~/.julia/packages and ~/.julia/compiled on Linux systems, but the configuration of packages to be used can be local to a project. The Pkg package is used to modify the local project’s configuration. (An alternative is “package mode” in the read-eval-print-loop or REPL, which we will show at the summer school.) Start julia in the directory of the cloned SMLP2022 repository\n\nusing Pkg        # there's a package called 'Pkg' to manipulate package configs\nPkg.activate(\".\")# activate the current directory as the project\n\nIf you’ve recieved an environment from someone/somwhere else – such as this course repository – then you’ll need to first “instantiate” it (i.e., install all the dependencies).\n\nPkg.instantiate()# only needed the first time you work in a project\nPkg.update()     # get the latest package versions compatible with the project\n\n\nPkg.status()\n\nOccasionally the Pkg.status function call will give info about new versions being available but blocked by requirements of other packages. This is to be expected - the package system is large and the web of dependencies are complex. Generally the Julia package system is very good at resolving dependencies."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Seventh Summer School on Statistical Methods for Linguistics and Psychology",
    "section": "",
    "text": "This site provides materials for the Advanced frequentist methods stream of the Summer School on Statistical Methods to be held at the University of Potsdam, 11-15 September, 2023."
  },
  {
    "objectID": "index.html#git",
    "href": "index.html#git",
    "title": "Seventh Summer School on Statistical Methods for Linguistics and Psychology",
    "section": "1.1 git",
    "text": "1.1 git\nWe will assume that you have git installed and are able to clone a repository from github. If not, Happy Git with R is a good place to learn about git for data science.\nThis website is built using quarto, described below, from the repository. Clone this repository with, e.g.\ngit clone https://github.com/RePsychLing/SMLP2023"
  },
  {
    "objectID": "index.html#julia-programming-language",
    "href": "index.html#julia-programming-language",
    "title": "Seventh Summer School on Statistical Methods for Linguistics and Psychology",
    "section": "1.2 Julia Programming Language",
    "text": "1.2 Julia Programming Language\nWe will use Julia v1.9.2 in the summer school. We recommend using Juliaup to install and manage Julia versions. Juliaup makes it trivial to upgrade to new Julia releases or even use old ones. Alternatively, you can download the version appropriate for your setup from here: Julia Programming Language"
  },
  {
    "objectID": "index.html#visual-studio-code-vs-code",
    "href": "index.html#visual-studio-code-vs-code",
    "title": "Seventh Summer School on Statistical Methods for Linguistics and Psychology",
    "section": "1.3 Visual Studio Code (VS Code)",
    "text": "1.3 Visual Studio Code (VS Code)\nWe will use VS Code IDE, that is Julia : VS Code ~ R : RStudio. You can download the version appropriate for your setup from here: VS Code"
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "Seventh Summer School on Statistical Methods for Linguistics and Psychology",
    "section": "1.4 Quarto",
    "text": "1.4 Quarto\nThe web site and other documents for this course are rendered using a knitr-like system called Quarto. You can download the version appropriate for your setup from here: quarto"
  },
  {
    "objectID": "useful_packages.html",
    "href": "useful_packages.html",
    "title": "Useful packages",
    "section": "",
    "text": "Unlike R, Julia does not immediately expose a huge number of functions, but instead requires loading packages (whether from the standard library or from the broader package ecosystem) for a lot of relevant functionality for statistical analysis. There are technical reasons for this, but one further motivation is that Julia is at a broader “technical computing” audience (like MATLAB or perhaps Python) and less at a “statistical analysis” audience.\nThis has two important implications:\nThis notebook is not intended to be an exhaustive list of packages, but rather to highlight a few packages that I suspect will be particularly useful. Before getting onto the packages, I have one final hint: take advantage of how easy and first-class package management in Julia is. Having good package management makes reproducible analyses much easier and avoids breaking old analyses when you start a new one. Pluto helpfully installs and manages for you, but the package-manager REPL mode (activated by typing ] at the julia&gt; prompt) is very useful."
  },
  {
    "objectID": "useful_packages.html#data-wrangling",
    "href": "useful_packages.html#data-wrangling",
    "title": "Useful packages",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nReading data\n\nArrow.jl a high performance format for data storage, accessible in R via the arrow package and in Python via pyarrow. (Confusingly, the function for reading and writing Arrow format files in R is called read_feather and write_feather, but the modern Arrow format is distinct from the older Feather format provided by the feather package.) This is the format that we store the example and test datasets in for MixedModels.jl.\nCSV.jl useful for reading comma-separated values, tab-separated values and basically everything handled by the read.csv and read.table family of functions in R.\n\nNote that by default both Arrow.jl and CSV.jl do not return a DataFrame, but rather “column tables” – named tuples of column vectors.\n\n\nDataFrames\nUnlike in R, DataFrames are not part of the base language, nor the standard library.\nDataFrames.jl provides the basic infrastructure around DataFrames, as well as its own mini language for doing the split-apply-combine approach that underlies R’s dplyr and much of the tidyverse. The DataFrames.jl documentation is the place to for looking at how to e.g. read in a CSV or Arrow file as a DataFrame. Note that DataFrames.jl by default depends on CategoricalArrays.jl to handle the equivalent of factor in the R world, but there is an alternative package for factor-like array type in Julia, PooledArrays.jl. PooledArrays are simpler, but more limited than CategoricalArrays and we (Phillip and Doug) sometimes use them in our examples and simulations.\nDataFrame.jl’s mini language can be a bit daunting, if you’re used to manipulations in the style of base R or the tidyverse. For that, there are several options; recently, we’e had particularly nice experiences with DataFrameMacros.jl and Chain.jl for a convenient syntax to connect or “pipe” together successive operations. It’s your choice whether and which of these add-ons you want to use! Phillip tends to write his code using raw DataFrames.jl, but Doug really enjoys DataFrameMacros.jl."
  },
  {
    "objectID": "useful_packages.html#regression",
    "href": "useful_packages.html#regression",
    "title": "Useful packages",
    "section": "Regression",
    "text": "Regression\nUnlike in R, neither formula processing nor basic regression are part of the base language or the standard library.\nThe formula syntax and basic contrast-coding schemes in Julia is provided by StatsModels.jl. By default, MixedModels.jl re-exports the @formula macro and most commonly used contrast schemes from StatsModels.jl, so you often don’t have to worry about loading StatsModels.jl directly. The same is true for GLM.jl, which provides basic linear and generalized linear models, such as ordinary least squares (OLS) regression and logistic regression, i.e. the classical, non mixed regression models.\nThe basic functionality looks quite similar to R, e.g.\njulia &gt; lm(@formula(y ~ 1 + x), data)\njulia &gt; glm(@formula(y ~ 1 + x), data, Binomial(), LogitLink())\nbut the more general modelling API (also used by MixedModels.jl) is also supported:\njulia &gt; fit(LinearModel, @formula(y ~ 1 + x), mydata)\njulia &gt; fit(\n  GeneralizedLinearModel,\n  @formula(y ~ 1 + x),\n  data,\n  Binomial(),\n  LogitLink(),\n)\n(You can also specify your model matrices directly and skip the formula interface, but we don’t recommend this as it’s easy to mess up in really subtle but very probelmatic ways.)\n\n@formula, macros and domain-specific languages\nAs a sidebar: why is @formula a macro and not a normal function? Well, that’s because formulas are essentially their own domain-specific language (a variant of Wilkinson-Roger notation) and macros are used for manipulating the language itself – or in this case, handling an entirely new, embedded language! This is also why macros are used by packages like Turing.jl and Soss.jl that define a language for Bayesian probabilistic programming like PyMC3 or Stan.\n\n\nExtensions to the formula syntax\nThere are several ongoing efforts to extend the formula syntax to include some of the “extras” available in R, e.g. RegressionFormulae.jl to use the caret (^) notation to limit interactions to a certain order ((a+b+c)^2 generates a + b + c + a&b + a&c + b&c, but not a&b&c). Note also that Julia uses & to express interactions, not : like in R.\n\n\nStandardizing Predictors\nAlthough function calls such as log can be used within Julia formulae, they must act on a rowwise basis, i.e. on observations. Transformations such as z-scoring or centering (often done with scale in R) require knowledge of the entire column. StandardizedPredictors.jl provides functions for centering, scaling, and z-scoring within the formula. These are treated as pseudo-contrasts and computed on demand, meaning that predict and effects (see next) computations will handle these transformations on new data (e.g. centering new data around the mean computed during fitting the original data) correctly and automatically.\n\n\nEffects\nJohn Fox’s effects package in R (and the related ggeffects package for plotting these using ggplot2) provides a nice way to visualize a model’s overall view of the data. This functionality is provided by Effects.jl and works out-of-the-box with most regression model packages in Julia (including MixedModels.jl). Support for formulae with embedded functions (such as log) is not yet complete, but we’re working on it!\n\n\nEstimated Marginal / Least Square Means\nEffects.jl provides a subset of the functionality (basic estimated-marginal means and exhaustive pairwise comparisons) of the R package emmeans package. However, it is often better to use sensible, hypothesis-driven contrast coding than to compute all pairwise comparisons after the fact. 😃"
  },
  {
    "objectID": "useful_packages.html#hypothesis-testing",
    "href": "useful_packages.html#hypothesis-testing",
    "title": "Useful packages",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\nClassical statistical tests such as the t-test can be found in the package HypothesisTests.jl."
  },
  {
    "objectID": "useful_packages.html#plotting-ecosystem",
    "href": "useful_packages.html#plotting-ecosystem",
    "title": "Useful packages",
    "section": "Plotting ecosystem",
    "text": "Plotting ecosystem\nThroughtout this course, we have used the Makie ecosystem for plotting, but there are several alternatives in Julia.\n\nMakie\nThe Makie ecosystem is a relatively new take on graphics that aims to be both powerful and easy to use. Makie.jl itself only provides abstract definitions for many components (and is used in e.g. MixedModelsMakie.jl to define plot types for MixedModels.jl). The actual plotting and rendering is handled by a backend package such as CairoMakie.jl (good for Quarto notebooks or rending static 2D images) and GLMakie.jl (good for dynamic, interactive visuals and 3D images). AlgebraOfGraphics.jl builds a grammar of graphics upon the Makie framework. It’s a great way to get good plots very quickly, but extensive customization is still best achieved by using Makie directly.\n\n\nPlots.jl\nPlots.jl is the original plotting package in Julia, but we often find it difficult to work with compared to some of the other alternatives. StatsPlots.jl builds on this, adding common statistical plots, while UnicodePlots.jl renders plots as Unicode characters directly in the REPL.\nPGFPlotsX.jl is a very new package that writes directly to PGF (the format used by LaTeX’s tikz framework) and can stand alone or be used as a rendering backend for the Plots.jl ecosystem.\n\n\nGadfly\nGadfly.jl was the original attempt to create a plotting system in Julia based on the grammar of graphics (the “gg” in ggplot2). Development has largely stalled, but some functionality still exceeds AlgebraOfGraphics.jl, which has taken up the grammar of graphics mantle. Notably, the MixedModels.jl documentation still uses Gadfly as of this writing (early September 2021).\n\n\nOthers\nThere are many other graphics packages available in Julia, often wrapping well-established frameworks such as VegaLite."
  },
  {
    "objectID": "useful_packages.html#connecting-to-other-languages",
    "href": "useful_packages.html#connecting-to-other-languages",
    "title": "Useful packages",
    "section": "Connecting to Other Languages",
    "text": "Connecting to Other Languages\nUsing Julia doesn’t mean you have to leave all the packages you knew in other languages behind. In Julia, it’s often possible to even easily and quickly invoke code from other languages from within Julia.\nRCall.jl provides a very convenient interface for interacting with R. JellyMe4.jl add support for moving MixedModels.jl and lme4 models back and forth between the languages (which means that you can use emmeans, sjtools, DHARMa, car, etc. to examine MixedModels.jl models!). RData.jl provides support for reading .rds and .rda files from Julia, while RDatasets.jl provides convenient access to many of the standard datasets provided by R and various R packages.\nPyCall.jl provides a very convenient way for interacting with Python code and packages. PyPlot.jl builds upon this foundation to provide support for Python’s matplotlib. Similarly, PyMNE.jl and PyFOOOF.jl provide some additional functionality to make interacting with MNE-Python and FOOOF from within Julia even easier than with vanilla PyCall. More recently, PythonCall.jl has proven to be a populat alternative to PyCall.jl.\nFor MATLAB users, there is also MATLAB.jl\nCxx.jl provides interoperability with C++. It also provides a C++ REPL mode, making it possible to treating C++ much more like a dynamic language than the traditional compiler toolchain would allow.\nSupport for calling C and Fortran is part of the Julia standard library."
  },
  {
    "objectID": "sleepstudy.html",
    "href": "sleepstudy.html",
    "title": "Analysis of the sleepstudy data",
    "section": "",
    "text": "The sleepstudy data are from a study of the effects of sleep deprivation on response time reported in Balkin et al. (2000) and in Belenky et al. (2003). Eighteen subjects were allowed only 3 hours of time to sleep each night for 9 successive nights. Their reaction time was measured each day, starting the day before the first night of sleep deprivation, when the subjects were on their regular sleep schedule."
  },
  {
    "objectID": "sleepstudy.html#loading-the-data",
    "href": "sleepstudy.html#loading-the-data",
    "title": "Analysis of the sleepstudy data",
    "section": "Loading the data",
    "text": "Loading the data\nFirst attach the MixedModels package and other packages for plotting. The CairoMakie package allows the Makie graphics system (Danisch & Krumbiegel, 2021) to generate high quality static images. Activate that package with the SVG (Scalable Vector Graphics) backend.\n\n\nCode\nusing CairoMakie       # graphics back-end\nusing DataFrameMacros  # simplified dplyr-like data wrangling\nusing DataFrames\nusing KernelDensity    # density estimation\nusing MixedModels\nusing MixedModelsMakie # diagnostic plots\nusing ProgressMeter\nusing Random           # random number generators\nusing RCall            # call R from Julia\n\nProgressMeter.ijulia_behavior(:clear);\nCairoMakie.activate!(; type=\"svg\");\n\n\nThe sleepstudy data are one of the datasets available with the MixedModels package.\n\nsleepstudy = MixedModels.dataset(\"sleepstudy\")\n\nArrow.Table with 180 rows, 3 columns, and schema:\n :subj      String\n :days      Int8\n :reaction  Float64\n\n\nFigure 1 displays the data in a multi-panel plot created with the lattice package in R (Sarkar, 2008), using RCall.jl.\n\n\nCode\nRCall.ijulia_setdevice(MIME(\"image/svg+xml\"); width=10, height=4.5)\nR\"\"\"\nrequire(\"lattice\", quietly=TRUE)\nprint(xyplot(reaction ~ days | subj,\n  $(DataFrame(sleepstudy)),\n  aspect=\"xy\",\n  layout=c(9,2),\n  type=c(\"g\", \"p\", \"r\"),\n  index.cond=function(x,y) coef(lm(y ~ x))[1],\n  xlab = \"Days of sleep deprivation\",\n  ylab = \"Average reaction time (ms)\"\n))\n\"\"\";\n\n\n\n\n\nFigure 1: Average response time versus days of sleep deprivation by subject\n\n\n\n\nEach panel shows the data from one subject and a line fit by least squares to that subject’s data. Starting at the lower left panel and proceeding across rows, the panels are ordered by increasing intercept of the least squares line.\nThere are some deviations from linearity within the panels but the deviations are neither substantial nor systematic."
  },
  {
    "objectID": "sleepstudy.html#fitting-an-initial-model",
    "href": "sleepstudy.html#fitting-an-initial-model",
    "title": "Analysis of the sleepstudy data",
    "section": "Fitting an initial model",
    "text": "Fitting an initial model\n\ncontrasts = Dict(:subj =&gt; Grouping())\nm1 = let\n  form = @formula(reaction ~ 1 + days + (1 + days | subj))\n  fit(MixedModel, form, sleepstudy; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n\n\n(Intercept)\n251.4051\n6.6323\n37.91\n&lt;1e-99\n23.7805\n\n\ndays\n10.4673\n1.5022\n6.97\n&lt;1e-11\n5.7168\n\n\nResidual\n25.5918\n\n\n\n\n\n\n\n\n\nThis model includes fixed effects for the intercept, representing the typical reaction time at the beginning of the experiment with zero days of sleep deprivation, and the slope w.r.t. days of sleep deprivation. The parameter estimates are about 250 ms. typical reaction time without deprivation and a typical increase of 10.5 ms. per day of sleep deprivation.\nThe random effects represent shifts from the typical behavior for each subject. The shift in the intercept has a standard deviation of about 24 ms. which would suggest a range of about 200 ms. to 300 ms. in the intercepts. Similarly within-subject slopes would be expected to have a range of about 0 ms./day up to 20 ms./day.\nThe random effects for the slope and for the intercept are allowed to be correlated within subject. The estimated correlation, 0.08, is small. This estimate is not shown in the default display above but is shown in the output from VarCorr (variance components and correlations).\n\nVarCorr(m1)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\nsubj\n(Intercept)\n565.51067\n23.78047\n\n\n\n\ndays\n32.68212\n5.71683\n+0.08\n\n\nResidual\n\n654.94145\n25.59182\n\n\n\n\n\n\nTechnically, the random effects for each subject are unobserved random variables and are not “parameters” in the model per se. Hence we do not report standard errors or confidence intervals for these deviations. However, we can produce prediction intervals on the random effects for each subject. Because the experimental design is balanced, these intervals will have the same width for all subjects.\nA plot of the prediction intervals versus the level of the grouping factor (subj, in this case) is sometimes called a caterpillar plot because it can look like a fuzzy caterpillar if there are many levels of the grouping factor. By default, the levels of the grouping factor are sorted by increasing value of the first random effect.\n\n\nCode\ncaterpillar(m1)\n\n\n\n\n\nFigure 2: Prediction intervals on random effects for model m1\n\n\n\n\nFigure 2 reinforces the conclusion that there is little correlation between the random effect for intercept and the random effect for slope."
  },
  {
    "objectID": "sleepstudy.html#a-model-with-uncorrelated-random-effects",
    "href": "sleepstudy.html#a-model-with-uncorrelated-random-effects",
    "title": "Analysis of the sleepstudy data",
    "section": "A model with uncorrelated random effects",
    "text": "A model with uncorrelated random effects\nThe zerocorr function applied to a random-effects term creates uncorrelated vector-valued per-subject random effects.\n\nm2 = let\n  form = @formula reaction ~ 1 + days + zerocorr(1 + days | subj)\n  fit(MixedModel, form, sleepstudy; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n\n\n(Intercept)\n251.4051\n6.7077\n37.48\n&lt;1e-99\n24.1714\n\n\ndays\n10.4673\n1.5193\n6.89\n&lt;1e-11\n5.7994\n\n\nResidual\n25.5561\n\n\n\n\n\n\n\n\n\nAgain, the default display doesn’t show that there is no correlation parameter to be estimated in this model, but the VarCorr display does.\n\nVarCorr(m2)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\nsubj\n(Intercept)\n584.25897\n24.17145\n\n\n\n\ndays\n33.63281\n5.79938\n.\n\n\nResidual\n\n653.11578\n25.55613\n\n\n\n\n\n\nThis model has a slightly lower log-likelihood than does m1 and one fewer parameter than m1. A likelihood-ratio test can be used to compare these nested models.\n\nMixedModels.likelihoodratiotest(m2, m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nreaction ~ 1 + days + zerocorr(1 + days | subj)\n5\n1752\n\n\n\n\n\nreaction ~ 1 + days + (1 + days | subj)\n6\n1752\n0\n1\n0.8004\n\n\n\n\n\nAlternatively, the AIC or BIC values can be compared.\n\n\nCode\nlet mods = [m2, m1]\n  DataFrame(;\n    model=[:m2, :m1],\n    pars=dof.(mods),\n    geomdof=(sum ∘ leverage).(mods),\n    AIC=aic.(mods),\n    BIC=bic.(mods),\n    AICc=aicc.(mods),\n  )\nend\n\n\n2×6 DataFrame\n\n\n\nRow\nmodel\npars\ngeomdof\nAIC\nBIC\nAICc\n\n\n\nSymbol\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\nm2\n5\n29.045\n1762.0\n1777.97\n1762.35\n\n\n2\nm1\n6\n28.6115\n1763.94\n1783.1\n1764.42\n\n\n\n\n\n\nThe goodness of fit measures: AIC, BIC, and AICc, are all on a “smaller is better” scale and, hence, they all prefer m2.\nThe pars column, which is the same as the model-dof column in the likelihood ratio test output, is simply a count of the number of parameters to be estimated when fitting the model. For example, in m2 there are two fixed-effects parameters and three variance components (including the residual variance).\nAn alternative, more geometrically inspired definition of “degrees of freedom”, is the sum of the leverage values, called geomdof in this table.\nInterestingly, the model with fewer parameters, m2, has a greater sum of the leverage values than the model with more parameters, m1. We’re not sure what to make of that.\nIn both cases the sum of the leverage values is toward the upper end of the range of possible values, which is the rank of the fixed-effects model matrix (2) up to the rank of the fixed-effects plus the random effects model matrix (2 + 36 = 38).\n\n\n\n\n\n\nNote\n\n\n\nI think that the upper bound may be 36, not 38, because the two columns of X lie in the column span of Z\n\n\nThis comparison does show, however, that a simple count of the parameters in a mixed-effects model can underestimate, sometimes drastically, the model complexity. This is because a single variance component or multiple components can add many dimensions to the linear predictor."
  },
  {
    "objectID": "sleepstudy.html#some-diagnostic-plots",
    "href": "sleepstudy.html#some-diagnostic-plots",
    "title": "Analysis of the sleepstudy data",
    "section": "Some diagnostic plots",
    "text": "Some diagnostic plots\nIn mixed-effects models the linear predictor expression incorporates fixed-effects parameters, which summarize trends for the population or certain well-defined subpopulations, and random effects which represent deviations associated with the experimental units or observational units - individual subjects, in this case. The random effects are modeled as unobserved random variables.\nThe conditional means of these random variables, sometimes called the BLUPs or Best Linear Unbiased Predictors, are not simply the least squares estimates. They are attenuated or shrunk towards zero to reflect the fact that the individuals are assumed to come from a population. A shrinkage plot, Figure 3, shows the BLUPs from the model fit compared to the values without any shrinkage. If the BLUPs are similar to the unshrunk values then the more complicated model accounting for individual differences is supported. If the BLUPs are strongly shrunk towards zero then the additional complexity in the model to account for individual differences is not providing sufficient increase in fidelity to the data to warrant inclusion.\n\n\nCode\nshrinkageplot!(Figure(; resolution=(500, 500)), m1)\n\n\n\n\n\nFigure 3: Shrinkage plot of means of the random effects in model m1\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis plot could be drawn as shrinkageplot(m1). The reason for explicitly creating a Figure to be modified by shrinkageplot! is to control the resolution.\n\n\nThis plot shows an intermediate pattern. The random effects are somewhat shrunk toward the origin, a model simplification trend, but not completely shrunk - indicating that fidelity to the data is enhanced with these additional coefficients in the linear predictor.\nIf the shrinkage were primarily in one direction - for example, if the arrows from the unshrunk values to the shrunk values were mostly in the vertical direction - then we would get an indication that we could drop the random effect for slope and revert to a simpler model. This is not the case here.\nAs would be expected, the unshrunk values that are further from the origin tend to be shrunk more toward the origin. That is, the arrows that originate furthest from the origin are longer. However, that is not always the case. The arrow in the upper right corner, from S337, is relatively short. Examination of the panel for S337 in the data plot shows a strong linear trend, even though both the intercept and the slope are unusually large. The neighboring panels in the data plot, S330 and S331, have more variability around the least squares line and are subject to a greater amount of shrinkage in the model. (They correspond to the two arrows on the right hand side of the figure around -5 on the vertical scale.)"
  },
  {
    "objectID": "sleepstudy.html#assessing-variability-by-bootstrapping",
    "href": "sleepstudy.html#assessing-variability-by-bootstrapping",
    "title": "Analysis of the sleepstudy data",
    "section": "Assessing variability by bootstrapping",
    "text": "Assessing variability by bootstrapping\nThe speed of fitting linear mixed-effects models using MixedModels.jl allows for using simulation-based approaches to inference instead of relying on approximate standard errors. A parametric bootstrap sample for model m is a collection of models of the same form as m fit to data values simulated from m. That is, we pretend that m and its parameter values are the true parameter values, simulate data from these values, and estimate parameters from the simulated data.\nSimulating and fitting a substantial number of model fits, 5000 in this case, takes only a few seconds, following which we extract a data frame of the parameter estimates and plot densities of some of these estimates.\n\nrng = Random.seed!(42)    # initialize a random number generator\nm1bstp = parametricbootstrap(rng, 5000, m1; hide_progress=true)\nallpars = DataFrame(m1bstp.allpars)\n\n30000×5 DataFrame29975 rows omitted\n\n\n\nRow\niter\ntype\ngroup\nnames\nvalue\n\n\n\nInt64\nString\nString?\nString?\nFloat64\n\n\n\n\n1\n1\nβ\nmissing\n(Intercept)\n260.712\n\n\n2\n1\nβ\nmissing\ndays\n9.84975\n\n\n3\n1\nσ\nsubj\n(Intercept)\n15.3314\n\n\n4\n1\nσ\nsubj\ndays\n6.40292\n\n\n5\n1\nρ\nsubj\n(Intercept), days\n-0.0259482\n\n\n6\n1\nσ\nresidual\nmissing\n23.4092\n\n\n7\n2\nβ\nmissing\n(Intercept)\n262.253\n\n\n8\n2\nβ\nmissing\ndays\n12.3008\n\n\n9\n2\nσ\nsubj\n(Intercept)\n16.3183\n\n\n10\n2\nσ\nsubj\ndays\n5.54687\n\n\n11\n2\nρ\nsubj\n(Intercept), days\n0.552608\n\n\n12\n2\nσ\nresidual\nmissing\n25.7047\n\n\n13\n3\nβ\nmissing\n(Intercept)\n253.149\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n29989\n4999\nβ\nmissing\n(Intercept)\n251.077\n\n\n29990\n4999\nβ\nmissing\ndays\n10.8061\n\n\n29991\n4999\nσ\nsubj\n(Intercept)\n31.6311\n\n\n29992\n4999\nσ\nsubj\ndays\n5.53413\n\n\n29993\n4999\nρ\nsubj\n(Intercept), days\n0.171692\n\n\n29994\n4999\nσ\nresidual\nmissing\n22.4943\n\n\n29995\n5000\nβ\nmissing\n(Intercept)\n249.945\n\n\n29996\n5000\nβ\nmissing\ndays\n9.25346\n\n\n29997\n5000\nσ\nsubj\n(Intercept)\n38.7082\n\n\n29998\n5000\nσ\nsubj\ndays\n4.68739\n\n\n29999\n5000\nρ\nsubj\n(Intercept), days\n-0.251217\n\n\n30000\n5000\nσ\nresidual\nmissing\n26.0088\n\n\n\n\n\n\nAn empirical density plot of the estimates for the fixed-effects coefficients, Figure 4, shows the normal distribution, “bell-curve”, shape as we might expect.\n\n\nCode\nbegin\n  f1 = Figure(; resolution=(1000, 400))\n  CairoMakie.density!(\n    Axis(f1[1, 1]; xlabel=\"Intercept [ms]\"),\n    @subset(allpars, :type == \"β\" && :names == \"(Intercept)\").value,\n  )\n  CairoMakie.density!(\n    Axis(f1[1, 2]; xlabel=\"Coefficient of days [ms/day]\"),\n    @subset(allpars, :type == \"β\" && :names == \"days\").value,\n  )\n  f1\nend\n\n\n\n\n\nFigure 4: Empirical density plots of bootstrap replications of fixed-effects parameter estimates\n\n\n\n\nIt is also possible to create interval estimates of the parameters from the bootstrap replicates. We define the 1-α shortestcovint to be the shortest interval that contains a proportion 1-α (defaults to 95%) of the bootstrap estimates of the parameter.\n\nDataFrame(shortestcovint(m1bstp))\n\n6×5 DataFrame\n\n\n\nRow\ntype\ngroup\nnames\nlower\nupper\n\n\n\nString\nString?\nString?\nFloat64\nFloat64\n\n\n\n\n1\nβ\nmissing\n(Intercept)\n239.64\n265.228\n\n\n2\nβ\nmissing\ndays\n7.42347\n13.1607\n\n\n3\nσ\nsubj\n(Intercept)\n10.1722\n33.0877\n\n\n4\nσ\nsubj\ndays\n2.99474\n7.6612\n\n\n5\nρ\nsubj\n(Intercept), days\n-0.40135\n1.0\n\n\n6\nσ\nresidual\nmissing\n22.701\n28.5016\n\n\n\n\n\n\nThe intervals look reasonable except that the upper bound on the interval for ρ, the correlation coefficient, is 1.0 . It turns out that the estimates of ρ have a great deal of variability.\nEven more alarming, some of these ρ values are undefined (denoted NaN) because the way ρ is calculated can create a division by zero.\n\ndescribe(@select(@subset(allpars, :type == \"ρ\"), :value))\n\n1×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nFloat64\nFloat64\nNothing\nFloat64\nInt64\nDataType\n\n\n\n\n1\nvalue\nNaN\nNaN\n\nNaN\n0\nFloat64\n\n\n\n\n\n\nBecause there are several values on the boundary (ρ = 1.0) and a pulse like this is not handled well by a density plot, we plot this sample as a histogram, Figure 5.\n\n\nCode\nhist(\n  @subset(allpars, :type == \"ρ\", isfinite(:value)).value;\n  bins=40,\n  axis=(; xlabel=\"Estimated correlation of the random effects\"),\n  figure=(; resolution=(500, 500)),\n)\n\n\n\n\n\nFigure 5: Histogram of bootstrap replications of the within-subject correlation parameter\n\n\n\n\nFinally, density plots for the variance components (but on the scale of the standard deviation), Figure 6, show reasonable symmetry.\n\n\nCode\nbegin\n  σs = @subset(allpars, :type == \"σ\")\n  f2 = Figure(; resolution=(1000, 300))\n  CairoMakie.density!(\n    Axis(f2[1, 1]; xlabel=\"Residual σ\"),\n    @subset(σs, :group == \"residual\").value,\n  )\n  CairoMakie.density!(\n    Axis(f2[1, 2]; xlabel=\"subj-Intercept σ\"),\n    @subset(σs, :group == \"subj\" && :names == \"(Intercept)\").value,\n  )\n  CairoMakie.density!(\n    Axis(f2[1, 3]; xlabel=\"subj-slope σ\"),\n    @subset(σs, :group == \"subj\" && :names == \"days\").value,\n  )\n  f2\nend\n\n\n\n\n\nFigure 6: Empirical density plots of bootstrap replicates of standard deviation estimates\n\n\n\n\nThe estimates of the coefficients, β₁ and β₂, are not highly correlated as shown in a scatterplot of the bootstrap estimates, Figure 7 .\n\nvcov(m1; corr=true)  # correlation estimate from the model\n\n2×2 Matrix{Float64}:\n  1.0       -0.137545\n -0.137545   1.0\n\n\n\n\nCode\nlet\n  vals = disallowmissing(\n    Array(\n      select(\n        unstack(DataFrame(m1bstp.β), :iter, :coefname, :β),\n        Not(:iter),\n      ),\n    ),\n  )\n  scatter(\n    vals;\n    color=(:blue, 0.20),\n    axis=(; xlabel=\"Intercept\", ylabel=\"Coefficient of days\"),\n    figure=(; resolution=(500, 500)),\n  )\n  contour!(kde(vals))\n  current_figure()\nend\n\n\n\n\n\nFigure 7: Scatter-plot of bootstrap replicates of fixed-effects estimates with contours"
  },
  {
    "objectID": "bootstrap.html",
    "href": "bootstrap.html",
    "title": "Parametric bootstrap for mixed-effects models",
    "section": "",
    "text": "The speed of MixedModels.jl relative to its predecessors makes the parametric bootstrap much more computationally tractable. This is valuable because the parametric bootstrap can be used to produce more accurate confidence intervals than methods based on standard errors or profiling of the likelihood surface.\nThis page is adapted from the MixedModels.jl docs"
  },
  {
    "objectID": "bootstrap.html#the-parametric-bootstrap",
    "href": "bootstrap.html#the-parametric-bootstrap",
    "title": "Parametric bootstrap for mixed-effects models",
    "section": "The parametric bootstrap",
    "text": "The parametric bootstrap\nBootstrapping is a family of procedures for generating sample values of a statistic, allowing for visualization of the distribution of the statistic or for inference from this sample of values. Bootstrapping also belongs to a larger family of procedures called resampling, which are based on creating new samples of data from an existing one, then computing statistics on the new samples, in order to examine the distribution of the relevant statistics.\nA parametric bootstrap is used with a parametric model, m, that has been fit to data. The procedure is to simulate n response vectors from m using the estimated parameter values and refit m to these responses in turn, accumulating the statistics of interest at each iteration.\nThe parameters of a LinearMixedModel object are the fixed-effects parameters, β, the standard deviation, σ, of the per-observation noise, and the covariance parameter, θ, that defines the variance-covariance matrices of the random effects. A technical description of the covariance parameter can be found in the MixedModels.jl docs. Lisa Schwetlick and Daniel Backhaus have provided a more beginner-friendly description of the covariance parameter in the documentation for MixedModelsSim.jl. For today’s purposes – looking at the uncertainty in the estimates from a fitted model – we can simply use values from the fitted model, but we will revisit the parametric bootstrap as a convenient way to simulate new data, potentially with different parameter values, for power analysis.\nFor example, a simple linear mixed-effects model for the Dyestuff data in the lme4 package for R is fit by\n\nusing AlgebraOfGraphics\nusing CairoMakie\nusing DataFrames\nusing MixedModels\nusing MixedModelsMakie\nusing ProgressMeter\nusing Random\n\nusing AlgebraOfGraphics: AlgebraOfGraphics as AoG\nCairoMakie.activate!(; type=\"svg\") # use SVG (other options include PNG)\nProgressMeter.ijulia_behavior(:clear);\n\nNote that the precise stream of random numbers generated for a given seed can change between Julia versions. For exact reproducibility, you either need to have the exact same Julia version or use the StableRNGs package."
  },
  {
    "objectID": "bootstrap.html#a-model-of-moderate-complexity",
    "href": "bootstrap.html#a-model-of-moderate-complexity",
    "title": "Parametric bootstrap for mixed-effects models",
    "section": "A model of moderate complexity",
    "text": "A model of moderate complexity\nThe kb07 data (Kronmüller & Barr, 2007) are one of the datasets provided by the MixedModels package.\n\nkb07 = MixedModels.dataset(:kb07)\n\nArrow.Table with 1789 rows, 7 columns, and schema:\n :subj      String\n :item      String\n :spkr      String\n :prec      String\n :load      String\n :rt_trunc  Int16\n :rt_raw    Int16\n\n\nConvert the table to a DataFrame for summary.\n\nkb07 = DataFrame(kb07)\ndescribe(kb07)\n\n7×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nsubj\n\nS030\n\nS103\n0\nString\n\n\n2\nitem\n\nI01\n\nI32\n0\nString\n\n\n3\nspkr\n\nnew\n\nold\n0\nString\n\n\n4\nprec\n\nbreak\n\nmaintain\n0\nString\n\n\n5\nload\n\nno\n\nyes\n0\nString\n\n\n6\nrt_trunc\n2182.2\n579\n1940.0\n5171\n0\nInt16\n\n\n7\nrt_raw\n2226.24\n579\n1940.0\n15923\n0\nInt16\n\n\n\n\n\n\nThe experimental factors; spkr, prec, and load, are two-level factors.\n\ncontrasts = Dict(:spkr =&gt; EffectsCoding(),\n                 :prec =&gt; EffectsCoding(),\n                 :load =&gt; EffectsCoding(),\n                 :subj =&gt; Grouping(),\n                 :item =&gt; Grouping())\n\nDict{Symbol, StatsModels.AbstractContrasts} with 5 entries:\n  :item =&gt; Grouping()\n  :spkr =&gt; EffectsCoding(nothing, nothing)\n  :load =&gt; EffectsCoding(nothing, nothing)\n  :prec =&gt; EffectsCoding(nothing, nothing)\n  :subj =&gt; Grouping()\n\n\nThe EffectsCoding contrast is used with these to create a ±1 encoding. Furthermore, Grouping constrasts are assigned to the subj and item factors. This is not a contrast per-se but an indication that these factors will be used as grouping factors for random effects and, therefore, there is no need to create a contrast matrix. For large numbers of levels in a grouping factor, an attempt to create a contrast matrix may cause memory overflow.\nIt is not important in these cases but a good practice in any case.\nWe can look at an initial fit of moderate complexity:\n\nform = @formula(rt_trunc ~ 1 + spkr * prec * load +\n                          (1 + spkr + prec + load | subj) +\n                          (1 + spkr + prec + load | item))\nm0 = fit(MixedModel, form, kb07; contrasts)\n\nMinimizing 883   Time: 0:00:00 ( 0.97 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\nσ_item\n\n\n\n\n(Intercept)\n2181.6729\n77.2879\n28.23\n&lt;1e-99\n301.7871\n362.0938\n\n\nspkr: old\n67.7484\n18.2976\n3.70\n0.0002\n43.1536\n40.6843\n\n\nprec: maintain\n-333.9212\n47.1387\n-7.08\n&lt;1e-11\n62.0318\n246.8048\n\n\nload: yes\n78.7702\n19.5373\n4.03\n&lt;1e-04\n65.1901\n42.3299\n\n\nspkr: old & prec: maintain\n-21.9655\n15.8058\n-1.39\n0.1646\n\n\n\n\nspkr: old & load: yes\n18.3844\n15.8058\n1.16\n0.2448\n\n\n\n\nprec: maintain & load: yes\n4.5340\n15.8058\n0.29\n0.7742\n\n\n\n\nspkr: old & prec: maintain & load: yes\n23.6073\n15.8058\n1.49\n0.1353\n\n\n\n\nResidual\n668.4871\n\n\n\n\n\n\n\n\n\n\nThe default display in Quarto uses the pretty MIME show method for the model and omits the estimated correlations of the random effects.\nThe VarCorr extractor displays these.\n\nVarCorr(m0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\nsubj\n(Intercept)\n91075.4527\n301.7871\n\n\n\n\n\n\nspkr: old\n1862.2358\n43.1536\n+0.78\n\n\n\n\n\nprec: maintain\n3847.9447\n62.0318\n-0.59\n+0.03\n\n\n\n\nload: yes\n4249.7506\n65.1901\n+0.36\n+0.82\n+0.53\n\n\nitem\n(Intercept)\n131111.9379\n362.0938\n\n\n\n\n\n\nspkr: old\n1655.2134\n40.6843\n+0.44\n\n\n\n\n\nprec: maintain\n60912.6143\n246.8048\n-0.69\n+0.35\n\n\n\n\nload: yes\n1791.8243\n42.3299\n+0.32\n+0.16\n-0.14\n\n\nResidual\n\n446875.0375\n668.4871\n\n\n\n\n\n\n\n\nNone of the two-factor or three-factor interaction terms in the fixed-effects are significant. In the random-effects terms only the scalar random effects and the prec random effect for item appear to be warranted, leading to the reduced formula\n\n# formula f4 from https://doi.org/10.33016/nextjournal.100002\nform = @formula(rt_trunc ~ 1 + spkr * prec * load + (1 | subj) + (1 + prec | item))\n\nm1 = fit(MixedModel, form, kb07; contrasts)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_item\nσ_subj\n\n\n\n\n(Intercept)\n2181.7582\n77.4709\n28.16\n&lt;1e-99\n364.7286\n298.1109\n\n\nspkr: old\n67.8114\n16.0526\n4.22\n&lt;1e-04\n\n\n\n\nprec: maintain\n-333.8582\n47.4629\n-7.03\n&lt;1e-11\n252.6687\n\n\n\nload: yes\n78.6849\n16.0525\n4.90\n&lt;1e-06\n\n\n\n\nspkr: old & prec: maintain\n-21.8802\n16.0525\n-1.36\n0.1729\n\n\n\n\nspkr: old & load: yes\n18.3214\n16.0526\n1.14\n0.2537\n\n\n\n\nprec: maintain & load: yes\n4.4710\n16.0526\n0.28\n0.7806\n\n\n\n\nspkr: old & prec: maintain & load: yes\n23.5219\n16.0525\n1.47\n0.1428\n\n\n\n\nResidual\n678.9318\n\n\n\n\n\n\n\n\n\n\n\nVarCorr(m1)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\nitem\n(Intercept)\n133026.917\n364.729\n\n\n\n\nprec: maintain\n63841.496\n252.669\n-0.70\n\n\nsubj\n(Intercept)\n88870.080\n298.111\n\n\n\nResidual\n\n460948.432\n678.932\n\n\n\n\n\n\nThese two models are nested and can be compared with a likelihood-ratio test.\n\nMixedModels.likelihoodratiotest(m0, m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nrt_trunc ~ 1 + spkr + prec + load + spkr & prec + spkr & load + prec & load + spkr & prec & load + (1 | subj) + (1 + prec | item)\n13\n28658\n\n\n\n\n\nrt_trunc ~ 1 + spkr + prec + load + spkr & prec + spkr & load + prec & load + spkr & prec & load + (1 + spkr + prec + load | subj) + (1 + spkr + prec + load | item)\n29\n28637\n21\n16\n0.1649\n\n\n\n\n\nThe p-value of approximately 14% leads us to prefer the simpler model, m1, to the more complex, m0."
  },
  {
    "objectID": "bootstrap.html#bootstrap-basics",
    "href": "bootstrap.html#bootstrap-basics",
    "title": "Parametric bootstrap for mixed-effects models",
    "section": "Bootstrap basics",
    "text": "Bootstrap basics\nTo bootstrap the model parameters, first initialize a random number generator then create a bootstrap sample\n\nconst RNG = MersenneTwister(42)\nsamp = parametricbootstrap(RNG, 1_000, m1)\ndf = DataFrame(samp.allpars)\nfirst(df, 10)\n\n10×5 DataFrame\n\n\n\nRow\niter\ntype\ngroup\nnames\nvalue\n\n\n\nInt64\nString\nString?\nString?\nFloat64\n\n\n\n\n1\n1\nβ\nmissing\n(Intercept)\n2049.88\n\n\n2\n1\nβ\nmissing\nspkr: old\n71.6398\n\n\n3\n1\nβ\nmissing\nprec: maintain\n-268.333\n\n\n4\n1\nβ\nmissing\nload: yes\n75.1566\n\n\n5\n1\nβ\nmissing\nspkr: old & prec: maintain\n-17.8459\n\n\n6\n1\nβ\nmissing\nspkr: old & load: yes\n-1.90968\n\n\n7\n1\nβ\nmissing\nprec: maintain & load: yes\n13.1018\n\n\n8\n1\nβ\nmissing\nspkr: old & prec: maintain & load: yes\n37.19\n\n\n9\n1\nσ\nitem\n(Intercept)\n363.568\n\n\n10\n1\nσ\nitem\nprec: maintain\n199.692\n\n\n\n\n\n\nEspecially for those with a background in R or pandas, the simplest way of accessing the parameter estimates in the parametric bootstrap object is to create a DataFrame from the allpars property as shown above.\nWe can use subset to subset out relevant rows of a dataframe. A density plot of the estimates of σ, the residual standard deviation, can be created as\n\nσres = subset(df, :type =&gt; ByRow(==(\"σ\")), :group =&gt; ByRow(==(\"residual\")); skipmissing=true)\n\nplt = data(σres) * mapping(:value) * AoG.density()\ndraw(plt; axis=(;title=\"Parametric bootstrap estimates of σ\"))\n\n\n\n\nA density plot of the estimates of the standard deviation of the random effects is obtained as\n\nσsubjitem = subset(df, :type =&gt; ByRow(==(\"σ\")), :group =&gt; ByRow(!=(\"residual\")); skipmissing=true)\n\nplt = data(σsubjitem) * mapping(:value; layout=:names, color=:group) * AoG.density()\ndraw(plt; figure=(;supertitle=\"Parametric bootstrap estimates of variance components\"))\n\n\n\n\nThe bootstrap sample can be used to generate intervals that cover a certain percentage of the bootstrapped values. We refer to these as “coverage intervals”, similar to a confidence interval. The shortest such intervals, obtained with the shortestcovint extractor, correspond to a highest posterior density interval in Bayesian inference.\nWe generate these for all random and fixed effects:\n\nshortestcovint(samp)\n\n13-element Vector{NamedTuple{(:type, :group, :names, :lower, :upper)}}:\n (type = \"β\", group = missing, names = \"(Intercept)\", lower = 2028.4504682672964, upper = 2335.4980378747036)\n (type = \"β\", group = missing, names = \"spkr: old\", lower = 33.90584194560795, upper = 97.1017123385091)\n (type = \"β\", group = missing, names = \"prec: maintain\", lower = -420.9759791010719, upper = -246.92630826126546)\n (type = \"β\", group = missing, names = \"load: yes\", lower = 49.939734569214366, upper = 108.72371422004355)\n (type = \"β\", group = missing, names = \"spkr: old & prec: maintain\", lower = -52.84340405095695, upper = 8.707634571058161)\n (type = \"β\", group = missing, names = \"spkr: old & load: yes\", lower = -11.990358740715502, upper = 49.090842667896304)\n (type = \"β\", group = missing, names = \"prec: maintain & load: yes\", lower = -25.207699936710174, upper = 36.986540545649625)\n (type = \"β\", group = missing, names = \"spkr: old & prec: maintain & load: yes\", lower = -5.88517077964873, upper = 54.770344717114426)\n (type = \"σ\", group = \"item\", names = \"(Intercept)\", lower = 267.28218879001105, upper = 462.8175723410845)\n (type = \"σ\", group = \"item\", names = \"prec: maintain\", lower = 178.14890712185007, upper = 316.22873298202416)\n (type = \"ρ\", group = \"item\", names = \"(Intercept), prec: maintain\", lower = -0.9058596236131196, upper = -0.48139111311317206)\n (type = \"σ\", group = \"subj\", names = \"(Intercept)\", lower = 231.8760081324643, upper = 356.152081034666)\n (type = \"σ\", group = \"residual\", names = missing, lower = 653.5649122788086, upper = 700.7662328017541)\n\n\nand convert it to a dataframe:\n\nDataFrame(shortestcovint(samp))\n\n13×5 DataFrame\n\n\n\nRow\ntype\ngroup\nnames\nlower\nupper\n\n\n\nString\nString?\nString?\nFloat64\nFloat64\n\n\n\n\n1\nβ\nmissing\n(Intercept)\n2028.45\n2335.5\n\n\n2\nβ\nmissing\nspkr: old\n33.9058\n97.1017\n\n\n3\nβ\nmissing\nprec: maintain\n-420.976\n-246.926\n\n\n4\nβ\nmissing\nload: yes\n49.9397\n108.724\n\n\n5\nβ\nmissing\nspkr: old & prec: maintain\n-52.8434\n8.70763\n\n\n6\nβ\nmissing\nspkr: old & load: yes\n-11.9904\n49.0908\n\n\n7\nβ\nmissing\nprec: maintain & load: yes\n-25.2077\n36.9865\n\n\n8\nβ\nmissing\nspkr: old & prec: maintain & load: yes\n-5.88517\n54.7703\n\n\n9\nσ\nitem\n(Intercept)\n267.282\n462.818\n\n\n10\nσ\nitem\nprec: maintain\n178.149\n316.229\n\n\n11\nρ\nitem\n(Intercept), prec: maintain\n-0.90586\n-0.481391\n\n\n12\nσ\nsubj\n(Intercept)\n231.876\n356.152\n\n\n13\nσ\nresidual\nmissing\n653.565\n700.766\n\n\n\n\n\n\n\ndraw(\n  data(samp.β) * mapping(:β; color=:coefname) * AoG.density();\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\nFor the fixed effects, MixedModelsMakie provides a convenience interface to plot the combined coverage intervals and density plots\n\nridgeplot(samp)\n\n\n\n\nOften the intercept will be on a different scale and potentially less interesting, so we can stop it from being included in the plot:\n\nridgeplot(samp; show_intercept=false, xlabel=\"Bootstrap density and 95%CI\")"
  },
  {
    "objectID": "bootstrap.html#singularity",
    "href": "bootstrap.html#singularity",
    "title": "Parametric bootstrap for mixed-effects models",
    "section": "Singularity",
    "text": "Singularity\nLet’s consider the classic dysetuff dataset:\n\ndyestuff = MixedModels.dataset(:dyestuff)\nmdye = fit(MixedModel, @formula(yield ~ 1 + (1 | batch)), dyestuff)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_batch\n\n\n\n\n(Intercept)\n1527.5000\n17.6946\n86.33\n&lt;1e-99\n37.2603\n\n\nResidual\n49.5101\n\n\n\n\n\n\n\n\n\n\nsampdye = parametricbootstrap(MersenneTwister(1234321), 10_000, mdye)\ndfdye = DataFrame(sampdye.allpars)\nfirst(dfdye, 10)\n\n┌ Warning: NLopt was roundoff limited\n└ @ MixedModels ~/.julia/packages/MixedModels/8zfgx/src/optsummary.jl:180\n┌ Warning: NLopt was roundoff limited\n└ @ MixedModels ~/.julia/packages/MixedModels/8zfgx/src/optsummary.jl:180\n┌ Warning: NLopt was roundoff limited\n└ @ MixedModels ~/.julia/packages/MixedModels/8zfgx/src/optsummary.jl:180\n┌ Warning: NLopt was roundoff limited\n└ @ MixedModels ~/.julia/packages/MixedModels/8zfgx/src/optsummary.jl:180\n┌ Warning: NLopt was roundoff limited\n└ @ MixedModels ~/.julia/packages/MixedModels/8zfgx/src/optsummary.jl:180\n\n\n10×5 DataFrame\n\n\n\nRow\niter\ntype\ngroup\nnames\nvalue\n\n\n\nInt64\nString\nString?\nString?\nFloat64\n\n\n\n\n1\n1\nβ\nmissing\n(Intercept)\n1509.13\n\n\n2\n1\nσ\nbatch\n(Intercept)\n14.312\n\n\n3\n1\nσ\nresidual\nmissing\n67.4315\n\n\n4\n2\nβ\nmissing\n(Intercept)\n1538.08\n\n\n5\n2\nσ\nbatch\n(Intercept)\n25.5673\n\n\n6\n2\nσ\nresidual\nmissing\n47.9831\n\n\n7\n3\nβ\nmissing\n(Intercept)\n1508.02\n\n\n8\n3\nσ\nbatch\n(Intercept)\n21.7622\n\n\n9\n3\nσ\nresidual\nmissing\n50.1346\n\n\n10\n4\nβ\nmissing\n(Intercept)\n1538.47\n\n\n\n\n\n\n\nσbatch = subset(dfdye, :type =&gt; ByRow(==(\"σ\")), :group =&gt; ByRow(==(\"batch\")); skipmissing=true)\n\nplt = data(σbatch) * mapping(:value) * AoG.density()\ndraw(plt; axis=(;title=\"Parametric bootstrap estimates of σ_batch\"))\n\n\n\n\nNotice that this density plot has a spike, or mode, at zero. Although this mode appears to be diffuse, this is an artifact of the way that density plots are created. In fact, it is a pulse, as can be seen from a histogram.\n\nplt = data(σbatch) * mapping(:value) * AoG.histogram(;bins=100)\ndraw(plt; axis=(;title=\"Parametric bootstrap estimates of σ_batch\"))\n\n\n\n\nA value of zero for the standard deviation of the random effects is an example of a singular covariance. It is easy to detect the singularity in the case of a scalar random-effects term. However, it is not as straightforward to detect singularity in vector-valued random-effects terms.\nFor example, if we bootstrap a model fit to the sleepstudy data\n\nsleepstudy = MixedModels.dataset(:sleepstudy)\nmsleep = fit(MixedModel, @formula(reaction ~ 1 + days + (1 + days | subj)),\n             sleepstudy)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n\n\n(Intercept)\n251.4051\n6.6323\n37.91\n&lt;1e-99\n23.7805\n\n\ndays\n10.4673\n1.5022\n6.97\n&lt;1e-11\n5.7168\n\n\nResidual\n25.5918\n\n\n\n\n\n\n\n\n\n\nsampsleep = parametricbootstrap(MersenneTwister(666), 10_000, msleep);\ndfsleep = DataFrame(sampsleep.allpars);\nfirst(dfsleep, 10)\n\n10×5 DataFrame\n\n\n\nRow\niter\ntype\ngroup\nnames\nvalue\n\n\n\nInt64\nString\nString?\nString?\nFloat64\n\n\n\n\n1\n1\nβ\nmissing\n(Intercept)\n252.488\n\n\n2\n1\nβ\nmissing\ndays\n11.0328\n\n\n3\n1\nσ\nsubj\n(Intercept)\n29.6185\n\n\n4\n1\nσ\nsubj\ndays\n6.33343\n\n\n5\n1\nρ\nsubj\n(Intercept), days\n0.233383\n\n\n6\n1\nσ\nresidual\nmissing\n22.4544\n\n\n7\n2\nβ\nmissing\n(Intercept)\n260.763\n\n\n8\n2\nβ\nmissing\ndays\n8.55352\n\n\n9\n2\nσ\nsubj\n(Intercept)\n20.8099\n\n\n10\n2\nσ\nsubj\ndays\n4.3292\n\n\n\n\n\n\nthe singularity can be exhibited as a standard deviation of zero or as a correlation of ±1.\n\nDataFrame(shortestcovint(sampsleep))\n\n6×5 DataFrame\n\n\n\nRow\ntype\ngroup\nnames\nlower\nupper\n\n\n\nString\nString?\nString?\nFloat64\nFloat64\n\n\n\n\n1\nβ\nmissing\n(Intercept)\n237.905\n264.231\n\n\n2\nβ\nmissing\ndays\n7.44545\n13.3516\n\n\n3\nσ\nsubj\n(Intercept)\n10.6757\n33.3567\n\n\n4\nσ\nsubj\ndays\n3.07033\n7.822\n\n\n5\nρ\nsubj\n(Intercept), days\n-0.411665\n1.0\n\n\n6\nσ\nresidual\nmissing\n22.6345\n28.5125\n\n\n\n\n\n\nA histogram of the estimated correlations from the bootstrap sample has a spike at +1.\n\nρs = subset(dfsleep, :type =&gt; ByRow(==(\"ρ\")), :group =&gt; ByRow(==(\"subj\")); skipmissing=true)\nplt = data(ρs) * mapping(:value) * AoG.histogram(;bins=100)\ndraw(plt; axis=(;title=\"Parametric bootstrap samples of correlation of random effects\"))\n\n\n\n\nor, as a count,\n\ncount(ρs.value .≈ 1)\n\n291\n\n\nClose examination of the histogram shows a few values of -1.\n\ncount(ρs.value .≈ -1)\n\n2\n\n\nFurthermore there are even a few cases where the estimate of the standard deviation of the random effect for the intercept is zero.\n\nσs = subset(dfsleep, :type =&gt; ByRow(==(\"σ\")), :group =&gt; ByRow(==(\"subj\")), :names =&gt; ByRow(==(\"(Intercept)\")); skipmissing=true)\ncount(σs.value .≈ 0)\n\n7\n\n\nThere is a general condition to check for singularity of an estimated covariance matrix or matrices in a bootstrap sample. The parameter optimized in the estimation is θ, the relative covariance parameter. Some of the elements of this parameter vector must be non-negative and, when one of these components is approximately zero, one of the covariance matrices will be singular.\nThe issingular method for a MixedModel object that tests if a parameter vector θ corresponds to a boundary or singular fit.\nThis operation is encapsulated in a method for the issingular function that works on MixedModelBootstrap objects.\n\ncount(issingular(sampsleep))\n\n300"
  },
  {
    "objectID": "arrow.html",
    "href": "arrow.html",
    "title": "Notes on saved data files",
    "section": "",
    "text": "The Arrow storage format provides a language-agnostic storage and memory specification for columnar data tables, which just means “something that looks like a data frame in R”. That is, an arrow table is an ordered, named collection of columns, all of the same length.\nThe columns can be of different types including numeric values, character strings, and factor-like representations - called DictEncoded.\nAn Arrow file can be read or written from R, Python, Julia and many other languages. Somewhat confusingly in R and Python the name feather, which refers to an earlier version of the storage format, is used in some function names like read_feather."
  },
  {
    "objectID": "arrow.html#the-arrow-storage-format",
    "href": "arrow.html#the-arrow-storage-format",
    "title": "Notes on saved data files",
    "section": "",
    "text": "The Arrow storage format provides a language-agnostic storage and memory specification for columnar data tables, which just means “something that looks like a data frame in R”. That is, an arrow table is an ordered, named collection of columns, all of the same length.\nThe columns can be of different types including numeric values, character strings, and factor-like representations - called DictEncoded.\nAn Arrow file can be read or written from R, Python, Julia and many other languages. Somewhat confusingly in R and Python the name feather, which refers to an earlier version of the storage format, is used in some function names like read_feather."
  },
  {
    "objectID": "arrow.html#the-emotikon-data",
    "href": "arrow.html#the-emotikon-data",
    "title": "Notes on saved data files",
    "section": "The Emotikon data",
    "text": "The Emotikon data\nThe SMLP2021 repository contains a version of the data from Fühner et al. (2021) in notebooks/data/fggk21.arrow. After that file was created there were changes in the master RDS file on the osf.io site for the project. We will recreate the Arrow file here then split it into two separate tables, one with a row for each child in the study and one with a row for each test result.\nThe Arrow package for Julia does not export any function names, which means that the function to read an Arrow file must be called as Arrow.Table. It returns a column table, as described in the Tables package. This is like a read-only data frame, which can be easily converted to a full-fledged DataFrame if desired.\nThis arrangement allows for the Arrow package not to depend on the DataFrames package, which is a heavy-weight dependency, but still easily produce a DataFrame if warranted.\nLoad the packages to be used.\n\n\nCode\nusing AlgebraOfGraphics\nusing Arrow\nusing CairoMakie\nusing Chain\nusing DataFrameMacros\nusing DataFrames\nusing Downloads\nusing KernelDensity\nusing RCall   # access R from within Julia\nusing StatsBase\n\nCairoMakie.activate!(; type=\"svg\")\nusing AlgebraOfGraphics: density"
  },
  {
    "objectID": "arrow.html#downloading-and-importing-the-rds-file",
    "href": "arrow.html#downloading-and-importing-the-rds-file",
    "title": "Notes on saved data files",
    "section": "Downloading and importing the RDS file",
    "text": "Downloading and importing the RDS file\nThis is similar to some of the code shown by Julius Krumbiegel on Monday. In the data directory of the emotikon project on osf.io under Data, the url for the rds data file is found to be [https://osf.io/xawdb/]. Note that we want version 2 of this file.\n\nfn = Downloads.download(\"https://osf.io/xawdb/download?version=2\");\n\n\ndfrm = rcopy(R\"readRDS($fn)\")\n\n525126×7 DataFrame525101 rows omitted\n\n\n\nRow\nCohort\nSchool\nChild\nSex\nage\nTest\nscore\n\n\n\nCat…\nCat…\nCat…\nCat…\nFloat64\nCat…\nFloat64\n\n\n\n\n1\n2013\nS100067\nC002352\nmale\n7.99452\nS20_r\n5.26316\n\n\n2\n2013\nS100067\nC002352\nmale\n7.99452\nBPT\n3.7\n\n\n3\n2013\nS100067\nC002352\nmale\n7.99452\nSLJ\n125.0\n\n\n4\n2013\nS100067\nC002352\nmale\n7.99452\nStar_r\n2.47146\n\n\n5\n2013\nS100067\nC002352\nmale\n7.99452\nRun\n1053.0\n\n\n6\n2013\nS100067\nC002353\nmale\n7.99452\nS20_r\n5.0\n\n\n7\n2013\nS100067\nC002353\nmale\n7.99452\nBPT\n4.1\n\n\n8\n2013\nS100067\nC002353\nmale\n7.99452\nSLJ\n116.0\n\n\n9\n2013\nS100067\nC002353\nmale\n7.99452\nStar_r\n1.76778\n\n\n10\n2013\nS100067\nC002353\nmale\n7.99452\nRun\n1089.0\n\n\n11\n2013\nS100067\nC002354\nmale\n7.99452\nS20_r\n4.54545\n\n\n12\n2013\nS100067\nC002354\nmale\n7.99452\nBPT\n3.9\n\n\n13\n2013\nS100067\nC002354\nmale\n7.99452\nSLJ\n111.0\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n525115\n2018\nS401470\nC117964\nmale\n9.10609\nStar_r\n1.63704\n\n\n525116\n2018\nS401470\nC117964\nmale\n9.10609\nRun\n864.0\n\n\n525117\n2018\nS401470\nC117965\nfemale\n9.10609\nS20_r\n4.65116\n\n\n525118\n2018\nS401470\nC117965\nfemale\n9.10609\nBPT\n3.8\n\n\n525119\n2018\nS401470\nC117965\nfemale\n9.10609\nSLJ\n123.0\n\n\n525120\n2018\nS401470\nC117965\nfemale\n9.10609\nStar_r\n1.52889\n\n\n525121\n2018\nS401470\nC117965\nfemale\n9.10609\nRun\n1080.0\n\n\n525122\n2018\nS800200\nC117966\nmale\n9.10609\nS20_r\n4.54545\n\n\n525123\n2018\nS800200\nC117966\nmale\n9.10609\nBPT\n3.8\n\n\n525124\n2018\nS800200\nC117966\nmale\n9.10609\nSLJ\n100.0\n\n\n525125\n2018\nS800200\nC117966\nmale\n9.10609\nStar_r\n2.18506\n\n\n525126\n2018\nS800200\nC117966\nmale\n9.10609\nRun\n990.0\n\n\n\n\n\n\nNow write this file as a Arrow file and read it back in.\n\narrowfn = joinpath(\"data\", \"fggk21.arrow\")\nArrow.write(arrowfn, dfrm; compress=:lz4)\ntbl = Arrow.Table(arrowfn)\n\nArrow.Table with 525126 rows, 7 columns, and schema:\n :Cohort  String\n :School  String\n :Child   String\n :Sex     String\n :age     Float64\n :Test    String\n :score   Float64\n\n\n\nfilesize(arrowfn)\n\n3077850\n\n\n\ndf = DataFrame(tbl)\n\n525126×7 DataFrame525101 rows omitted\n\n\n\nRow\nCohort\nSchool\nChild\nSex\nage\nTest\nscore\n\n\n\nString\nString\nString\nString\nFloat64\nString\nFloat64\n\n\n\n\n1\n2013\nS100067\nC002352\nmale\n7.99452\nS20_r\n5.26316\n\n\n2\n2013\nS100067\nC002352\nmale\n7.99452\nBPT\n3.7\n\n\n3\n2013\nS100067\nC002352\nmale\n7.99452\nSLJ\n125.0\n\n\n4\n2013\nS100067\nC002352\nmale\n7.99452\nStar_r\n2.47146\n\n\n5\n2013\nS100067\nC002352\nmale\n7.99452\nRun\n1053.0\n\n\n6\n2013\nS100067\nC002353\nmale\n7.99452\nS20_r\n5.0\n\n\n7\n2013\nS100067\nC002353\nmale\n7.99452\nBPT\n4.1\n\n\n8\n2013\nS100067\nC002353\nmale\n7.99452\nSLJ\n116.0\n\n\n9\n2013\nS100067\nC002353\nmale\n7.99452\nStar_r\n1.76778\n\n\n10\n2013\nS100067\nC002353\nmale\n7.99452\nRun\n1089.0\n\n\n11\n2013\nS100067\nC002354\nmale\n7.99452\nS20_r\n4.54545\n\n\n12\n2013\nS100067\nC002354\nmale\n7.99452\nBPT\n3.9\n\n\n13\n2013\nS100067\nC002354\nmale\n7.99452\nSLJ\n111.0\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n525115\n2018\nS401470\nC117964\nmale\n9.10609\nStar_r\n1.63704\n\n\n525116\n2018\nS401470\nC117964\nmale\n9.10609\nRun\n864.0\n\n\n525117\n2018\nS401470\nC117965\nfemale\n9.10609\nS20_r\n4.65116\n\n\n525118\n2018\nS401470\nC117965\nfemale\n9.10609\nBPT\n3.8\n\n\n525119\n2018\nS401470\nC117965\nfemale\n9.10609\nSLJ\n123.0\n\n\n525120\n2018\nS401470\nC117965\nfemale\n9.10609\nStar_r\n1.52889\n\n\n525121\n2018\nS401470\nC117965\nfemale\n9.10609\nRun\n1080.0\n\n\n525122\n2018\nS800200\nC117966\nmale\n9.10609\nS20_r\n4.54545\n\n\n525123\n2018\nS800200\nC117966\nmale\n9.10609\nBPT\n3.8\n\n\n525124\n2018\nS800200\nC117966\nmale\n9.10609\nSLJ\n100.0\n\n\n525125\n2018\nS800200\nC117966\nmale\n9.10609\nStar_r\n2.18506\n\n\n525126\n2018\nS800200\nC117966\nmale\n9.10609\nRun\n990.0"
  },
  {
    "objectID": "arrow.html#avoiding-needless-repetition",
    "href": "arrow.html#avoiding-needless-repetition",
    "title": "Notes on saved data files",
    "section": "Avoiding needless repetition",
    "text": "Avoiding needless repetition\nOne of the principles of relational database design is that information should not be repeated needlessly. Each row of df is determined by a combination of Child and Test, together producing a score, which can be converted to a zScore.\nThe other columns in the table, Cohort, School, age, and Sex, are properties of the Child.\nStoring these values redundantly in the full table takes up space but, more importantly, allows for inconsistency. As it stands, a given Child could be recorded as being in one Cohort for the Run test and in another Cohort for the S20_r test and nothing about the table would detect this as being an error.\nThe approach used in relational databases is to store the information for score in one table that contains only Child, Test and score, store the information for the Child in another table including Cohort, School, age and Sex. These tables can then be combined to create the table to be used for analysis by joining the different tables together.\nThe maintainers of the DataFrames package have put in a lot of work over the past few years to make joins quite efficient in Julia. Thus the processing penalty of reassembling the big table from three smaller tables is minimal.\nIt is important to note that the main advantage of using smaller tables that are joined together to produce the analysis table is the fact that the information in the analysis table is consistent by design."
  },
  {
    "objectID": "arrow.html#creating-the-smaller-table",
    "href": "arrow.html#creating-the-smaller-table",
    "title": "Notes on saved data files",
    "section": "Creating the smaller table",
    "text": "Creating the smaller table\n\nChild = unique(select(df, :Child, :School, :Cohort, :Sex, :age))\n\n108295×5 DataFrame108270 rows omitted\n\n\n\nRow\nChild\nSchool\nCohort\nSex\nage\n\n\n\nString\nString\nString\nString\nFloat64\n\n\n\n\n1\nC002352\nS100067\n2013\nmale\n7.99452\n\n\n2\nC002353\nS100067\n2013\nmale\n7.99452\n\n\n3\nC002354\nS100067\n2013\nmale\n7.99452\n\n\n4\nC002355\nS100122\n2013\nfemale\n7.99452\n\n\n5\nC002356\nS100146\n2013\nmale\n7.99452\n\n\n6\nC002357\nS100146\n2013\nmale\n7.99452\n\n\n7\nC002358\nS100146\n2013\nmale\n7.99452\n\n\n8\nC002359\nS100183\n2013\nfemale\n7.99452\n\n\n9\nC002360\nS100195\n2013\nfemale\n7.99452\n\n\n10\nC002361\nS100213\n2013\nmale\n7.99452\n\n\n11\nC002362\nS100237\n2013\nfemale\n7.99452\n\n\n12\nC002363\nS100237\n2013\nfemale\n7.99452\n\n\n13\nC002364\nS100250\n2013\nfemale\n7.99452\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n108284\nC117943\nS130539\n2018\nfemale\n9.10609\n\n\n108285\nC117944\nS130539\n2018\nmale\n9.10609\n\n\n108286\nC117945\nS130539\n2018\nmale\n9.10609\n\n\n108287\nC117946\nS130539\n2018\nmale\n9.10609\n\n\n108288\nC117956\nS400580\n2018\nmale\n9.10609\n\n\n108289\nC117957\nS400919\n2018\nmale\n9.10609\n\n\n108290\nC117958\nS400919\n2018\nmale\n9.10609\n\n\n108291\nC117959\nS400919\n2018\nmale\n9.10609\n\n\n108292\nC117962\nS401250\n2018\nfemale\n9.10609\n\n\n108293\nC117964\nS401470\n2018\nmale\n9.10609\n\n\n108294\nC117965\nS401470\n2018\nfemale\n9.10609\n\n\n108295\nC117966\nS800200\n2018\nmale\n9.10609\n\n\n\n\n\n\n\nlength(unique(Child.Child))  # should be 108295\n\n108295\n\n\n\nfilesize(\n  Arrow.write(\"./data/fggk21_Child.arrow\", Child; compress=:lz4)\n)\n\n1774946\n\n\n\nfilesize(\n  Arrow.write(\n    \"./data/fggk21_Score.arrow\",\n    select(df, :Child, :Test, :score);\n    compress=:lz4,\n  ),\n)\n\n2794058\n\n\n\n\n\n\n\n\nNote\n\n\n\nA careful examination of the file sizes versus that of ./data/fggk21.arrow will show that the separate tables combined take up more space than the original because of the compression. Compression algorithms are often more successful when applied to larger files.\n\n\nNow read the Arrow tables in and reassemble the original table.\n\nScore = DataFrame(Arrow.Table(\"./data/fggk21_Score.arrow\"))\n\n525126×3 DataFrame525101 rows omitted\n\n\n\nRow\nChild\nTest\nscore\n\n\n\nString\nString\nFloat64\n\n\n\n\n1\nC002352\nS20_r\n5.26316\n\n\n2\nC002352\nBPT\n3.7\n\n\n3\nC002352\nSLJ\n125.0\n\n\n4\nC002352\nStar_r\n2.47146\n\n\n5\nC002352\nRun\n1053.0\n\n\n6\nC002353\nS20_r\n5.0\n\n\n7\nC002353\nBPT\n4.1\n\n\n8\nC002353\nSLJ\n116.0\n\n\n9\nC002353\nStar_r\n1.76778\n\n\n10\nC002353\nRun\n1089.0\n\n\n11\nC002354\nS20_r\n4.54545\n\n\n12\nC002354\nBPT\n3.9\n\n\n13\nC002354\nSLJ\n111.0\n\n\n⋮\n⋮\n⋮\n⋮\n\n\n525115\nC117964\nStar_r\n1.63704\n\n\n525116\nC117964\nRun\n864.0\n\n\n525117\nC117965\nS20_r\n4.65116\n\n\n525118\nC117965\nBPT\n3.8\n\n\n525119\nC117965\nSLJ\n123.0\n\n\n525120\nC117965\nStar_r\n1.52889\n\n\n525121\nC117965\nRun\n1080.0\n\n\n525122\nC117966\nS20_r\n4.54545\n\n\n525123\nC117966\nBPT\n3.8\n\n\n525124\nC117966\nSLJ\n100.0\n\n\n525125\nC117966\nStar_r\n2.18506\n\n\n525126\nC117966\nRun\n990.0\n\n\n\n\n\n\nAt this point we can create the z-score column by standardizing the scores for each Test. The code to do this follows Julius’s presentation on Monday.\n\n@transform!(groupby(Score, :Test), :zScore = @bycol zscore(:score))\n\n525126×4 DataFrame525101 rows omitted\n\n\n\nRow\nChild\nTest\nscore\nzScore\n\n\n\nString\nString\nFloat64\nFloat64\n\n\n\n\n1\nC002352\nS20_r\n5.26316\n1.7913\n\n\n2\nC002352\nBPT\n3.7\n-0.0622317\n\n\n3\nC002352\nSLJ\n125.0\n-0.0336567\n\n\n4\nC002352\nStar_r\n2.47146\n1.46874\n\n\n5\nC002352\nRun\n1053.0\n0.331058\n\n\n6\nC002353\nS20_r\n5.0\n1.15471\n\n\n7\nC002353\nBPT\n4.1\n0.498354\n\n\n8\nC002353\nSLJ\n116.0\n-0.498822\n\n\n9\nC002353\nStar_r\n1.76778\n-0.9773\n\n\n10\nC002353\nRun\n1089.0\n0.574056\n\n\n11\nC002354\nS20_r\n4.54545\n0.0551481\n\n\n12\nC002354\nBPT\n3.9\n0.218061\n\n\n13\nC002354\nSLJ\n111.0\n-0.757248\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n525115\nC117964\nStar_r\n1.63704\n-1.43175\n\n\n525116\nC117964\nRun\n864.0\n-0.944681\n\n\n525117\nC117965\nS20_r\n4.65116\n0.31086\n\n\n525118\nC117965\nBPT\n3.8\n0.0779146\n\n\n525119\nC117965\nSLJ\n123.0\n-0.137027\n\n\n525120\nC117965\nStar_r\n1.52889\n-1.8077\n\n\n525121\nC117965\nRun\n1080.0\n0.513306\n\n\n525122\nC117966\nS20_r\n4.54545\n0.0551481\n\n\n525123\nC117966\nBPT\n3.8\n0.0779146\n\n\n525124\nC117966\nSLJ\n100.0\n-1.32578\n\n\n525125\nC117966\nStar_r\n2.18506\n0.473217\n\n\n525126\nC117966\nRun\n990.0\n-0.0941883\n\n\n\n\n\n\n\nChild = DataFrame(Arrow.Table(\"./data/fggk21_Child.arrow\"))\n\n108295×5 DataFrame108270 rows omitted\n\n\n\nRow\nChild\nSchool\nCohort\nSex\nage\n\n\n\nString\nString\nString\nString\nFloat64\n\n\n\n\n1\nC002352\nS100067\n2013\nmale\n7.99452\n\n\n2\nC002353\nS100067\n2013\nmale\n7.99452\n\n\n3\nC002354\nS100067\n2013\nmale\n7.99452\n\n\n4\nC002355\nS100122\n2013\nfemale\n7.99452\n\n\n5\nC002356\nS100146\n2013\nmale\n7.99452\n\n\n6\nC002357\nS100146\n2013\nmale\n7.99452\n\n\n7\nC002358\nS100146\n2013\nmale\n7.99452\n\n\n8\nC002359\nS100183\n2013\nfemale\n7.99452\n\n\n9\nC002360\nS100195\n2013\nfemale\n7.99452\n\n\n10\nC002361\nS100213\n2013\nmale\n7.99452\n\n\n11\nC002362\nS100237\n2013\nfemale\n7.99452\n\n\n12\nC002363\nS100237\n2013\nfemale\n7.99452\n\n\n13\nC002364\nS100250\n2013\nfemale\n7.99452\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n108284\nC117943\nS130539\n2018\nfemale\n9.10609\n\n\n108285\nC117944\nS130539\n2018\nmale\n9.10609\n\n\n108286\nC117945\nS130539\n2018\nmale\n9.10609\n\n\n108287\nC117946\nS130539\n2018\nmale\n9.10609\n\n\n108288\nC117956\nS400580\n2018\nmale\n9.10609\n\n\n108289\nC117957\nS400919\n2018\nmale\n9.10609\n\n\n108290\nC117958\nS400919\n2018\nmale\n9.10609\n\n\n108291\nC117959\nS400919\n2018\nmale\n9.10609\n\n\n108292\nC117962\nS401250\n2018\nfemale\n9.10609\n\n\n108293\nC117964\nS401470\n2018\nmale\n9.10609\n\n\n108294\nC117965\nS401470\n2018\nfemale\n9.10609\n\n\n108295\nC117966\nS800200\n2018\nmale\n9.10609\n\n\n\n\n\n\n\ndf1 = disallowmissing!(leftjoin(Score, Child; on=:Child))\n\n525126×8 DataFrame525101 rows omitted\n\n\n\nRow\nChild\nTest\nscore\nzScore\nSchool\nCohort\nSex\nage\n\n\n\nString\nString\nFloat64\nFloat64\nString\nString\nString\nFloat64\n\n\n\n\n1\nC002352\nS20_r\n5.26316\n1.7913\nS100067\n2013\nmale\n7.99452\n\n\n2\nC002352\nBPT\n3.7\n-0.0622317\nS100067\n2013\nmale\n7.99452\n\n\n3\nC002352\nSLJ\n125.0\n-0.0336567\nS100067\n2013\nmale\n7.99452\n\n\n4\nC002352\nStar_r\n2.47146\n1.46874\nS100067\n2013\nmale\n7.99452\n\n\n5\nC002352\nRun\n1053.0\n0.331058\nS100067\n2013\nmale\n7.99452\n\n\n6\nC002353\nS20_r\n5.0\n1.15471\nS100067\n2013\nmale\n7.99452\n\n\n7\nC002353\nBPT\n4.1\n0.498354\nS100067\n2013\nmale\n7.99452\n\n\n8\nC002353\nSLJ\n116.0\n-0.498822\nS100067\n2013\nmale\n7.99452\n\n\n9\nC002353\nStar_r\n1.76778\n-0.9773\nS100067\n2013\nmale\n7.99452\n\n\n10\nC002353\nRun\n1089.0\n0.574056\nS100067\n2013\nmale\n7.99452\n\n\n11\nC002354\nS20_r\n4.54545\n0.0551481\nS100067\n2013\nmale\n7.99452\n\n\n12\nC002354\nBPT\n3.9\n0.218061\nS100067\n2013\nmale\n7.99452\n\n\n13\nC002354\nSLJ\n111.0\n-0.757248\nS100067\n2013\nmale\n7.99452\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n525115\nC117964\nStar_r\n1.63704\n-1.43175\nS401470\n2018\nmale\n9.10609\n\n\n525116\nC117964\nRun\n864.0\n-0.944681\nS401470\n2018\nmale\n9.10609\n\n\n525117\nC117965\nS20_r\n4.65116\n0.31086\nS401470\n2018\nfemale\n9.10609\n\n\n525118\nC117965\nBPT\n3.8\n0.0779146\nS401470\n2018\nfemale\n9.10609\n\n\n525119\nC117965\nSLJ\n123.0\n-0.137027\nS401470\n2018\nfemale\n9.10609\n\n\n525120\nC117965\nStar_r\n1.52889\n-1.8077\nS401470\n2018\nfemale\n9.10609\n\n\n525121\nC117965\nRun\n1080.0\n0.513306\nS401470\n2018\nfemale\n9.10609\n\n\n525122\nC117966\nS20_r\n4.54545\n0.0551481\nS800200\n2018\nmale\n9.10609\n\n\n525123\nC117966\nBPT\n3.8\n0.0779146\nS800200\n2018\nmale\n9.10609\n\n\n525124\nC117966\nSLJ\n100.0\n-1.32578\nS800200\n2018\nmale\n9.10609\n\n\n525125\nC117966\nStar_r\n2.18506\n0.473217\nS800200\n2018\nmale\n9.10609\n\n\n525126\nC117966\nRun\n990.0\n-0.0941883\nS800200\n2018\nmale\n9.10609\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe call to disallowmissing! is because the join will create columns that allow for missing values but we know that we should not get missing values in the result. This call will fail if, for some reason, missing values were created."
  },
  {
    "objectID": "arrow.html#discovering-patterns-in-the-data",
    "href": "arrow.html#discovering-patterns-in-the-data",
    "title": "Notes on saved data files",
    "section": "Discovering patterns in the data",
    "text": "Discovering patterns in the data\nOne of the motivations for creating the Child table was be able to bin the ages according to the age of each child, not the age of each Child-Test combination. Not all children have all 5 test results. We can check the number of results by grouping on :Child and evaluate the number of rows in each group.\n\nnobsChild = combine(groupby(Score, :Child), nrow =&gt; :ntest)\n\n108295×2 DataFrame108270 rows omitted\n\n\n\nRow\nChild\nntest\n\n\n\nString\nInt64\n\n\n\n\n1\nC002352\n5\n\n\n2\nC002353\n5\n\n\n3\nC002354\n5\n\n\n4\nC002355\n5\n\n\n5\nC002356\n5\n\n\n6\nC002357\n5\n\n\n7\nC002358\n5\n\n\n8\nC002359\n4\n\n\n9\nC002360\n5\n\n\n10\nC002361\n4\n\n\n11\nC002362\n5\n\n\n12\nC002363\n5\n\n\n13\nC002364\n5\n\n\n⋮\n⋮\n⋮\n\n\n108284\nC117943\n5\n\n\n108285\nC117944\n5\n\n\n108286\nC117945\n5\n\n\n108287\nC117946\n5\n\n\n108288\nC117956\n5\n\n\n108289\nC117957\n4\n\n\n108290\nC117958\n5\n\n\n108291\nC117959\n5\n\n\n108292\nC117962\n5\n\n\n108293\nC117964\n5\n\n\n108294\nC117965\n5\n\n\n108295\nC117966\n5\n\n\n\n\n\n\nNow create a table of the number of children with 1, 2, …, 5 test scores.\n\ncombine(groupby(nobsChild, :ntest), nrow)\n\n5×2 DataFrame\n\n\n\nRow\nntest\nnrow\n\n\n\nInt64\nInt64\n\n\n\n\n1\n1\n462\n\n\n2\n2\n729\n\n\n3\n3\n1739\n\n\n4\n4\n8836\n\n\n5\n5\n96529\n\n\n\n\n\n\nA natural question at this point is whether there is something about those students who have few observations. For example, are they from only a few schools?\nOne approach to examining properties like is to add the number of observations for each child to the :Child table. Later we can group the table according to this :ntest to look at properties of :Child by :ntest.\n\ngdf = groupby(\n  disallowmissing!(leftjoin(Child, nobsChild; on=:Child)), :ntest\n)\n\nGroupedDataFrame with 5 groups based on key: ntestFirst Group (462 rows): ntest = 1437 rows omitted\n\n\n\nRow\nChild\nSchool\nCohort\nSex\nage\nntest\n\n\n\nString\nString\nString\nString\nFloat64\nInt64\n\n\n\n\n1\nC002452\nS101175\n2013\nmale\n7.99452\n1\n\n\n2\nC002625\nS103329\n2013\nmale\n7.99452\n1\n\n\n3\nC002754\nS104814\n2013\nfemale\n7.99452\n1\n\n\n4\nC003269\nS102258\n2012\nfemale\n7.99726\n1\n\n\n5\nC003599\nS105843\n2012\nfemale\n7.99726\n1\n\n\n6\nC003807\nS100754\n2011\nmale\n8.0\n1\n\n\n7\nC003985\nS102945\n2011\nmale\n8.0\n1\n\n\n8\nC004086\nS104255\n2011\nmale\n8.0\n1\n\n\n9\nC004657\nS101400\n2014\nmale\n8.03833\n1\n\n\n10\nC005036\nS105909\n2014\nmale\n8.03833\n1\n\n\n11\nC005440\nS101023\n2019\nmale\n8.05202\n1\n\n\n12\nC005523\nS101825\n2019\nfemale\n8.05202\n1\n\n\n13\nC005697\nS103615\n2019\nmale\n8.05202\n1\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n451\nC112638\nS103718\n2015\nfemale\n9.0486\n1\n\n\n452\nC114749\nS112938\n2017\nmale\n9.06502\n1\n\n\n453\nC115460\nS101953\n2015\nmale\n9.08145\n1\n\n\n454\nC115569\nS100572\n2017\nmale\n9.08419\n1\n\n\n455\nC115587\nS100754\n2017\nfemale\n9.08419\n1\n\n\n456\nC117108\nS103196\n2018\nfemale\n9.10609\n1\n\n\n457\nC117229\nS103615\n2018\nmale\n9.10609\n1\n\n\n458\nC117230\nS103615\n2018\nmale\n9.10609\n1\n\n\n459\nC117419\nS104954\n2018\nfemale\n9.10609\n1\n\n\n460\nC117437\nS105004\n2018\nmale\n9.10609\n1\n\n\n461\nC117539\nS105636\n2018\nmale\n9.10609\n1\n\n\n462\nC117659\nS106483\n2018\nfemale\n9.10609\n1\n\n\n\n⋮\n\n\nLast Group (96529 rows): ntest = 5\n\n\n96504 rows omitted\n\n\n\n\n\n\n\n\n\nRow\nChild\nSchool\nCohort\nSex\nage\nntest\n\n\n\nString\nString\nString\nString\nFloat64\nInt64\n\n\n\n\n1\nC002352\nS100067\n2013\nmale\n7.99452\n5\n\n\n2\nC002353\nS100067\n2013\nmale\n7.99452\n5\n\n\n3\nC002354\nS100067\n2013\nmale\n7.99452\n5\n\n\n4\nC002355\nS100122\n2013\nfemale\n7.99452\n5\n\n\n5\nC002356\nS100146\n2013\nmale\n7.99452\n5\n\n\n6\nC002357\nS100146\n2013\nmale\n7.99452\n5\n\n\n7\nC002358\nS100146\n2013\nmale\n7.99452\n5\n\n\n8\nC002360\nS100195\n2013\nfemale\n7.99452\n5\n\n\n9\nC002362\nS100237\n2013\nfemale\n7.99452\n5\n\n\n10\nC002363\nS100237\n2013\nfemale\n7.99452\n5\n\n\n11\nC002364\nS100250\n2013\nfemale\n7.99452\n5\n\n\n12\nC002365\nS100304\n2013\nmale\n7.99452\n5\n\n\n13\nC002366\nS100304\n2013\nmale\n7.99452\n5\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n96518\nC117942\nS130539\n2018\nmale\n9.10609\n5\n\n\n96519\nC117943\nS130539\n2018\nfemale\n9.10609\n5\n\n\n96520\nC117944\nS130539\n2018\nmale\n9.10609\n5\n\n\n96521\nC117945\nS130539\n2018\nmale\n9.10609\n5\n\n\n96522\nC117946\nS130539\n2018\nmale\n9.10609\n5\n\n\n96523\nC117956\nS400580\n2018\nmale\n9.10609\n5\n\n\n96524\nC117958\nS400919\n2018\nmale\n9.10609\n5\n\n\n96525\nC117959\nS400919\n2018\nmale\n9.10609\n5\n\n\n96526\nC117962\nS401250\n2018\nfemale\n9.10609\n5\n\n\n96527\nC117964\nS401470\n2018\nmale\n9.10609\n5\n\n\n96528\nC117965\nS401470\n2018\nfemale\n9.10609\n5\n\n\n96529\nC117966\nS800200\n2018\nmale\n9.10609\n5\n\n\n\n\n\n\n\nAre the sexes represented more-or-less equally?\n\ncombine(groupby(first(gdf), :Sex), nrow =&gt; :nchild)\n\n2×2 DataFrame\n\n\n\nRow\nSex\nnchild\n\n\n\nString\nInt64\n\n\n\n\n1\nmale\n230\n\n\n2\nfemale\n232\n\n\n\n\n\n\n\ncombine(groupby(last(gdf), :Sex), nrow =&gt; :nchild)\n\n2×2 DataFrame\n\n\n\nRow\nSex\nnchild\n\n\n\nString\nInt64\n\n\n\n\n1\nmale\n47552\n\n\n2\nfemale\n48977\n\n\n\n\n\n\nWhat about the distribution of ages?\n\n\"\"\"\n    ridgeplot!(ax::Axis, df::AbstractDataFrame, densvar::Symbol, group::Symbol; normalize=false)\n    ridgeplot!(f::Figure, args...; pos=(1,1) kwargs...)\n    ridgeplot(args...; kwargs...)\nCreate a \"ridge plot\".\nA ridge plot is stacked plot of densities for a given variable (`densvar`) grouped by a different variable (`group`). Because densities can very widely in scale, it is sometimes useful to `normalize` the densities so that each density has a maximum of 1.\nThe non-mutating method creates a Figure before calling the method for Figure.\nThe method for Figure places the ridge plot in the grid position specified by `pos`, default is (1,1).\n\"\"\"\nfunction ridgeplot!(\n  ax::Axis,\n  df::AbstractDataFrame,\n  densvar::Symbol,\n  group::Symbol;\n  normalize=false,\n)\n  # `normalize` makes it so that the max density is always 1\n  # `normalize` works on the density not the area/mass\n  gdf = groupby(df, group)\n  dens = combine(gdf, densvar =&gt; kde =&gt; :kde)\n  sort!(dens, group)\n  spacing = normalize ? 1.0 : 0.9 * maximum(dens[!, :kde]) do val\n    return maximum(val.density)\n  end\n\n  nticks = length(gdf)\n\n  for (idx, row) in enumerate(eachrow(dens))\n    dd = if normalize\n      row.kde.density ./ maximum(row.kde.density)\n    else\n      row.kde.density\n    end\n\n    offset = idx * spacing\n\n    lower = Observable(Point2f.(row.kde.x, offset))\n    upper = Observable(Point2f.(row.kde.x, dd .+ offset))\n    band!(ax, lower, upper; color=(:black, 0.3))\n    lines!(ax, upper; color=(:black, 1.0))\n  end\n\n  ax.yticks[] = (\n    1:spacing:(nticks * spacing), string.(dens[!, group])\n  )\n  ylims!(ax, 0, (nticks + 2) * spacing)\n  ax.xlabel[] = string(densvar)\n  ax.ylabel[] = string(group)\n\n  return ax\nend\n\n\nfunction ridgeplot!(f::Figure, args...; pos=(1, 1), kwargs...)\n  ridgeplot!(Axis(f[pos...]), args...; kwargs...)\n  return f\nend\n\n\n\"\"\"\n    ridgeplot(args...; kwargs...)\nSee [ridgeplot!](@ref).\n\"\"\"\nfunction ridgeplot(args...; kwargs...)\n  return ridgeplot!(Figure(), args...; kwargs...)\nend\n\n\nridgeplot(parent(gdf), :age, :ntest)\n\n\nparent(gdf)\n\n108295×6 DataFrame108270 rows omitted\n\n\n\nRow\nChild\nSchool\nCohort\nSex\nage\nntest\n\n\n\nString\nString\nString\nString\nFloat64\nInt64\n\n\n\n\n1\nC002352\nS100067\n2013\nmale\n7.99452\n5\n\n\n2\nC002353\nS100067\n2013\nmale\n7.99452\n5\n\n\n3\nC002354\nS100067\n2013\nmale\n7.99452\n5\n\n\n4\nC002355\nS100122\n2013\nfemale\n7.99452\n5\n\n\n5\nC002356\nS100146\n2013\nmale\n7.99452\n5\n\n\n6\nC002357\nS100146\n2013\nmale\n7.99452\n5\n\n\n7\nC002358\nS100146\n2013\nmale\n7.99452\n5\n\n\n8\nC002359\nS100183\n2013\nfemale\n7.99452\n4\n\n\n9\nC002360\nS100195\n2013\nfemale\n7.99452\n5\n\n\n10\nC002361\nS100213\n2013\nmale\n7.99452\n4\n\n\n11\nC002362\nS100237\n2013\nfemale\n7.99452\n5\n\n\n12\nC002363\nS100237\n2013\nfemale\n7.99452\n5\n\n\n13\nC002364\nS100250\n2013\nfemale\n7.99452\n5\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n108284\nC117943\nS130539\n2018\nfemale\n9.10609\n5\n\n\n108285\nC117944\nS130539\n2018\nmale\n9.10609\n5\n\n\n108286\nC117945\nS130539\n2018\nmale\n9.10609\n5\n\n\n108287\nC117946\nS130539\n2018\nmale\n9.10609\n5\n\n\n108288\nC117956\nS400580\n2018\nmale\n9.10609\n5\n\n\n108289\nC117957\nS400919\n2018\nmale\n9.10609\n4\n\n\n108290\nC117958\nS400919\n2018\nmale\n9.10609\n5\n\n\n108291\nC117959\nS400919\n2018\nmale\n9.10609\n5\n\n\n108292\nC117962\nS401250\n2018\nfemale\n9.10609\n5\n\n\n108293\nC117964\nS401470\n2018\nmale\n9.10609\n5\n\n\n108294\nC117965\nS401470\n2018\nfemale\n9.10609\n5\n\n\n108295\nC117966\nS800200\n2018\nmale\n9.10609\n5"
  },
  {
    "objectID": "arrow.html#reading-arrow-files-in-other-languages",
    "href": "arrow.html#reading-arrow-files-in-other-languages",
    "title": "Notes on saved data files",
    "section": "Reading Arrow files in other languages",
    "text": "Reading Arrow files in other languages\nThere are Arrow implementations for R (the arrow package) and for Python (pyarrow).\n#| eval: false\nimport pyarrow.feather: read_table\nread_table(\"./data/fggk21.arrow\")\n#| eval: false\nlibrary(\"arrow\")\nfggk21 &lt;- read_feather(\"./data/fggk21.arrow\")\nnrow(fggk21)"
  },
  {
    "objectID": "kb07.html",
    "href": "kb07.html",
    "title": "Bootstrapping a fitted model",
    "section": "",
    "text": "Begin by loading the packages to be used.\nCode\nusing AlgebraOfGraphics\nusing CairoMakie\nusing DataFrameMacros\nusing DataFrames\nusing MixedModels\nusing ProgressMeter\nusing Random\n\nCairoMakie.activate!(; type=\"svg\");\nProgressMeter.ijulia_behavior(:clear);\nProvide a short alias for AlgebraOfGraphics.\nconst AOG = AlgebraOfGraphics;"
  },
  {
    "objectID": "kb07.html#data-set-and-model",
    "href": "kb07.html#data-set-and-model",
    "title": "Bootstrapping a fitted model",
    "section": "Data set and model",
    "text": "Data set and model\nThe kb07 data (Kronmüller & Barr, 2007) are one of the datasets provided by the MixedModels package.\n\nkb07 = MixedModels.dataset(:kb07)\n\nArrow.Table with 1789 rows, 7 columns, and schema:\n :subj      String\n :item      String\n :spkr      String\n :prec      String\n :load      String\n :rt_trunc  Int16\n :rt_raw    Int16\n\n\nConvert the table to a DataFrame for summary.\n\nkb07 = DataFrame(kb07)\ndescribe(kb07)\n\n7×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nsubj\n\nS030\n\nS103\n0\nString\n\n\n2\nitem\n\nI01\n\nI32\n0\nString\n\n\n3\nspkr\n\nnew\n\nold\n0\nString\n\n\n4\nprec\n\nbreak\n\nmaintain\n0\nString\n\n\n5\nload\n\nno\n\nyes\n0\nString\n\n\n6\nrt_trunc\n2182.2\n579\n1940.0\n5171\n0\nInt16\n\n\n7\nrt_raw\n2226.24\n579\n1940.0\n15923\n0\nInt16\n\n\n\n\n\n\nThe experimental factors; spkr, prec, and load, are two-level factors. The EffectsCoding contrast is used with these to create a \\(\\pm1\\) encoding. Furthermore, Grouping constrasts are assigned to the subj and item factors. This is not a contrast per-se but an indication that these factors will be used as grouping factors for random effects and, therefore, there is no need to create a contrast matrix. For large numbers of levels in a grouping factor, an attempt to create a contrast matrix may cause memory overflow.\nIt is not important in these cases but a good practice in any case.\n\ncontrasts = merge(\n  Dict(nm =&gt; EffectsCoding() for nm in (:spkr, :prec, :load)),\n  Dict(nm =&gt; Grouping() for nm in (:subj, :item)),\n);\n\nThe display of an initial model fit\n\nkbm01 = let\n  form = @formula(\n    rt_trunc ~\n      1 +\n      spkr * prec * load +\n      (1 + spkr + prec + load | subj) +\n      (1 + spkr + prec + load | item)\n  )\n  fit(MixedModel, form, kb07; contrasts)\nend\n\nMinimizing 883   Time: 0:00:01 ( 1.38 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\nσ_item\n\n\n\n\n(Intercept)\n2181.6729\n77.2879\n28.23\n&lt;1e-99\n301.7871\n362.0938\n\n\nspkr: old\n67.7484\n18.2976\n3.70\n0.0002\n43.1536\n40.6843\n\n\nprec: maintain\n-333.9212\n47.1387\n-7.08\n&lt;1e-11\n62.0318\n246.8048\n\n\nload: yes\n78.7702\n19.5373\n4.03\n&lt;1e-04\n65.1901\n42.3299\n\n\nspkr: old & prec: maintain\n-21.9655\n15.8058\n-1.39\n0.1646\n\n\n\n\nspkr: old & load: yes\n18.3844\n15.8058\n1.16\n0.2448\n\n\n\n\nprec: maintain & load: yes\n4.5340\n15.8058\n0.29\n0.7742\n\n\n\n\nspkr: old & prec: maintain & load: yes\n23.6073\n15.8058\n1.49\n0.1353\n\n\n\n\nResidual\n668.4871\n\n\n\n\n\n\n\n\n\n\ndoes not include the estimated correlations of the random effects.\nThe VarCorr extractor displays these.\n\nVarCorr(kbm01)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\nsubj\n(Intercept)\n91075.4527\n301.7871\n\n\n\n\n\n\nspkr: old\n1862.2358\n43.1536\n+0.78\n\n\n\n\n\nprec: maintain\n3847.9447\n62.0318\n-0.59\n+0.03\n\n\n\n\nload: yes\n4249.7506\n65.1901\n+0.36\n+0.82\n+0.53\n\n\nitem\n(Intercept)\n131111.9379\n362.0938\n\n\n\n\n\n\nspkr: old\n1655.2134\n40.6843\n+0.44\n\n\n\n\n\nprec: maintain\n60912.6143\n246.8048\n-0.69\n+0.35\n\n\n\n\nload: yes\n1791.8243\n42.3299\n+0.32\n+0.16\n-0.14\n\n\nResidual\n\n446875.0375\n668.4871\n\n\n\n\n\n\n\n\nNone of the two-factor or three-factor interaction terms in the fixed-effects are significant. In the random-effects terms only the scalar random effects and the prec random effect for item appear to be warranted, leading to the reduced formula\n\nkbm02 = let\n  form = @formula(\n    rt_trunc ~\n      1 + spkr + prec + load + (1 | subj) + (1 + prec | item)\n  )\n  fit(MixedModel, form, kb07; contrasts)\nend\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_item\nσ_subj\n\n\n\n\n(Intercept)\n2181.8526\n77.4681\n28.16\n&lt;1e-99\n364.7126\n298.0259\n\n\nspkr: old\n67.8790\n16.0785\n4.22\n&lt;1e-04\n\n\n\n\nprec: maintain\n-333.7906\n47.4472\n-7.03\n&lt;1e-11\n252.5212\n\n\n\nload: yes\n78.5904\n16.0785\n4.89\n&lt;1e-05\n\n\n\n\nResidual\n680.0319\n\n\n\n\n\n\n\n\n\n\n\nVarCorr(kbm02)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\nitem\n(Intercept)\n133015.244\n364.713\n\n\n\n\nprec: maintain\n63766.936\n252.521\n-0.70\n\n\nsubj\n(Intercept)\n88819.436\n298.026\n\n\n\nResidual\n\n462443.388\n680.032\n\n\n\n\n\n\nThese two models are nested and can be compared with a likelihood-ratio test.\n\nMixedModels.likelihoodratiotest(kbm02, kbm01)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nrt_trunc ~ 1 + spkr + prec + load + (1 | subj) + (1 + prec | item)\n9\n28664\n\n\n\n\n\nrt_trunc ~ 1 + spkr + prec + load + spkr & prec + spkr & load + prec & load + spkr & prec & load + (1 + spkr + prec + load | subj) + (1 + spkr + prec + load | item)\n29\n28637\n27\n20\n0.1431\n\n\n\n\n\nThe p-value of approximately 14% leads us to prefer the simpler model, kbm02, to the more complex, kbm01."
  },
  {
    "objectID": "kb07.html#a-bootstrap-sample",
    "href": "kb07.html#a-bootstrap-sample",
    "title": "Bootstrapping a fitted model",
    "section": "A bootstrap sample",
    "text": "A bootstrap sample\nCreate a bootstrap sample of a few thousand parameter estimates from the reduced model. The pseudo-random number generator is initialized to a fixed value for reproducibility.\n\nRandom.seed!(1234321)\nhide_progress = true\nkbm02samp = parametricbootstrap(2000, kbm02; hide_progress);\n\nOne of the uses of such a sample is to form “confidence intervals” on the parameters by obtaining the shortest interval that covers a given proportion (95%, by default) of the sample.\n\nDataFrame(shortestcovint(kbm02samp))\n\n9×5 DataFrame\n\n\n\nRow\ntype\ngroup\nnames\nlower\nupper\n\n\n\nString\nString?\nString?\nFloat64\nFloat64\n\n\n\n\n1\nβ\nmissing\n(Intercept)\n2028.01\n2337.92\n\n\n2\nβ\nmissing\nspkr: old\n38.431\n99.5944\n\n\n3\nβ\nmissing\nprec: maintain\n-439.321\n-245.864\n\n\n4\nβ\nmissing\nload: yes\n46.0262\n107.511\n\n\n5\nσ\nitem\n(Intercept)\n261.196\n448.51\n\n\n6\nσ\nitem\nprec: maintain\n175.489\n312.051\n\n\n7\nρ\nitem\n(Intercept), prec: maintain\n-0.897984\n-0.445594\n\n\n8\nσ\nsubj\n(Intercept)\n228.099\n357.789\n\n\n9\nσ\nresidual\nmissing\n655.249\n701.497\n\n\n\n\n\n\nA sample like this can be used for more than just creating an interval because it approximates the distribution of the estimator. For the fixed-effects parameters the estimators are close to being normally distributed, Figure 1.\n\n\nCode\ndraw(\n  data(kbm02samp.β) * mapping(:β; color=:coefname) * AOG.density();\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\n\nFigure 1: Comparative densities of the fixed-effects coefficients in kbm02samp\n\n\n\n\n\n\nCode\ndraw(\n  data(\n    filter(\n      :column =&gt; ==(Symbol(\"(Intercept)\")), DataFrame(kbm02samp.σs)\n    ),\n  ) *\n  mapping(:σ; color=:group) *\n  AOG.density();\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\n\nFigure 2: Density plot of bootstrap samples standard deviation of random effects\n\n\n\n\n\n\nCode\ndraw(\n  data(filter(:type =&gt; ==(\"ρ\"), DataFrame(kbm02samp.allpars))) *\n  mapping(:value =&gt; \"Correlation\"; color=:names) *\n  AOG.density();\n  figure=(; resolution=(800, 450)),\n)\n\n\n\n\n\nFigure 3: Density plot of correlation parameters in bootstrap sample from model kbm02"
  },
  {
    "objectID": "kkl15.html",
    "href": "kkl15.html",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "",
    "text": "Kliegl et al. (2015) is a follow-up to Kliegl et al. (2010) (see also script mmt_kwdyz11.qmd) from an experiment looking at a variety of effects of visual cueing under four different cue-target relations (CTRs). In this experiment two rectangles are displayed (1) in horizontal orientation , (2) in vertical orientation, (3) in left diagonal orientation, or in (4) right diagonal orientation relative to a central fixation point. Subjects react to the onset of a small or a large visual target occuring at one of the four ends of the two rectangles. The target is cued validly on 70% of trials by a brief flash of the corner of the rectangle at which it appears; it is cued invalidly at the three other locations 10% of the trials each. This implies a latent imbalance in design that is not visiable in the repeated-measures ANOVA, but we will show its effect in the random-effect structure and conditional modes.\nThere are a couple of differences between the first and this follow-up experiment, rendering it more a conceptual than a direct replication. First, the original experiment was carried out at Peking University and this follow-up at Potsdam University. Second, diagonal orientations of rectangles and large target sizes were not part of the design of Kliegl et al. (2010). To keep matters somewhat simpler and comparable we ignore them in this script.\nWe specify three contrasts for the four-level factor CTR that are derived from spatial, object-based, and attractor-like features of attention. They map onto sequential differences between appropriately ordered factor levels. Replicating Kliegl et al. (2010), the attraction effect was not significant as a fixed effect, but yielded a highly reliable variance component (VC; i.e., reliable individual differences in positive and negative attraction effects cancel the fixed effect). Moreover, these individual differences in the attraction effect were negatively correlated with those in the spatial effect.\nThis comparison is of interest because a few years after the publication of Kliegl et al. (2010), the theoretically critical correlation parameter (CP) between the spatial effect and the attraction effect was determined as the source of a non-singular LMM in that paper. The present study served the purpose to estimate this parameter with a larger sample and a wider variety of experimental conditions. Therefore, the code in this script is largely the same as the one in kwdyz.jl.\nThere will be another vignette modelling the additional experimental manipulations of target size and orientation of cue rectangle. This analysis was reported in the parsimonious mixed-model paper (Bates et al., 2015); they were also used in a paper of GAMMs (Baayen et al., 2017). Data and R scripts are also available in R-package RePsychLing. Here we provide some of the corresponding analyses with MixedModels.jl and a much wider variety of visualizations of LMM results."
  },
  {
    "objectID": "kkl15.html#background",
    "href": "kkl15.html#background",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "",
    "text": "Kliegl et al. (2015) is a follow-up to Kliegl et al. (2010) (see also script mmt_kwdyz11.qmd) from an experiment looking at a variety of effects of visual cueing under four different cue-target relations (CTRs). In this experiment two rectangles are displayed (1) in horizontal orientation , (2) in vertical orientation, (3) in left diagonal orientation, or in (4) right diagonal orientation relative to a central fixation point. Subjects react to the onset of a small or a large visual target occuring at one of the four ends of the two rectangles. The target is cued validly on 70% of trials by a brief flash of the corner of the rectangle at which it appears; it is cued invalidly at the three other locations 10% of the trials each. This implies a latent imbalance in design that is not visiable in the repeated-measures ANOVA, but we will show its effect in the random-effect structure and conditional modes.\nThere are a couple of differences between the first and this follow-up experiment, rendering it more a conceptual than a direct replication. First, the original experiment was carried out at Peking University and this follow-up at Potsdam University. Second, diagonal orientations of rectangles and large target sizes were not part of the design of Kliegl et al. (2010). To keep matters somewhat simpler and comparable we ignore them in this script.\nWe specify three contrasts for the four-level factor CTR that are derived from spatial, object-based, and attractor-like features of attention. They map onto sequential differences between appropriately ordered factor levels. Replicating Kliegl et al. (2010), the attraction effect was not significant as a fixed effect, but yielded a highly reliable variance component (VC; i.e., reliable individual differences in positive and negative attraction effects cancel the fixed effect). Moreover, these individual differences in the attraction effect were negatively correlated with those in the spatial effect.\nThis comparison is of interest because a few years after the publication of Kliegl et al. (2010), the theoretically critical correlation parameter (CP) between the spatial effect and the attraction effect was determined as the source of a non-singular LMM in that paper. The present study served the purpose to estimate this parameter with a larger sample and a wider variety of experimental conditions. Therefore, the code in this script is largely the same as the one in kwdyz.jl.\nThere will be another vignette modelling the additional experimental manipulations of target size and orientation of cue rectangle. This analysis was reported in the parsimonious mixed-model paper (Bates et al., 2015); they were also used in a paper of GAMMs (Baayen et al., 2017). Data and R scripts are also available in R-package RePsychLing. Here we provide some of the corresponding analyses with MixedModels.jl and a much wider variety of visualizations of LMM results."
  },
  {
    "objectID": "kkl15.html#packages",
    "href": "kkl15.html#packages",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "Packages",
    "text": "Packages\n\n\nCode\nusing Arrow\nusing AlgebraOfGraphics\nusing CairoMakie\nusing CategoricalArrays\nusing Chain\nusing DataFrameMacros\nusing DataFrames\nusing MixedModels\nusing MixedModelsMakie\nusing Random\nusing ProgressMeter\nusing Statistics\nusing StatsBase\n\nusing AlgebraOfGraphics: density\nusing AlgebraOfGraphics: boxplot\nusing MixedModelsMakie: qqnorm\nusing MixedModelsMakie: ridgeplot\nusing MixedModelsMakie: scatter\nconst datadir = joinpath(@__DIR__, \"data\")\n\nProgressMeter.ijulia_behavior(:clear)\nCairoMakie.activate!(; type=\"png\")"
  },
  {
    "objectID": "kkl15.html#read-data-compute-and-plot-means",
    "href": "kkl15.html#read-data-compute-and-plot-means",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "Read data, compute and plot means",
    "text": "Read data, compute and plot means\n\ndat = @chain \"kkl15.arrow\" begin\n  joinpath(datadir, _)\n  Arrow.Table\n  DataFrame\n  select(\n    :subj =&gt;\n      (s -&gt; categorical(string.('S', lpad.(s, 3, '0')))) =&gt; :Subj,\n    :tar =&gt; categorical =&gt; :CTR,\n    :rt =&gt; (x -&gt; log.(x)) =&gt; :lrt,\n    :rt,\n  )\nend\nlevels!(dat.CTR, [\"val\", \"sod\", \"dos\", \"dod\"])\ndescribe(dat)\n\n4×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nSubj\n\nS001\n\nS147\n0\nCategoricalValue{String, UInt32}\n\n\n2\nCTR\n\nval\n\ndod\n0\nCategoricalValue{String, UInt32}\n\n\n3\nlrt\n5.64424\n5.0121\n5.62255\n6.61938\n0\nFloat64\n\n\n4\nrt\n293.147\n150.22\n276.594\n749.481\n0\nFloat64\n\n\n\n\n\n\nWe recommend to code the levels/units of random factor / grouping variable not as a number, but as a string starting with a letter and of the same length for all levels/units.\nWe also recommend to sort levels of factors into a meaningful order, that is overwrite the default alphabetic ordering. This is also a good place to choose alternative names for variables in the context of the present analysis.\nThe LMM analysis is based on log-transformed reaction times lrt, indicated by a boxcox() check of model residuals. With the exception of diagnostic plots of model residuals, the analysis of untransformed reaction times did not lead to different results.\nComparative density plots of all response times by cue-target relation show the times for valid cues to be faster than for the other conditions.\n\n\nCode\ndraw(\n  data(dat) *\n  mapping(\n    :lrt =&gt; \"log(Reaction time [ms])\";\n    color=:CTR =&gt;\n      renamer(\"val\" =&gt; \"valid cue\", \"sod\" =&gt; \"some obj/diff pos\", \"dos\" =&gt; \"diff obj/same pos\", \"dod\" =&gt; \"diff obj/diff pos\") =&gt; \"Cue-target relation\",\n  ) *\n  density();\n  figure=(; resolution=(800, 350)),\n)\n\n\n\n\n\nFigure 1: Compartive density plots of log response time by condition\n\n\n\n\nBoxplots of the mean of log response time by subject under the different conditions show an outlier value under three of the four conditions; they are from the same subject.\n\ndat_subj = combine(\n  groupby(dat, [:Subj, :CTR]),\n  :rt =&gt; length =&gt; :n,\n  :rt =&gt; mean =&gt; :rt_m,\n  :lrt =&gt; mean =&gt; :lrt_m,\n)\ndescribe(dat_subj)\n\n5×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nSubj\n\nS001\n\nS147\n0\nCategoricalValue{String, UInt32}\n\n\n2\nCTR\n\nval\n\ndod\n0\nCategoricalValue{String, UInt32}\n\n\n3\nn\n156.294\n49\n64.0\n448\n0\nInt64\n\n\n4\nrt_m\n308.223\n208.194\n304.862\n584.71\n0\nFloat64\n\n\n5\nlrt_m\n5.6908\n5.33226\n5.69848\n6.36141\n0\nFloat64\n\n\n\n\n\n\n\n\nCode\nboxplot(\n  dat_subj.CTR.refs,\n  dat_subj.lrt_m;\n  orientation=:horizontal,\n  show_notch=true,\n  axis=(;\n    yticks=(\n      1:4,\n      [\n        \"valid cue\",\n        \"same obj/diff pos\",\n        \"diff obj/same pos\",\n        \"diff obj/diff pos\",\n      ],\n    ),\n  ),\n  figure=(; resolution=(800, 300)),\n)\n\n\n\n\n\nFigure 2: Comparative boxplots of mean response by subject under different conditions\n\n\n\n\nMean of log reaction times for four cue-target relations. Targets appeared at (a) the cued position (valid) in a rectangle, (b) in the same rectangle cue, but at its other end, (c) on the second rectangle, but at a corresponding horizontal/vertical physical distance, or (d) at the other end of the second rectangle, that is \\(\\sqrt{2}\\) of horizontal/vertical distance diagonally across from the cue, that is also at larger physical distance compared to (c).\nWe remove the outlier subject and replot, but we model the data points in dat and check whether this subject appears as an outlier in the caterpillar plot of conditional modes.\n\n\nCode\nlet\n  dat_subj2 = @subset(dat_subj, :rt_m &lt; 510)\n  boxplot(\n    dat_subj2.CTR.refs,\n    dat_subj2.lrt_m;\n    orientation=:horizontal,\n    show_notch=true,\n    axis=(;\n      yticks=(\n        1:4,\n        [\n          \"valid cue\",\n          \"same obj/diff pos\",\n          \"diff obj/same pos\",\n          \"diff obj/diff pos\",\n        ],\n      ),\n    ),\n    figure=(; resolution=(800, 300)),\n  )\nend\n\n\n\n\n\nFigure 3: Comparative boxplots of mean response by subject under different conditions without outlier\n\n\n\n\nA better alternative to the boxplot is often a dotplot, because it also displays subjects’ condition means.\nTo be done\nFor the next set of plots we average subjects’ data within the four experimental conditions. This table could be used as input for a repeated-measures ANOVA.\n\ndat_cond = combine(\n  groupby(dat_subj, :CTR),\n  :n =&gt; length =&gt; :N,\n  :lrt_m =&gt; mean =&gt; :lrt_M,\n  :lrt_m =&gt; std =&gt; :lrt_SD,\n  :lrt_m =&gt; (x -&gt; std(x) / sqrt(length(x))) =&gt; :lrt_SE,\n)\n\n4×5 DataFrame\n\n\n\nRow\nCTR\nN\nlrt_M\nlrt_SD\nlrt_SE\n\n\n\nCat…\nInt64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\nval\n86\n5.61443\n0.15805\n0.0170429\n\n\n2\nsod\n86\n5.68836\n0.191395\n0.0206386\n\n\n3\ndos\n86\n5.72943\n0.191027\n0.0205989\n\n\n4\ndod\n86\n5.73099\n0.21628\n0.023322\n\n\n\n\n\n\nWe can also look at correlations plots based on the four condition means. There are actually two correlation matrices which have correspondences in alternative parameterizatios of the LMM random-effect structure. One matrix is based on the four measures. If you think of the four measures as test scores, this matrix is the usual correlation matrix. The second matrix contains correlations between the Grand Mean (GM) and the three effects defined with the contrasts for the four levels of the condition factor in the next chunk.\nTo this end, we\n\nuse the unstack() command to convert data from long to wide format,\ncompute the GM and the three experimental effects.\nplot the correlation matrix for four measures/scores, and\nplot the correlation matrix for GM and three effects\n\n\ndat_subj_w = @chain dat_subj begin\n  unstack(:Subj, :CTR, :rt_m)\n  disallowmissing!\n  @transform(\n    :GM = (:val + :sod + :dos + :dod) ./ 4,\n    :spatial = :sod - :val,\n    :object = :dos - :sod,\n    :attraction = :dod - :dos,\n  )\nend\ndescribe(dat_subj_w)\n\n9×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nSubj\n\nS001\n\nS147\n0\nCategoricalValue{String, UInt32}\n\n\n2\nval\n283.688\n216.35\n286.376\n513.53\n0\nFloat64\n\n\n3\nsod\n306.75\n213.444\n305.092\n562.015\n0\nFloat64\n\n\n4\ndos\n319.896\n215.787\n317.527\n584.71\n0\nFloat64\n\n\n5\ndod\n322.561\n208.194\n315.511\n555.206\n0\nFloat64\n\n\n6\nGM\n308.223\n217.819\n309.381\n553.865\n0\nFloat64\n\n\n7\nspatial\n23.0621\n-47.2036\n20.2272\n87.7873\n0\nFloat64\n\n\n8\nobject\n13.1456\n-13.8273\n11.7903\n61.0424\n0\nFloat64\n\n\n9\nattraction\n2.66497\n-43.8703\n-1.11887\n63.5347\n0\nFloat64\n\n\n\n\n\n\n\n#@df dat_subj_w StatsPlots.corrplot(cols(2:5), grid = false, compact=false)\n\n\n#@df dat_subj_w StatsPlots.corrplot(cols(6:9), grid = false, compact=false)\n\n\n\n\n\n\n\nNote\n\n\n\nTwo of the theoreticsally irrelevant within-subject effect correlations have a different sign than the corresponding, non-significant CPs in the LMM; they are negative here, numerically positive in the LMM. This occurs only very rarely in the case of ecological correlations. However, as they are not significant according to shortest coverage interval, it may not be that relevant either. It is the case both for effects based on log-transformed and raw reaction times."
  },
  {
    "objectID": "kkl15.html#linear-mixed-model",
    "href": "kkl15.html#linear-mixed-model",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "Linear mixed model",
    "text": "Linear mixed model\n\ncontrasts = Dict(\n  :Subj =&gt; Grouping(),\n  :CTR =&gt; SeqDiffCoding(; levels=[\"val\", \"sod\", \"dos\", \"dod\"]),\n)\nm1 = let\n  form = @formula lrt ~ 1 + CTR + (1 + CTR | Subj)\n  fit(MixedModel, form, dat; contrasts)\nend\n\nMinimizing 324   Time: 0:00:00 ( 0.53 ms/it)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n5.6907\n0.0199\n286.42\n&lt;1e-99\n0.1839\n\n\nCTR: sod\n0.0740\n0.0080\n9.30\n&lt;1e-19\n0.0688\n\n\nCTR: dos\n0.0409\n0.0038\n10.74\n&lt;1e-26\n0.0011\n\n\nCTR: dod\n0.0016\n0.0057\n0.28\n0.7771\n0.0387\n\n\nResidual\n0.1971\n\n\n\n\n\n\n\n\n\n\nVarCorr(m1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\nSubj\n(Intercept)\n0.03382587\n0.18391810\n\n\n\n\n\n\nCTR: sod\n0.00472955\n0.06877175\n+0.56\n\n\n\n\n\nCTR: dos\n0.00000126\n0.00112042\n-0.05\n+0.80\n\n\n\n\nCTR: dod\n0.00149691\n0.03868996\n+0.60\n+0.66\n+0.36\n\n\nResidual\n\n0.03884575\n0.19709326\n\n\n\n\n\n\n\n\n\nissingular(m1)\n\ntrue\n\n\n\nonly(MixedModels.PCA(m1))\n\n\nPrincipal components based on correlation matrix\n (Intercept)   1.0     .      .      .\n CTR: sod      0.56   1.0     .      .\n CTR: dos     -0.05   0.8    1.0     .\n CTR: dod      0.6    0.66   0.36   1.0\n\nNormalized cumulative variances:\n[0.6325, 0.9136, 1.0, 1.0]\n\nComponent loadings\n                PC1    PC2    PC3    PC4\n (Intercept)  -0.41   0.66  -0.47   0.42\n CTR: sod     -0.6   -0.18  -0.34  -0.7\n CTR: dos     -0.43  -0.69  -0.07   0.58\n CTR: dod     -0.53   0.25   0.81  -0.0\n\n\nWe note that the critical correlation parameter between spatial (sod) and attraction (dod) is now estimated at .66 – not that close to the 1.0 boundary that caused singularity in Kliegl et al. (2010). However, the LMM based on log reaction times is still singular. Let’s check for untransformed reaction times.\n\nm1_rt = let\n  form = @formula rt ~ 1 + CTR + (1 + CTR | Subj)\n  fit(MixedModel, form, dat; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n308.2059\n6.4152\n48.04\n&lt;1e-99\n59.3789\n\n\nCTR: sod\n23.0720\n2.6416\n8.73\n&lt;1e-17\n22.8512\n\n\nCTR: dos\n13.0855\n1.4585\n8.97\n&lt;1e-18\n6.8351\n\n\nCTR: dod\n2.6860\n2.0608\n1.30\n0.1924\n15.1021\n\n\nResidual\n65.2246\n\n\n\n\n\n\n\n\n\n\nVarCorr(m1_rt)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\nSubj\n(Intercept)\n3525.85438\n59.37891\n\n\n\n\n\n\nCTR: sod\n522.17688\n22.85119\n+0.66\n\n\n\n\n\nCTR: dos\n46.71799\n6.83506\n+0.35\n+0.15\n\n\n\n\nCTR: dod\n228.07278\n15.10208\n+0.53\n+0.65\n+0.30\n\n\nResidual\n\n4254.24728\n65.22459\n\n\n\n\n\n\n\n\n\nissingular(m1_rt)\n\nfalse\n\n\nFor untransformed reaction times, we see the model is not singular."
  },
  {
    "objectID": "kkl15.html#diagnostic-plots-of-lmm-residuals",
    "href": "kkl15.html#diagnostic-plots-of-lmm-residuals",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "Diagnostic plots of LMM residuals",
    "text": "Diagnostic plots of LMM residuals\nDo model residuals meet LMM assumptions? Classic plots are\n\nResidual over fitted\nQuantiles of model residuals over theoretical quantiles of normal distribution\n\n\nResidual-over-fitted plot\nThe slant in residuals show a lower and upper boundary of reaction times, that is we have have too few short and too few long residuals. Not ideal, but at least width of the residual band looks similar across the fitted values, that is there is no evidence for heteroskedasticity.\n\n\nCode\nscatter(fitted(m1), residuals(m1); alpha=0.3)\n\n\n\n\n\nFigure 4: Residuals versus fitted values for model m1\n\n\n\n\nWith many observations the scatterplot is not that informative. Contour plots or heatmaps may be an alternative.\n\n\nCode\nset_aog_theme!()\ndraw(\n  data((; f=fitted(m1), r=residuals(m1))) *\n  mapping(\n    :f =&gt; \"Fitted values from m1\", :r =&gt; \"Residuals from m1\"\n  ) *\n  density();\n)\n\n\n\n\n\nFigure 5: Heatmap of residuals versus fitted values for model m1\n\n\n\n\n\n\nQ-Q plot\nThe plot of quantiles of model residuals over corresponding quantiles of the normal distribution should yield a straight line along the main diagonal.\n\n\n\nCode\nqqnorm(m1; qqline=:none)\n\nFigure 6: ?(caption)\n\n\n\n\n\nCode\nqqnorm(m1_rt; qqline=:none)\n\nFigure 7: ?(caption)\n\n\n\n\nObserved and theoretical normal distribution\nThe violation of expectation is again due to the fact that the distribution of residuals is narrower than expected from a normal distribution. We can see this in this plot. Overall, it does not look too bad.\n\n\nCode\nlet\n  n = nrow(dat)\n  dat_rz = (;\n    value=vcat(residuals(m1) ./ std(residuals(m1)), randn(n)),\n    curve=repeat([\"residual\", \"normal\"]; inner=n),\n  )\n  draw(\n    data(dat_rz) *\n    mapping(:value; color=:curve) *\n    density(; bandwidth=0.1);\n  )\nend\n\n\n\n\n\nFigure 8: Kernel density plot of the standardized residuals for model m1 versus a standard normal"
  },
  {
    "objectID": "kkl15.html#conditional-modes",
    "href": "kkl15.html#conditional-modes",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "Conditional modes",
    "text": "Conditional modes\n\nCaterpillar plot\n\n\nCode\ncm1 = only(ranefinfo(m1))\ncaterpillar!(Figure(; resolution=(800, 1200)), cm1; orderby=2)\n\n\n\n\n\nFigure 9: Prediction intervals of the subject random effects in model m1\n\n\n\n\nWhen we order the conditional modes for GM, that is (Intercept), the outlier subject S113 becomes visible; the associated experimental effects are not unusual.\n\n\nCode\ncaterpillar!(Figure(; resolution=(800, 1200)), cm1; orderby=1)\n\n\n\n\n\nFigure 10: Prediction intervals of the subject random effects in model m1 ordered by mean response\n\n\n\n\nThe catepillar plot also reveals that credibilty intervals are much shorter for subjects’ Grand Means, shown in (Intercept), than the subjects’ experimental effects, because the latter are based on difference scores not means. Moreover, credibility intervals are shorter for the first spatial effect sod than the other two effects, because the spatial effect involves the valid condition which yielded three times as many trials than the other three conditions. Consequently, the spatial effect is more reliable. Unfortunately, due to differences in scaling of the x-axis of the panels this effect must be inferred. One option to reveal this difference is to reparameterize the LMM such model parameters estimate the conditional modes for the levels of condition rather than the contrast-based effects. This is accomplished by replacing the 1 in the random effect term with 0, as shown next.\n\nm1L = let\n  form = @formula rt ~ 1 + CTR + (0 + CTR | Subj)\n  fit(MixedModel, form, dat; contrasts)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Subj\n\n\n\n\n(Intercept)\n308.2059\n6.4199\n48.01\n&lt;1e-99\n\n\n\nCTR: sod\n23.0720\n2.6415\n8.73\n&lt;1e-17\n60.2203\n\n\nCTR: dos\n13.0855\n1.4589\n8.97\n&lt;1e-18\n62.5228\n\n\nCTR: dod\n2.6860\n2.0617\n1.30\n0.1926\n71.5967\n\n\nCTR: val\n\n\n\n\n47.3219\n\n\nResidual\n65.2245\n\n\n\n\n\n\n\n\n\n\nVarCorr(m1L)\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\nSubj\nCTR: val\n2239.3599\n47.3219\n\n\n\n\n\n\nCTR: sod\n3626.4889\n60.2203\n+0.94\n\n\n\n\n\nCTR: dos\n3909.1032\n62.5228\n+0.94\n+0.99\n\n\n\n\nCTR: dod\n5126.0921\n71.5967\n+0.89\n+0.98\n+0.98\n\n\nResidual\n\n4254.2348\n65.2245\n\n\n\n\n\n\n\n\nThe caterpillar plot for levels shows the effect of the number of trials on credibility intervals; they are obviously much shorter for the valid condition. Note that this effect is not visible in a repeated-measure ANOVA with four condition means per subject as input.\n\n\nCode\n@chain m1L begin\n  ranefinfo\n  only\n  caterpillar!(Figure(; resolution=(800, 1000)), _; orderby=1)\nend\n\n\n\n\n\nFigure 11: Prediction intervals of the subject random effects in model m1L\n\n\n\n\n\n\nShrinkage plot\n\nLog-transformed reaction times (LMM m1)\n\n\nCode\nshrinkageplot!(Figure(; resolution=(1000, 1200)), m1)\n\n\n\n\n\nFigure 12: Shrinkage plots of the subject random effects in model m1L\n\n\n\n\nThree of the CPs are imploded, but not the theoretically critical ones. These implosions did not occur (or were not as visible) for raw reaction times.\n\n\nRaw reaction times (LMM m1_rt)\n\n\nCode\nshrinkageplot!(Figure(; resolution=(1000, 1200)), m1_rt)\n\n\n\n\n\nFigure 13: Shrinkage plots of the subject random effects in model m1_rt\n\n\n\n\nThe implosion is for three CP visualizations is not observed for raw reaction times. Interesting."
  },
  {
    "objectID": "kkl15.html#parametric-bootstrap",
    "href": "kkl15.html#parametric-bootstrap",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "Parametric bootstrap",
    "text": "Parametric bootstrap\nHere we\n\ngenerate a bootstrap sample\ncompute shortest covergage intervals for the LMM parameters\nplot densities of bootstrapped parameter estimates for residual, fixed effects, variance components, and correlation parameters\n\n\nGenerate a bootstrap sample\nWe generate 2500 samples for the 15 model parameters (4 fixed effect, 4 VCs, 6 CPs, and 1 residual).\n\nsamp = parametricbootstrap(MersenneTwister(1234321), 2500, m1;\n                           optsum_overrides=(; ftol_rel=1e-8));\n\n\ndat2 = DataFrame(samp.allpars)\nfirst(dat2, 10)\n\n10×5 DataFrame\n\n\n\nRow\niter\ntype\ngroup\nnames\nvalue\n\n\n\nInt64\nString\nString?\nString?\nFloat64\n\n\n\n\n1\n1\nβ\nmissing\n(Intercept)\n5.65296\n\n\n2\n1\nβ\nmissing\nCTR: sod\n0.0776058\n\n\n3\n1\nβ\nmissing\nCTR: dos\n0.0390975\n\n\n4\n1\nβ\nmissing\nCTR: dod\n-0.00227358\n\n\n5\n1\nσ\nSubj\n(Intercept)\n0.172726\n\n\n6\n1\nσ\nSubj\nCTR: sod\n0.0724938\n\n\n7\n1\nρ\nSubj\n(Intercept), CTR: sod\n0.37604\n\n\n8\n1\nσ\nSubj\nCTR: dos\n0.0132321\n\n\n9\n1\nρ\nSubj\n(Intercept), CTR: dos\n0.308332\n\n\n10\n1\nρ\nSubj\nCTR: sod, CTR: dos\n-0.0694926\n\n\n\n\n\n\n\nnrow(dat2) # 2500 estimates for each of 15 model parameters\n\n37500\n\n\n\n\nShortest coverage interval\n\nDataFrame(shortestcovint(samp))\n\n15×5 DataFrame\n\n\n\nRow\ntype\ngroup\nnames\nlower\nupper\n\n\n\nString\nString?\nString?\nFloat64\nFloat64\n\n\n\n\n1\nβ\nmissing\n(Intercept)\n5.65481\n5.7307\n\n\n2\nβ\nmissing\nCTR: sod\n0.0590247\n0.0895861\n\n\n3\nβ\nmissing\nCTR: dos\n0.0333873\n0.0485981\n\n\n4\nβ\nmissing\nCTR: dod\n-0.00842478\n0.0132909\n\n\n5\nσ\nSubj\n(Intercept)\n0.156037\n0.211141\n\n\n6\nσ\nSubj\nCTR: sod\n0.0565917\n0.0802134\n\n\n7\nρ\nSubj\n(Intercept), CTR: sod\n0.402446\n0.731505\n\n\n8\nσ\nSubj\nCTR: dos\n0.000631101\n0.017703\n\n\n9\nρ\nSubj\n(Intercept), CTR: dos\n-0.999999\n0.920431\n\n\n10\nρ\nSubj\nCTR: sod, CTR: dos\n-0.89795\n0.999998\n\n\n11\nσ\nSubj\nCTR: dod\n0.028268\n0.049033\n\n\n12\nρ\nSubj\n(Intercept), CTR: dod\n0.386061\n0.816622\n\n\n13\nρ\nSubj\nCTR: sod, CTR: dod\n0.436493\n0.887933\n\n\n14\nρ\nSubj\nCTR: dos, CTR: dod\n-0.860609\n0.831012\n\n\n15\nσ\nresidual\nmissing\n0.195905\n0.198269\n\n\n\n\n\n\nWe can also visualize the shortest coverage intervals for fixed effects with the ridgeplot() command:\n\n\nCode\nridgeplot(samp; show_intercept=false)\n\n\n\n\n\nFigure 14: Ridge plot of fixed-effects bootstrap samples from model m1L\n\n\n\n\n\n\nComparative density plots of bootstrapped parameter estimates\n\nResidual\n\n\nCode\ndraw(\n  data(@subset(dat2, :type == \"σ\" && :group == \"residual\")) *\n  mapping(:value =&gt; \"Residual\") *\n  density();\n  figure=(; resolution=(800, 400)),\n)\n\n\n\n\n\nFigure 15: Kernel density estimate from bootstrap samples of the residual standard deviation for model m1L\n\n\n\n\n\n\nFixed effects and associated variance components (w/o GM)\nThe shortest coverage interval for the GM ranges from 376 to 404 ms and the associate variance component from .15 to .21. To keep the plot range small we do not include their densities here.\n\n\nCode\nrn = renamer([\n  \"(Intercept)\" =&gt; \"GM\",\n  \"CTR: sod\" =&gt; \"spatial effect\",\n  \"CTR: dos\" =&gt; \"object effect\",\n  \"CTR: dod\" =&gt; \"attraction effect\",\n  \"(Intercept), CTR: sod\" =&gt; \"GM, spatial\",\n  \"(Intercept), CTR: dos\" =&gt; \"GM, object\",\n  \"CTR: sod, CTR: dos\" =&gt; \"spatial, object\",\n  \"(Intercept), CTR: dod\" =&gt; \"GM, attraction\",\n  \"CTR: sod, CTR: dod\" =&gt; \"spatial, attraction\",\n  \"CTR: dos, CTR: dod\" =&gt; \"object, attraction\",\n])\ndraw(\n  data(@subset(dat2, :type == \"β\" && :names ≠ \"(Intercept)\")) *\n  mapping(\n    :value =&gt; \"Experimental effect size [ms]\";\n    color=:names =&gt; rn =&gt; \"Experimental effects\",\n  ) *\n  density();\n  figure=(; resolution=(800, 350)),\n)\n\n\n\n\n\nFigure 16: Kernel density estimate from bootstrap samples of the fixed effects for model m1L\n\n\n\n\nThe densitiies correspond nicely with the shortest coverage intervals.\n\n\nCode\ndraw(\n  data(@subset(dat2, :type == \"σ\" && :group == \"Subj\" && :names ≠ \"(Intercept)\") ) *\n  mapping(\n    :value =&gt; \"Standard deviations [ms]\";\n    color=:names =&gt; rn =&gt; \"Variance components\",\n  ) *\n  density();\n  figure=(; resolution=(800, 350)),\n)\n\n\n\n\n\nFigure 17: Kernel density estimate from bootstrap samples of the standard deviations for model m1L (excluding Grand Mean)\n\n\n\n\nThe VC are all very nicely defined.\n\n\nCorrelation parameters (CPs)\n\n\nCode\ndraw(\n  data(@subset(dat2, :type == \"ρ\")) *\n  mapping(\n    :value =&gt; \"Correlation\";\n    color=:names =&gt; rn =&gt; \"Correlation parameters\",\n  ) *\n  density();\n  figure=(; resolution=(800, 350)),\n)\n\n\n\n\n\nFigure 18: Kernel density estimate from bootstrap samples of the standard deviations for model m1L\n\n\n\n\nThree CPs stand out positively, the correlation between GM and the spatial effect, GM and attraction effect, and the correlation between spatial and attraction effects. The second CP was positive, but not significant in the first study. The third CP replicates a CP that was judged questionable in script kwdyz11.jl.\nThe three remaining CPs are not well defined for log-transformed reaction times; they only fit noise and should be removed. It is also possible that fitting the complex experimental design (including target size and rectangle orientation) will lead to more acceptable estimates. The corresponding plot based on LMM m1_rt for raw reaction times still shows them with very wide distributions, but acceptable."
  },
  {
    "objectID": "kkl15.html#kkl",
    "href": "kkl15.html#kkl",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "KKL",
    "text": "KKL\n\n# coeftable(m1)\n# VarCorr(m1)\n# m1_bak = m1;\n# m1_pr = profile(m1)\n\n# coeftable(m1L)\n# VarCorr(m1L_bak)\n# m1L_bak = m1L;\n# m1L_prf = profile(m1L)"
  },
  {
    "objectID": "kkl15.html#example",
    "href": "kkl15.html#example",
    "title": "RePsychLing Kliegl, Kuschela, & Laubrock (2015)",
    "section": "Example",
    "text": "Example\nhttps://dmbates.quarto.pub/plotting-profiles/#the-penicillin-example\n\nusing BSplineKit\ninclude(pkgdir(MixedModels, \"test\", \"modelcache.jl\"));\n\nThis works, …\n\nslpr01 = profile(models(:sleepstudy)[1]);\nshow(slpr01.m)\nTable(slpr01.tbl)\n\nslpr02 = profile(models(:sleepstudy)[2]);\nshow(slpr02.m)\nTable(slpr02.tbl)\n\nslpr03 = profile(models(:sleepstudy)[3]);\nshow(slpr03.m)\nTable(slpr03.tbl)\n\nslpr04 = profile(models(:sleepstudy)[4]);\nshow(slpr04.m)\nTable(slpr04.tbl)\n\nLinear mixed model fit by maximum likelihood\n reaction ~ 1 + days + (1 | subj)\n   logLik   -2 logLik     AIC       AICc        BIC    \n  -897.0393  1794.0786  1802.0786  1802.3072  1814.8505\n\nVariance components:\n            Column    Variance Std.Dev.\nsubj     (Intercept)  1296.8707 36.0121\nResidual               954.5278 30.8954\n Number of obs: 180; levels of grouping factors: 18\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n                Coef.  Std. Error      z  Pr(&gt;|z|)\n──────────────────────────────────────────────────\n(Intercept)  251.405     9.50619   26.45    &lt;1e-99\ndays          10.4673    0.801735  13.06    &lt;1e-38\n──────────────────────────────────────────────────Linear mixed model fit by maximum likelihood\n reaction ~ 1 + days + zerocorr(1 + days | subj)\n   logLik   -2 logLik     AIC       AICc        BIC    \n  -876.0016  1752.0033  1762.0033  1762.3481  1777.9680\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\nsubj     (Intercept)  584.25897 24.17145\n         days          33.63281  5.79938   .  \nResidual              653.11578 25.55613\n Number of obs: 180; levels of grouping factors: 18\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n                Coef.  Std. Error      z  Pr(&gt;|z|)\n──────────────────────────────────────────────────\n(Intercept)  251.405      6.70771  37.48    &lt;1e-99\ndays          10.4673     1.51931   6.89    &lt;1e-11\n──────────────────────────────────────────────────Linear mixed model fit by maximum likelihood\n reaction ~ 1 + days + (1 | subj) + (0 + days | subj)\n   logLik   -2 logLik     AIC       AICc        BIC    \n  -876.0016  1752.0033  1762.0033  1762.3481  1777.9680\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\nsubj     (Intercept)  584.25897 24.17145\n         days          33.63281  5.79938   .  \nResidual              653.11578 25.55613\n Number of obs: 180; levels of grouping factors: 18\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n                Coef.  Std. Error      z  Pr(&gt;|z|)\n──────────────────────────────────────────────────\n(Intercept)  251.405      6.70771  37.48    &lt;1e-99\ndays          10.4673     1.51931   6.89    &lt;1e-11\n──────────────────────────────────────────────────Linear mixed model fit by maximum likelihood\n reaction ~ 1 + days + (1 + days | subj)\n   logLik   -2 logLik     AIC       AICc        BIC    \n  -875.9697  1751.9393  1763.9393  1764.4249  1783.0971\n\nVariance components:\n            Column    Variance Std.Dev.   Corr.\nsubj     (Intercept)  565.51067 23.78047\n         days          32.68212  5.71683 +0.08\nResidual              654.94145 25.59182\n Number of obs: 180; levels of grouping factors: 18\n\n  Fixed-effects parameters:\n──────────────────────────────────────────────────\n                Coef.  Std. Error      z  Pr(&gt;|z|)\n──────────────────────────────────────────────────\n(Intercept)  251.405      6.63226  37.91    &lt;1e-99\ndays          10.4673     1.50224   6.97    &lt;1e-11\n──────────────────────────────────────────────────\n\n\n┌ Warning: Reverse spline for θ3 is not monotone.\n└ @ MixedModels ~/.julia/packages/MixedModels/8zfgx/src/profile/thetapr.jl:101\n\n\nTable with 11 columns and 176 rows:\n      p   ζ          β1       β2       σ        σ1       σ2       ρ1           ⋯\n    ┌───────────────────────────────────────────────────────────────────────────\n 1  │ σ   -4.36503   251.405  10.4673  20.1932  25.5124  5.97301  -0.0159131   ⋯\n 2  │ σ   -3.77904   251.405  10.4673  20.8002  25.3438  5.94784  -0.00710078  ⋯\n 3  │ σ   -3.20527   251.405  10.4673  21.4254  25.1637  5.92087  0.00248319   ⋯\n 4  │ σ   -2.64337   251.405  10.4673  22.0695  24.9702  5.89214  0.012907     ⋯\n 5  │ σ   -2.09299   251.405  10.4673  22.7328  24.7643  5.86136  0.0241931    ⋯\n 6  │ σ   -1.55378   251.405  10.4673  23.4162  24.5428  5.82877  0.0366321    ⋯\n 7  │ σ   -1.02543   251.405  10.4673  24.12    24.3063  5.79389  0.0501628    ⋯\n 8  │ σ   -0.507599  251.405  10.4673  24.845   24.0524  5.75671  0.0649787    ⋯\n 9  │ σ   0.0        251.405  10.4673  25.5918  23.7805  5.71683  0.0813321    ⋯\n 10 │ σ   0.497686   251.405  10.4673  26.3611  23.4886  5.67432  0.0992821    ⋯\n 11 │ σ   0.985732   251.405  10.4673  27.1535  23.1743  5.62882  0.119204     ⋯\n 12 │ σ   1.46442    251.405  10.4673  27.9696  22.8367  5.58018  0.141273     ⋯\n 13 │ σ   1.93403    251.405  10.4673  28.8104  22.4706  5.52776  0.166019     ⋯\n 14 │ σ   2.39482    251.405  10.4673  29.6764  22.0801  5.47229  0.193399     ⋯\n 15 │ σ   2.84705    251.405  10.4673  30.5684  21.6557  5.41246  0.224354     ⋯\n 16 │ σ   3.29096    251.405  10.4673  31.4872  21.1965  5.3481   0.259426     ⋯\n 17 │ σ   3.72678    251.405  10.4673  32.4337  20.6982  5.27896  0.299389     ⋯\n 18 │ σ   4.15477    251.405  10.4673  33.4086  20.1547  5.20514  0.34522      ⋯\n 19 │ β1  -4.21288   214.928  11.6039  25.5918  43.5445  5.82873  0.0813321    ⋯\n 20 │ β1  -3.95915   218.244  11.5009  25.5918  40.807   5.80949  0.0813321    ⋯\n 21 │ β1  -3.68345   221.56   11.397   25.592   38.1596  5.79179  0.0813321    ⋯\n 22 │ β1  -3.38345   224.876  11.2936  25.5919  35.6269  5.7761   0.0813321    ⋯\n 23 │ β1  -3.05683   228.192  11.1908  25.5926  33.2285  5.76131  0.0813321    ⋯\n ⋮  │ ⋮       ⋮         ⋮        ⋮        ⋮        ⋮        ⋮          ⋮       ⋱\n\n\n\nfunction fwdspline(pr::MixedModelProfile, par::Symbol)\n    spl = pr.fwd[par]\n    xv = spl.x\n    yv = spl.(xv)\n    minv = findmin(abs, yv)\n    est = xv[last(minv)]\n    slope = (Derivative(1) * spl)(est)\n    return (; spl, xv, yv, slope, intercept = first(minv) - slope * est)\nend\n\nfwdspline (generic function with 1 method)\n\n\n\nlet\n    f = Figure(; resolution=(700,600))\n    ax = Axis(f[1,1]; xlabel = \"θ₁\", ylabel=\"ζ\")\n    (; spl, xv, yv, slope, intercept) = fwdspline(slpr03, :θ1)\n    lines!(ax, first(xv) .. last(xv), identity ∘ spl;)\n    scatter!(ax, xv, yv)\n    ablines!(ax, intercept, slope)\n    f\nend\n\n\n\n\nWe see that in both cases the profile function is concave down over the region of interest. The ideal situation is for the profile to be close to a straight line suggesting a transformation like the square root.\n\nlet\n    f = Figure(; resolution=(700,600))\n    ax = Axis(f[1,1]; xlabel = \"√θ₂\", ylabel=\"ζ\")\n    (; spl, xv, yv) = fwdspline(slpr03, :θ2)\n    lines!(ax, sqrt(first(xv) + sqrt(eps())) .. sqrt(last(xv)), spl ∘ abs2;)\n    scatter!(ax, sqrt.(xv), yv)\n    f\nend\n\n\n\n\nAlthough it is tempting to use a logarithmic transformation of the theta parameter instead of the square root, we must allow the theta parameters to take on the value of zero, which is not possible when using a logarithmic transformation.\n\nfunction extractzeta(pr::MixedModelProfile)\n    (; tbl, fwd) = pr\n    tbl = Table(tbl)\n    rounddownabs(x) = (abs(x) &lt; 1.0e-5 ? 0. : x)\n    pnms = sort!(collect(keys(fwd)))\n    ptbl = NamedTuple{(pnms...,)}(ntuple(length(pnms)) do i\n        k = pnms[i]\n        rounddownabs.(fwd[k].(getproperty(tbl, k)))\n    end\n    )\n\n    Table(merge((; p=tbl.p), ptbl))\nend\n\nextractzeta (generic function with 1 method)\n\n\n\nslpr03zeta = extractzeta(slpr03)\n\nTable with 8 columns and 151 rows:\n      p   β1        β2        θ1         θ2          σ          σ1          ⋯\n    ┌────────────────────────────────────────────────────────────────────────\n 1  │ σ   0.0       0.0       1.22659    1.22659     -4.35251   0.232791    ⋯\n 2  │ σ   0.0       0.0       1.07836    1.07836     -3.76931   0.207962    ⋯\n 3  │ σ   0.0       0.0       0.928444   0.928448    -3.198     0.181947    ⋯\n 4  │ σ   0.0       0.0       0.776963   0.776951    -2.63822   0.154743    ⋯\n 5  │ σ   0.0       0.0       0.623994   0.623975    -2.08961   0.126313    ⋯\n 6  │ σ   0.0       0.0       0.469643   0.469643    -1.55181   0.0966386   ⋯\n 7  │ σ   0.0       0.0       0.314044   0.314109    -1.0245    0.0656912   ⋯\n 8  │ σ   0.0       0.0       0.15742    0.157508    -0.507334  0.0334798   ⋯\n 9  │ σ   0.0       0.0       0.0        0.0         0.0        0.0         ⋯\n 10 │ σ   0.0       0.0       -0.158154  -0.158156   0.497807   -0.0348562  ⋯\n 11 │ σ   0.0       0.0       -0.316835  -0.316807   0.986399   -0.0710259  ⋯\n 12 │ σ   0.0       0.0       -0.4757    -0.475716   1.46606    -0.108477   ⋯\n 13 │ σ   0.0       0.0       -0.634718  -0.634535   1.93709    -0.147453   ⋯\n 14 │ σ   0.0       0.0       -0.793274  -0.793269   2.39975    -0.187567   ⋯\n 15 │ σ   0.0       0.0       -0.95145   -0.951428   2.8543     -0.229221   ⋯\n 16 │ σ   0.0       0.0       -1.10884   -1.10886    3.30102    -0.2723     ⋯\n 17 │ σ   0.0       0.0       -1.26527   -1.26527    3.74014    -0.316957   ⋯\n 18 │ σ   0.0       0.0       -1.42042   -1.42042    4.17191    -0.363193   ⋯\n 19 │ β1  -4.24448  0.406406  2.46969    -0.0792392  0.0340255  2.55374     ⋯\n 20 │ β1  -3.98797  0.414794  2.20812    -0.0769013  0.0336483  2.28855     ⋯\n 21 │ β1  -3.70904  0.419764  1.93448    -0.0734987  0.0327812  2.00999     ⋯\n 22 │ β1  -3.40534  0.419646  1.65117    -0.0687154  0.0312409  1.72018     ⋯\n 23 │ β1  -3.07466  0.412317  1.36231    -0.0622537  0.0288394  1.42335     ⋯\n ⋮  │ ⋮      ⋮         ⋮          ⋮          ⋮           ⋮          ⋮       ⋱\n\n\n\nlet\n    f = Figure(; resolution=(700, 700))\n    ax = Axis(f[1,1]; aspect = 1, xlabel=\"ζ(θ₁)\", ylabel=\"ζ(θ₂)\")\n    tbl = filter(r -&gt; r.p == :θ1, slpr03zeta)\n    scatterlines!(ax, tbl.θ1, tbl.θ2)\n    tbl = filter(r -&gt; r.p == :θ2, slpr03zeta)\n    scatterlines!(ax, tbl.θ1, tbl.θ2)\n    f\nend"
  },
  {
    "objectID": "contrasts_fggk21.html",
    "href": "contrasts_fggk21.html",
    "title": "Mixed Models Tutorial: Contrast Coding",
    "section": "",
    "text": "Ths script uses a subset of data reported in Fühner, Golle, Granacher, & Kliegl (2021). Age and sex effects in physical fitness components of 108,295 third graders including 515 primary schools and 9 cohorts. (Fuenher2021?)\nTo circumvent delays associated with model fitting we work with models that are less complex than those in the reference publication. All the data to reproduce the models in the publication are used here, too; the script requires only a few changes to specify the more complex models in the paper.\nAll children were between 6.0 and 6.99 years at legal keydate (30 September) of school enrollement, that is in their ninth year of life in the third grade. To avoid delays associated with model fitting we work with a reduced data set and less complex models than those in the reference publication. The script requires only a few changes to specify the more complex models in the paper.\nThe script is structured in three main sections:"
  },
  {
    "objectID": "contrasts_fggk21.html#setup",
    "href": "contrasts_fggk21.html#setup",
    "title": "Mixed Models Tutorial: Contrast Coding",
    "section": "1. Setup",
    "text": "1. Setup\n\n1.0 Packages and functions\n\n\nCode\nusing AlgebraOfGraphics\nusing AlgebraOfGraphics: linear\nusing Arrow\nusing CairoMakie\nusing Chain\nusing CategoricalArrays\nusing DataFrames\nusing DataFrameMacros\nusing MixedModels\nusing ProgressMeter\nusing Statistics\nusing StatsBase\n\nProgressMeter.ijulia_behavior(:clear);\n\n\n\n\n1.1 Readme for ‘./data/fggk21.rds’\nNumber of scores: 525126\n\nCohort: 9 levels; 2011-2019\nSchool: 515 levels\nChild: 108295 levels; all children are between 8.0 and 8.99 years old\nSex: “Girls” (n=55,086), “Boys” (n= 53,209)\nage: testdate - middle of month of birthdate\nTest: 5 levels\n\nEndurance (Run): 6 minute endurance run [m]; to nearest 9m in 9x18m field\nCoordination (Star_r): star coordination run [m/s]; 9x9m field, 4 x diagonal = 50.912 m\nSpeed(S20_r): 20-meters sprint [m/s]\nMuscle power low (SLJ): standing long jump [cm]\nMuscle power up (BPT): 1-kg medicine ball push test [m]\n\nscore - see units\n\n\n\n1.2 Preprocessing\n\n1.2.1 Read data\n\ntbl = Arrow.Table(\"./data/fggk21.arrow\")\n\nArrow.Table with 525126 rows, 7 columns, and schema:\n :Cohort  String\n :School  String\n :Child   String\n :Sex     String\n :age     Float64\n :Test    String\n :score   Float64\n\n\n\ndf = DataFrame(tbl)\ndescribe(df)\n\n7×7 DataFrame\n\n\n\nRow\nvariable\nmean\nmin\nmedian\nmax\nnmissing\neltype\n\n\n\nSymbol\nUnion…\nAny\nUnion…\nAny\nInt64\nDataType\n\n\n\n\n1\nCohort\n\n2011\n\n2019\n0\nString\n\n\n2\nSchool\n\nS100043\n\nS800200\n0\nString\n\n\n3\nChild\n\nC002352\n\nC117966\n0\nString\n\n\n4\nSex\n\nfemale\n\nmale\n0\nString\n\n\n5\nage\n8.56073\n7.99452\n8.55852\n9.10609\n0\nFloat64\n\n\n6\nTest\n\nBPT\n\nStar_r\n0\nString\n\n\n7\nscore\n226.141\n1.14152\n4.65116\n1530.0\n0\nFloat64\n\n\n\n\n\n\n\n\n1.2.3 Extract a stratified subsample\nWe extract a random sample of 500 children from the Sex (2) x Test (5) cells of the design. Cohort and School are random.\n\nbegin\n  dat = @chain df begin\n    @transform(:Sex = :Sex == \"female\" ? \"Girls\" : \"Boys\")\n    @groupby(:Test, :Sex)\n    combine(x -&gt; x[sample(1:nrow(x), 500), :])\n  end\nend\n\n5000×7 DataFrame4975 rows omitted\n\n\n\nRow\nTest\nSex\nCohort\nSchool\nChild\nage\nscore\n\n\n\nString\nString\nString\nString\nString\nFloat64\nFloat64\n\n\n\n\n1\nS20_r\nBoys\n2013\nS102635\nC087137\n8.82683\n3.63636\n\n\n2\nS20_r\nBoys\n2018\nS105636\nC101782\n8.93908\n4.25532\n\n\n3\nS20_r\nBoys\n2017\nS100560\nC110754\n9.02396\n4.87805\n\n\n4\nS20_r\nBoys\n2014\nS102416\nC073691\n8.70363\n4.44444\n\n\n5\nS20_r\nBoys\n2016\nS111508\nC094432\n8.87885\n4.87805\n\n\n6\nS20_r\nBoys\n2016\nS104814\nC095946\n8.88433\n4.44444\n\n\n7\nS20_r\nBoys\n2016\nS104917\nC061975\n8.60233\n4.44444\n\n\n8\nS20_r\nBoys\n2015\nS111314\nC030041\n8.31759\n4.54545\n\n\n9\nS20_r\nBoys\n2019\nS104723\nC057313\n8.55578\n5.26316\n\n\n10\nS20_r\nBoys\n2017\nS103329\nC069149\n8.66256\n3.63636\n\n\n11\nS20_r\nBoys\n2013\nS103251\nC030686\n8.33128\n4.08163\n\n\n12\nS20_r\nBoys\n2018\nS101679\nC062325\n8.6078\n4.7619\n\n\n13\nS20_r\nBoys\n2012\nS102775\nC031649\n8.33402\n4.08163\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n4989\nRun\nGirls\n2012\nS104887\nC041152\n8.41615\n999.0\n\n\n4990\nRun\nGirls\n2015\nS102052\nC058624\n8.56947\n891.0\n\n\n4991\nRun\nGirls\n2015\nS102003\nC029349\n8.30664\n891.0\n\n\n4992\nRun\nGirls\n2018\nS100183\nC052461\n8.52567\n1240.0\n\n\n4993\nRun\nGirls\n2014\nS101291\nC009332\n8.1232\n1004.0\n\n\n4994\nRun\nGirls\n2011\nS103287\nC041870\n8.41889\n828.0\n\n\n4995\nRun\nGirls\n2017\nS106409\nC035125\n8.36687\n1134.0\n\n\n4996\nRun\nGirls\n2012\nS100158\nC050156\n8.50103\n792.0\n\n\n4997\nRun\nGirls\n2015\nS100626\nC009072\n8.11499\n1142.0\n\n\n4998\nRun\nGirls\n2018\nS101758\nC043116\n8.44079\n810.0\n\n\n4999\nRun\nGirls\n2011\nS104206\nC088798\n8.83231\n981.0\n\n\n5000\nRun\nGirls\n2012\nS100596\nC098677\n8.91718\n783.0\n\n\n\n\n\n\n\n\n1.2.2 Transformations\n\nbegin\n  transform!(dat, :age, :age =&gt; (x -&gt; x .- 8.5) =&gt; :a1) # centered age (linear)\n  select!(groupby(dat, :Test), :, :score =&gt; zscore =&gt; :zScore) # z-score\nend\n\n5000×9 DataFrame4975 rows omitted\n\n\n\nRow\nTest\nSex\nCohort\nSchool\nChild\nage\nscore\na1\nzScore\n\n\n\nString\nString\nString\nString\nString\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\nS20_r\nBoys\n2013\nS102635\nC087137\n8.82683\n3.63636\n0.326831\n-2.14665\n\n\n2\nS20_r\nBoys\n2018\nS105636\nC101782\n8.93908\n4.25532\n0.439083\n-0.619102\n\n\n3\nS20_r\nBoys\n2017\nS100560\nC110754\n9.02396\n4.87805\n0.523956\n0.917761\n\n\n4\nS20_r\nBoys\n2014\nS102416\nC073691\n8.70363\n4.44444\n0.203628\n-0.152351\n\n\n5\nS20_r\nBoys\n2016\nS111508\nC094432\n8.87885\n4.87805\n0.37885\n0.917761\n\n\n6\nS20_r\nBoys\n2016\nS104814\nC095946\n8.88433\n4.44444\n0.384326\n-0.152351\n\n\n7\nS20_r\nBoys\n2016\nS104917\nC061975\n8.60233\n4.44444\n0.102327\n-0.152351\n\n\n8\nS20_r\nBoys\n2015\nS111314\nC030041\n8.31759\n4.54545\n-0.182409\n0.0969362\n\n\n9\nS20_r\nBoys\n2019\nS104723\nC057313\n8.55578\n5.26316\n0.0557837\n1.86819\n\n\n10\nS20_r\nBoys\n2017\nS103329\nC069149\n8.66256\n3.63636\n0.16256\n-2.14665\n\n\n11\nS20_r\nBoys\n2013\nS103251\nC030686\n8.33128\n4.08163\n-0.16872\n-1.04775\n\n\n12\nS20_r\nBoys\n2018\nS101679\nC062325\n8.6078\n4.7619\n0.107803\n0.631124\n\n\n13\nS20_r\nBoys\n2012\nS102775\nC031649\n8.33402\n4.08163\n-0.165982\n-1.04775\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n4989\nRun\nGirls\n2012\nS104887\nC041152\n8.41615\n999.0\n-0.0838467\n-0.021097\n\n\n4990\nRun\nGirls\n2015\nS102052\nC058624\n8.56947\n891.0\n0.069473\n-0.766184\n\n\n4991\nRun\nGirls\n2015\nS102003\nC029349\n8.30664\n891.0\n-0.193361\n-0.766184\n\n\n4992\nRun\nGirls\n2018\nS100183\nC052461\n8.52567\n1240.0\n0.0256674\n1.64155\n\n\n4993\nRun\nGirls\n2014\nS101291\nC009332\n8.1232\n1004.0\n-0.376797\n0.0133978\n\n\n4994\nRun\nGirls\n2011\nS103287\nC041870\n8.41889\n828.0\n-0.0811088\n-1.20082\n\n\n4995\nRun\nGirls\n2017\nS106409\nC035125\n8.36687\n1134.0\n-0.133128\n0.910261\n\n\n4996\nRun\nGirls\n2012\nS100158\nC050156\n8.50103\n792.0\n0.00102669\n-1.44918\n\n\n4997\nRun\nGirls\n2015\nS100626\nC009072\n8.11499\n1142.0\n-0.38501\n0.965453\n\n\n4998\nRun\nGirls\n2018\nS101758\nC043116\n8.44079\n810.0\n-0.059206\n-1.325\n\n\n4999\nRun\nGirls\n2011\nS104206\nC088798\n8.83231\n981.0\n0.332307\n-0.145278\n\n\n5000\nRun\nGirls\n2012\nS100596\nC098677\n8.91718\n783.0\n0.41718\n-1.51127\n\n\n\n\n\n\n\nbegin\n  dat2 = combine(\n    groupby(dat, [:Test, :Sex]),\n    :score =&gt; mean,\n    :score =&gt; std,\n    :zScore =&gt; mean,\n    :zScore =&gt; std,\n  )\nend\n\n10×6 DataFrame\n\n\n\nRow\nTest\nSex\nscore_mean\nscore_std\nzScore_mean\nzScore_std\n\n\n\nString\nString\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\nS20_r\nBoys\n4.57565\n0.39524\n0.171447\n0.975432\n\n\n2\nBPT\nBoys\n3.9958\n0.734303\n0.31598\n1.01012\n\n\n3\nSLJ\nBoys\n129.026\n19.3646\n0.162945\n0.999799\n\n\n4\nStar_r\nBoys\n2.08942\n0.31292\n0.10335\n1.03547\n\n\n5\nRun\nBoys\n1038.18\n145.355\n0.249204\n1.0028\n\n\n6\nS20_r\nGirls\n4.43671\n0.403496\n-0.171447\n0.995806\n\n\n7\nBPT\nGirls\n3.5364\n0.642667\n-0.31598\n0.884066\n\n\n8\nSLJ\nGirls\n122.714\n18.8701\n-0.162945\n0.974268\n\n\n9\nStar_r\nGirls\n2.02695\n0.28803\n-0.10335\n0.953104\n\n\n10\nRun\nGirls\n965.936\n135.352\n-0.249204\n0.933784\n\n\n\n\n\n\n\n\n1.2.3 Figure of age x Sex x Test interactions\nThe main results of relevance here are shown in Figure 2 of Scientific Reports 11:17566."
  },
  {
    "objectID": "contrasts_fggk21.html#contrast-coding",
    "href": "contrasts_fggk21.html#contrast-coding",
    "title": "Mixed Models Tutorial: Contrast Coding",
    "section": "2. Contrast coding",
    "text": "2. Contrast coding\nContrast coding is part of StatsModels.jl. Here is the primary author’s (i.e., Dave Kleinschmidt’s documentation of Modeling Categorical Data.\nThe random factors Child, School, and Cohort are assigned a Grouping contrast. This contrast is needed when the number of groups (i.e., units, levels) is very large. This is the case for Child (i.e., the 108,925 children in the full and probably also the 11,566 children in the reduced data set). The assignment is not necessary for the typical sample size of experiments. However, we use this coding of random factors irrespective of the number of units associated with them to be transparent about the distinction between random and fixed factors.\nA couple of general remarks about the following examples. First, all contrasts defined in this tutorial return an estimate of the Grand Mean (GM) in the intercept, that is they are so-called sum-to-zero contrasts. In both Julia and R the default contrast is Dummy coding which is not a sum-to-zero contrast, but returns the mean of the reference (control) group - unfortunately for (quasi-)experimentally minded scientists.\nSecond, The factor Sex has only two levels. We use EffectCoding (also known as Sum coding in R) to estimate the difference of the levels from the Grand Mean. Unlike in R, the default sign of the effect is for the second level (base is the first, not the last level), but this can be changed with the base kwarg in the command. Effect coding is a sum-to-zero contrast, but when applied to factors with more than two levels does not yield orthogonal contrasts.\nFinally, contrasts for the five levels of the fixed factor Test represent the hypotheses about differences between them. In this tutorial, we use this factor to illustrate various options.\nWe (initially) include only Test as fixed factor and Child as random factor. More complex LMMs can be specified by simply adding other fixed or random factors to the formula.\n\n2.1 SeqDiffCoding: contr1\nSeqDiffCoding was used in the publication. This specification tests pairwise differences between the five neighboring levels of Test, that is:\n\nSDC1: 2-1\nSDC2: 3-2\nSDC3: 4-3\nSDC4: 5-4\n\nThe levels were sorted such that these contrasts map onto four a priori hypotheses; in other words, they are theoretically motivated pairwise comparisons. The motivation also encompasses theoretically motivated interactions with Sex. The order of levels can also be explicitly specified during contrast construction. This is very useful if levels are in a different order in the dataframe. We recommend the explicit specification to increase transparency of the code.\nThe statistical disadvantage of SeqDiffCoding is that the contrasts are not orthogonal, that is the contrasts are correlated. This is obvious from the fact that levels 2, 3, and 4 are all used in two contrasts. One consequence of this is that correlation parameters estimated between neighboring contrasts (e.g., 2-1 and 3-2) are difficult to interpret. Usually, they will be negative because assuming some practical limitation on the overall range (e.g., between levels 1 and 3), a small “2-1” effect “correlates” negatively with a larger “3-2” effect for mathematical reasons.\nObviously, the tradeoff between theoretical motivation and statistical purity is something that must be considered carefully when planning the analysis.\n\ncontr1 = merge(\n  Dict(nm =&gt; Grouping() for nm in (:School, :Child, :Cohort)),\n  Dict(\n    :Sex =&gt; EffectsCoding(; levels=[\"Girls\", \"Boys\"]),\n    :Test =&gt; SeqDiffCoding(;\n      levels=[\"Run\", \"Star_r\", \"S20_r\", \"SLJ\", \"BPT\"]\n    ),\n  ),\n)\n\nDict{Symbol, StatsModels.AbstractContrasts} with 5 entries:\n  :Child  =&gt; Grouping()\n  :School =&gt; Grouping()\n  :Test   =&gt; SeqDiffCoding([\"Run\", \"Star_r\", \"S20_r\", \"SLJ\", \"BPT\"])\n  :Cohort =&gt; Grouping()\n  :Sex    =&gt; EffectsCoding(nothing, [\"Girls\", \"Boys\"])\n\n\n\nf_ovi_1 = @formula zScore ~ 1 + Test + (1 | Child);\n\n\nm_ovi_SeqDiff_1 = fit(MixedModel, f_ovi_1, dat; contrasts=contr1)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n0.0007\n0.0143\n0.05\n0.9592\n0.7344\n\n\nTest: Star_r\n0.0010\n0.0442\n0.02\n0.9828\n\n\n\nTest: S20_r\n-0.0034\n0.0441\n-0.08\n0.9389\n\n\n\nTest: SLJ\n-0.0024\n0.0442\n-0.06\n0.9560\n\n\n\nTest: BPT\n0.0009\n0.0442\n0.02\n0.9834\n\n\n\nResidual\n0.6772\n\n\n\n\n\n\n\n\n\nIn this case, any differences between tests identified by the contrasts would be spurious because each test was standardized (i.e., M=0, \\(SD\\)=1). The differences could also be due to an imbalance in the number of boys and girls or in the number of missing observations for each test.\nThe primary interest in this study related to interactions of the test contrasts with and age and Sex. We start with age (linear) and its interaction with the four test contrasts.\n\nm_ovi_SeqDiff_2 = let\n  form = @formula zScore ~ 1 + Test * a1 + (1 | Child)\n  fit(MixedModel, form, dat; contrasts=contr1)\nend\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0138\n0.0144\n-0.95\n0.3396\n0.7351\n\n\nTest: Star_r\n-0.0084\n0.0450\n-0.19\n0.8525\n\n\n\nTest: S20_r\n0.0006\n0.0446\n0.01\n0.9895\n\n\n\nTest: SLJ\n-0.0037\n0.0449\n-0.08\n0.9337\n\n\n\nTest: BPT\n-0.0231\n0.0447\n-0.52\n0.6050\n\n\n\na1\n0.2903\n0.0496\n5.86\n&lt;1e-08\n\n\n\nTest: Star_r & a1\n0.2075\n0.1542\n1.35\n0.1785\n\n\n\nTest: S20_r & a1\n-0.0999\n0.1559\n-0.64\n0.5214\n\n\n\nTest: SLJ & a1\n0.0082\n0.1537\n0.05\n0.9577\n\n\n\nTest: BPT & a1\n0.6349\n0.1519\n4.18\n&lt;1e-04\n\n\n\nResidual\n0.6674\n\n\n\n\n\n\n\n\n\nThe difference between older and younger childrend is larger for Star_r than for Run (0.2473). S20_r did not differ significantly from Star_r (-0.0377) and SLJ (-0.0113) The largest difference in developmental gain was between BPT and SLJ (0.3355).\nPlease note that standard errors of this LMM are anti-conservative because the LMM is missing a lot of information in the RES (e..g., contrast-related VCs snd CPs for Child, School, and Cohort.\nNext we add the main effect of Sex and its interaction with the four test contrasts.\n\nm_ovi_SeqDiff_3 = let\n  form = @formula zScore ~ 1 + Test * (a1 + Sex) + (1 | Child)\n  fit(MixedModel, form, dat; contrasts=contr1)\nend\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0120\n0.0141\n-0.85\n0.3965\n0.7226\n\n\nTest: Star_r\n-0.0112\n0.0439\n-0.25\n0.7989\n\n\n\nTest: S20_r\n0.0021\n0.0436\n0.05\n0.9611\n\n\n\nTest: SLJ\n-0.0045\n0.0439\n-0.10\n0.9185\n\n\n\nTest: BPT\n-0.0192\n0.0437\n-0.44\n0.6609\n\n\n\na1\n0.2466\n0.0486\n5.08\n&lt;1e-06\n\n\n\nSex: Boys\n0.1987\n0.0139\n14.32\n&lt;1e-45\n\n\n\nTest: Star_r & a1\n0.2481\n0.1509\n1.64\n0.1003\n\n\n\nTest: S20_r & a1\n-0.1243\n0.1525\n-0.82\n0.4149\n\n\n\nTest: SLJ & a1\n0.0216\n0.1504\n0.14\n0.8857\n\n\n\nTest: BPT & a1\n0.5427\n0.1490\n3.64\n0.0003\n\n\n\nTest: Star_r & Sex: Boys\n-0.1480\n0.0430\n-3.44\n0.0006\n\n\n\nTest: S20_r & Sex: Boys\n0.0711\n0.0428\n1.66\n0.0968\n\n\n\nTest: SLJ & Sex: Boys\n-0.0117\n0.0429\n-0.27\n0.7856\n\n\n\nTest: BPT & Sex: Boys\n0.1409\n0.0431\n3.27\n0.0011\n\n\n\nResidual\n0.6482\n\n\n\n\n\n\n\n\n\nThe significant interactions with Sex reflect mostly differences related to muscle power, where the physiological constitution gives boys an advantage. The sex difference is smaller when coordination and cognition play a role – as in the Star_r test. (Caveat: SEs are estimated with an underspecified RES.)\nThe final step in this first series is to add the interactions between the three covariates. A significant interaction between any of the four Test contrasts and age (linear) x Sex was hypothesized to reflect a prepubertal signal (i.e., hormones start to rise in girls’ ninth year of life). However, this hypothesis is linked to a specific shape of the interaction: Girls would need to gain more than boys in tests of muscular power.\n\nf_ovi = @formula zScore ~ 1 + Test * a1 * Sex + (1 | Child)\nm_ovi_SeqDiff = fit(MixedModel, f_ovi, dat; contrasts=contr1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0118\n0.0141\n-0.83\n0.4049\n0.7182\n\n\nTest: Star_r\n-0.0100\n0.0440\n-0.23\n0.8199\n\n\n\nTest: S20_r\n0.0020\n0.0437\n0.05\n0.9635\n\n\n\nTest: SLJ\n-0.0049\n0.0439\n-0.11\n0.9115\n\n\n\nTest: BPT\n-0.0216\n0.0439\n-0.49\n0.6226\n\n\n\na1\n0.2487\n0.0485\n5.12\n&lt;1e-06\n\n\n\nSex: Boys\n0.2017\n0.0141\n14.26\n&lt;1e-45\n\n\n\nTest: Star_r & a1\n0.2545\n0.1510\n1.69\n0.0919\n\n\n\nTest: S20_r & a1\n-0.1289\n0.1526\n-0.84\n0.3981\n\n\n\nTest: SLJ & a1\n0.0196\n0.1505\n0.13\n0.8963\n\n\n\nTest: BPT & a1\n0.5422\n0.1490\n3.64\n0.0003\n\n\n\nTest: Star_r & Sex: Boys\n-0.1392\n0.0440\n-3.16\n0.0016\n\n\n\nTest: S20_r & Sex: Boys\n0.0668\n0.0437\n1.53\n0.1258\n\n\n\nTest: SLJ & Sex: Boys\n-0.0118\n0.0439\n-0.27\n0.7885\n\n\n\nTest: BPT & Sex: Boys\n0.1344\n0.0439\n3.06\n0.0022\n\n\n\na1 & Sex: Boys\n-0.0525\n0.0485\n-1.08\n0.2795\n\n\n\nTest: Star_r & a1 & Sex: Boys\n-0.1629\n0.1510\n-1.08\n0.2806\n\n\n\nTest: S20_r & a1 & Sex: Boys\n0.0847\n0.1526\n0.55\n0.5789\n\n\n\nTest: SLJ & a1 & Sex: Boys\n0.0142\n0.1505\n0.09\n0.9248\n\n\n\nTest: BPT & a1 & Sex: Boys\n0.1183\n0.1490\n0.79\n0.4274\n\n\n\nResidual\n0.6524\n\n\n\n\n\n\n\n\n\nThe results are very clear: Despite an abundance of statistical power there is no evidence for the differences between boys and girls in how much they gain in the ninth year of life in these five tests. The authors argue that, in this case, absence of evidence looks very much like evidence of absence of a hypothesized interaction.\nIn the next two sections we use different contrasts. Does this have a bearing on this result? We still ignore for now that we are looking at anti-conservative test statistics.\n\n\n2.2 HelmertCoding: contr2\nThe second set of contrasts uses HelmertCoding. Helmert coding codes each level as the difference from the average of the lower levels. With the default order of Test levels we get the following test statistics which we describe in reverse order of appearance in model output\n\nHeC4: 5 - mean(1,2,3,4)\nHeC3: 4 - mean(1,2,3)\nHeC2: 3 - mean(1,2)\nHeC1: 2 - 1\n\nIn the model output, HeC1 will be reported first and HeC4 last.\nThere is some justification for the HeC4 specification in a post-hoc manner because the fifth test (BPT) turned out to be different from the other four tests in that high performance is most likely not only related to physical fitness, but also to overweight/obesity, that is for a subset of children high scores on this test might be indicative of physical unfitness. A priori the SDC4 contrast 5-4 between BPT (5) and SLJ (4) was motivated because conceptually both are tests of the physical fitness component Muscular Power, BPT for upper limbs and SLJ for lower limbs, respectively.\nOne could argue that there is justification for HeC3 because Run (1), Star_r (2), and S20 (3) involve running but SLJ (4) does not. Sports scientists, however, recoil. For them it does not make much sense to average the different running tests, because they draw on completely different physiological resources; it is a variant of the old apples-and-oranges problem.\nThe justification for HeC3 is thatRun (1) and Star_r (2) draw more strongly on cardiosrespiratory Endurance than S20 (3) due to the longer duration of the runs compared to sprinting for 20 m which is a pure measure of the physical-fitness component Speed. Again, sports scientists are not very happy with this proposal.\nFinally, HeC1 contrasts the fitness components Endurance, indicated best by Run (1), and Coordination, indicated by Star_r (2). Endurance (i.e., running for 6 minutes) is considered to be the best indicator of health-related status among the five tests because it is a rather pure measure of cardiorespiratory fitness. The Star_r test requires execution of a pre-instructed sequence of forward, sideways, and backward runs. This coordination of body movements implies a demand on working memory (i.e., remembering the order of these subruns) and executive control processes, but performats also depends on endurance. HeC1 yields a measure of Coordination “corrected” for the contribution of Endurance.\nThe statistical advantage of HelmertCoding is that the resulting contrasts are orthogonal (uncorrelated). This allows for optimal partitioning of variance and statistical power. It is also more efficient to estimate “orthogonal” than “non-orthogonal” random-effect structures.\n\ncontr2 = Dict(\n  :School =&gt; Grouping(),\n  :Child =&gt; Grouping(),\n  :Cohort =&gt; Grouping(),\n  :Sex =&gt; EffectsCoding(; levels=[\"Girls\", \"Boys\"]),\n  :Test =&gt; HelmertCoding(;\n    levels=[\"Run\", \"Star_r\", \"S20_r\", \"SLJ\", \"BPT\"],\n  ),\n);\n\n\nm_ovi_Helmert = fit(MixedModel, f_ovi, dat; contrasts=contr2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0118\n0.0141\n-0.83\n0.4049\n0.7182\n\n\nTest: Star_r\n-0.0050\n0.0220\n-0.23\n0.8199\n\n\n\nTest: S20_r\n-0.0010\n0.0126\n-0.08\n0.9366\n\n\n\nTest: SLJ\n-0.0017\n0.0090\n-0.19\n0.8481\n\n\n\nTest: BPT\n-0.0054\n0.0069\n-0.77\n0.4392\n\n\n\na1\n0.2487\n0.0485\n5.12\n&lt;1e-06\n\n\n\nSex: Boys\n0.2017\n0.0141\n14.26\n&lt;1e-45\n\n\n\nTest: Star_r & a1\n0.1273\n0.0755\n1.69\n0.0919\n\n\n\nTest: S20_r & a1\n-0.0006\n0.0439\n-0.01\n0.9900\n\n\n\nTest: SLJ & a1\n0.0046\n0.0304\n0.15\n0.8789\n\n\n\nTest: BPT & a1\n0.1112\n0.0238\n4.66\n&lt;1e-05\n\n\n\nTest: Star_r & Sex: Boys\n-0.0696\n0.0220\n-3.16\n0.0016\n\n\n\nTest: S20_r & Sex: Boys\n-0.0009\n0.0126\n-0.07\n0.9420\n\n\n\nTest: SLJ & Sex: Boys\n-0.0034\n0.0090\n-0.38\n0.7049\n\n\n\nTest: BPT & Sex: Boys\n0.0248\n0.0069\n3.59\n0.0003\n\n\n\na1 & Sex: Boys\n-0.0525\n0.0485\n-1.08\n0.2795\n\n\n\nTest: Star_r & a1 & Sex: Boys\n-0.0815\n0.0755\n-1.08\n0.2806\n\n\n\nTest: S20_r & a1 & Sex: Boys\n0.0011\n0.0439\n0.02\n0.9806\n\n\n\nTest: SLJ & a1 & Sex: Boys\n0.0041\n0.0304\n0.13\n0.8931\n\n\n\nTest: BPT & a1 & Sex: Boys\n0.0261\n0.0238\n1.09\n0.2738\n\n\n\nResidual\n0.6524\n\n\n\n\n\n\n\n\n\nWe forego a detailed discussion of the effects, but note that again none of the interactions between age x Sex with the four test contrasts was significant.\nThe default labeling of Helmert contrasts may lead to confusions with other contrasts. Therefore, we could provide our own labels:\nlabels=[\"c2.1\", \"c3.12\", \"c4.123\", \"c5.1234\"]\nOnce the order of levels is memorized the proposed labelling is very transparent.\n\n\n2.3 HypothesisCoding: contr3\nThe third set of contrasts uses HypothesisCoding. Hypothesis coding allows the user to specify their own a priori contrast matrix, subject to the mathematical constraint that the matrix has full rank. For example, sport scientists agree that the first four tests can be contrasted with BPT, because the difference is akin to a correction of overall physical fitness. However, they want to keep the pairwise comparisons for the first four tests.\n\nHyC1: BPT - mean(1,2,3,4)\nHyC2: Star_r - Run_r\nHyC3: Run_r - S20_r\nHyC4: S20_r - SLJ\n\n\ncontr3 = Dict(\n  :School =&gt; Grouping(),\n  :Child =&gt; Grouping(),\n  :Cohort =&gt; Grouping(),\n  :Sex =&gt; EffectsCoding(; levels=[\"Girls\", \"Boys\"]),\n  :Test =&gt; HypothesisCoding(\n    [\n      -1 -1 -1 -1 +4\n      -1 +1 0 0 0\n       0 -1 +1 0 0\n       0 0 -1 +1 0\n    ];\n    levels=[\"Run\", \"Star_r\", \"S20_r\", \"SLJ\", \"BPT\"],\n    labels=[\"BPT-other\", \"Star-End\", \"S20-Star\", \"SLJ-S20\"],\n  ),\n);\n\n\nm_ovi_Hypo = fit(MixedModel, f_ovi, dat; contrasts=contr3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0118\n0.0141\n-0.83\n0.4049\n0.7182\n\n\nTest: BPT-other\n-0.1070\n0.1384\n-0.77\n0.4392\n\n\n\nTest: Star-End\n-0.0100\n0.0440\n-0.23\n0.8199\n\n\n\nTest: S20-Star\n0.0020\n0.0437\n0.05\n0.9635\n\n\n\nTest: SLJ-S20\n-0.0049\n0.0439\n-0.11\n0.9115\n\n\n\na1\n0.2487\n0.0485\n5.12\n&lt;1e-06\n\n\n\nSex: Boys\n0.2017\n0.0141\n14.26\n&lt;1e-45\n\n\n\nTest: BPT-other & a1\n2.2242\n0.4770\n4.66\n&lt;1e-05\n\n\n\nTest: Star-End & a1\n0.2545\n0.1510\n1.69\n0.0919\n\n\n\nTest: S20-Star & a1\n-0.1289\n0.1526\n-0.84\n0.3981\n\n\n\nTest: SLJ-S20 & a1\n0.0196\n0.1505\n0.13\n0.8963\n\n\n\nTest: BPT-other & Sex: Boys\n0.4967\n0.1384\n3.59\n0.0003\n\n\n\nTest: Star-End & Sex: Boys\n-0.1392\n0.0440\n-3.16\n0.0016\n\n\n\nTest: S20-Star & Sex: Boys\n0.0668\n0.0437\n1.53\n0.1258\n\n\n\nTest: SLJ-S20 & Sex: Boys\n-0.0118\n0.0439\n-0.27\n0.7885\n\n\n\na1 & Sex: Boys\n-0.0525\n0.0485\n-1.08\n0.2795\n\n\n\nTest: BPT-other & a1 & Sex: Boys\n0.5220\n0.4770\n1.09\n0.2738\n\n\n\nTest: Star-End & a1 & Sex: Boys\n-0.1629\n0.1510\n-1.08\n0.2806\n\n\n\nTest: S20-Star & a1 & Sex: Boys\n0.0847\n0.1526\n0.55\n0.5789\n\n\n\nTest: SLJ-S20 & a1 & Sex: Boys\n0.0142\n0.1505\n0.09\n0.9248\n\n\n\nResidual\n0.6524\n\n\n\n\n\n\n\n\n\nWith HypothesisCoding we must generate our own labels for the contrasts. The default labeling of contrasts is usually not interpretable. Therefore, we provide our own.\nAnyway, none of the interactions between age x Sex with the four Test contrasts was significant for these contrasts.\n\ncontr1b = Dict(\n  :School =&gt; Grouping(),\n  :Child =&gt; Grouping(),\n  :Cohort =&gt; Grouping(),\n  :Sex =&gt; EffectsCoding(; levels=[\"Girls\", \"Boys\"]),\n  :Test =&gt; HypothesisCoding(\n    [\n      -1 +1 0 0 0\n      0 -1 +1 0 0\n      0 0 -1 +1 0\n      0 0 0 -1 +1\n    ];\n    levels=[\"Run\", \"Star_r\", \"S20_r\", \"SLJ\", \"BPT\"],\n    labels=[\"Star-Run\", \"S20-Star\", \"SLJ-S20\", \"BPT-SLJ\"],\n  ),\n);\n\n\nm_ovi_SeqDiff_v2 = fit(MixedModel, f_ovi, dat; contrasts=contr1b)\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0118\n0.0141\n-0.83\n0.4049\n0.7182\n\n\nTest: Star-Run\n-0.0100\n0.0440\n-0.23\n0.8199\n\n\n\nTest: S20-Star\n0.0020\n0.0437\n0.05\n0.9635\n\n\n\nTest: SLJ-S20\n-0.0049\n0.0439\n-0.11\n0.9115\n\n\n\nTest: BPT-SLJ\n-0.0216\n0.0439\n-0.49\n0.6226\n\n\n\na1\n0.2487\n0.0485\n5.12\n&lt;1e-06\n\n\n\nSex: Boys\n0.2017\n0.0141\n14.26\n&lt;1e-45\n\n\n\nTest: Star-Run & a1\n0.2545\n0.1510\n1.69\n0.0919\n\n\n\nTest: S20-Star & a1\n-0.1289\n0.1526\n-0.84\n0.3981\n\n\n\nTest: SLJ-S20 & a1\n0.0196\n0.1505\n0.13\n0.8963\n\n\n\nTest: BPT-SLJ & a1\n0.5422\n0.1490\n3.64\n0.0003\n\n\n\nTest: Star-Run & Sex: Boys\n-0.1392\n0.0440\n-3.16\n0.0016\n\n\n\nTest: S20-Star & Sex: Boys\n0.0668\n0.0437\n1.53\n0.1258\n\n\n\nTest: SLJ-S20 & Sex: Boys\n-0.0118\n0.0439\n-0.27\n0.7885\n\n\n\nTest: BPT-SLJ & Sex: Boys\n0.1344\n0.0439\n3.06\n0.0022\n\n\n\na1 & Sex: Boys\n-0.0525\n0.0485\n-1.08\n0.2795\n\n\n\nTest: Star-Run & a1 & Sex: Boys\n-0.1629\n0.1510\n-1.08\n0.2806\n\n\n\nTest: S20-Star & a1 & Sex: Boys\n0.0847\n0.1526\n0.55\n0.5789\n\n\n\nTest: SLJ-S20 & a1 & Sex: Boys\n0.0142\n0.1505\n0.09\n0.9248\n\n\n\nTest: BPT-SLJ & a1 & Sex: Boys\n0.1183\n0.1490\n0.79\n0.4274\n\n\n\nResidual\n0.6524\n\n\n\n\n\n\n\n\n\n\nm_zcp_SeqD = let\n  form = @formula(\n    zScore ~ 1 + Test * a1 * Sex + zerocorr(1 + Test | Child)\n  )\n  fit(MixedModel, form, dat; contrasts=contr1b)\nend\n\nMinimizing 90    Time: 0:00:00 ( 4.66 ms/it)\n  objective:  13840.506143081951\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0118\n0.0141\n-0.83\n0.4047\n0.7222\n\n\nTest: Star-Run\n-0.0095\n0.0444\n-0.21\n0.8299\n0.0000\n\n\nTest: S20-Star\n0.0023\n0.0436\n0.05\n0.9584\n0.4536\n\n\nTest: SLJ-S20\n-0.0056\n0.0436\n-0.13\n0.8978\n0.2859\n\n\nTest: BPT-SLJ\n-0.0189\n0.0436\n-0.43\n0.6644\n0.0000\n\n\na1\n0.2490\n0.0485\n5.13\n&lt;1e-06\n\n\n\nSex: Boys\n0.2017\n0.0141\n14.26\n&lt;1e-45\n\n\n\nTest: Star-Run & a1\n0.2460\n0.1525\n1.61\n0.1066\n\n\n\nTest: S20-Star & a1\n-0.1290\n0.1525\n-0.85\n0.3977\n\n\n\nTest: SLJ-S20 & a1\n0.0175\n0.1492\n0.12\n0.9067\n\n\n\nTest: BPT-SLJ & a1\n0.5480\n0.1481\n3.70\n0.0002\n\n\n\nTest: Star-Run & Sex: Boys\n-0.1403\n0.0444\n-3.16\n0.0016\n\n\n\nTest: S20-Star & Sex: Boys\n0.0671\n0.0436\n1.54\n0.1239\n\n\n\nTest: SLJ-S20 & Sex: Boys\n-0.0127\n0.0436\n-0.29\n0.7703\n\n\n\nTest: BPT-SLJ & Sex: Boys\n0.1367\n0.0436\n3.13\n0.0017\n\n\n\na1 & Sex: Boys\n-0.0523\n0.0485\n-1.08\n0.2810\n\n\n\nTest: Star-Run & a1 & Sex: Boys\n-0.1623\n0.1525\n-1.06\n0.2871\n\n\n\nTest: S20-Star & a1 & Sex: Boys\n0.0876\n0.1525\n0.57\n0.5658\n\n\n\nTest: SLJ-S20 & a1 & Sex: Boys\n0.0212\n0.1492\n0.14\n0.8869\n\n\n\nTest: BPT-SLJ & a1 & Sex: Boys\n0.1105\n0.1481\n0.75\n0.4558\n\n\n\nResidual\n0.5925\n\n\n\n\n\n\n\n\n\n\nm_zcp_SeqD_2 = let\n  form = @formula(\n    zScore ~ 1 + Test * a1 * Sex + (0 + Test | Child)\n  )\n  fit(MixedModel, form, dat; contrasts=contr1b)\nend\n\nMinimizing 2763      Time: 0:00:11 ( 4.06 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0119\n0.0141\n-0.84\n0.3981\n\n\n\nTest: Star-Run\n-0.0106\n0.0441\n-0.24\n0.8095\n\n\n\nTest: S20-Star\n0.0066\n0.0443\n0.15\n0.8818\n\n\n\nTest: SLJ-S20\n-0.0087\n0.0447\n-0.19\n0.8458\n\n\n\nTest: BPT-SLJ\n-0.0226\n0.0437\n-0.52\n0.6044\n\n\n\na1\n0.2504\n0.0483\n5.18\n&lt;1e-06\n\n\n\nSex: Boys\n0.2017\n0.0141\n14.33\n&lt;1e-45\n\n\n\nTest: Star-Run & a1\n0.2268\n0.1516\n1.50\n0.1346\n\n\n\nTest: S20-Star & a1\n-0.1246\n0.1548\n-0.80\n0.4208\n\n\n\nTest: SLJ-S20 & a1\n0.0246\n0.1533\n0.16\n0.8725\n\n\n\nTest: BPT-SLJ & a1\n0.5302\n0.1485\n3.57\n0.0004\n\n\n\nTest: Star-Run & Sex: Boys\n-0.1375\n0.0441\n-3.12\n0.0018\n\n\n\nTest: S20-Star & Sex: Boys\n0.0648\n0.0443\n1.46\n0.1431\n\n\n\nTest: SLJ-S20 & Sex: Boys\n-0.0055\n0.0447\n-0.12\n0.9021\n\n\n\nTest: BPT-SLJ & Sex: Boys\n0.1260\n0.0437\n2.89\n0.0039\n\n\n\na1 & Sex: Boys\n-0.0472\n0.0483\n-0.98\n0.3288\n\n\n\nTest: Star-Run & a1 & Sex: Boys\n-0.1572\n0.1516\n-1.04\n0.2996\n\n\n\nTest: S20-Star & a1 & Sex: Boys\n0.0993\n0.1548\n0.64\n0.5212\n\n\n\nTest: SLJ-S20 & a1 & Sex: Boys\n-0.0095\n0.1533\n-0.06\n0.9505\n\n\n\nTest: BPT-SLJ & a1 & Sex: Boys\n0.1571\n0.1485\n1.06\n0.2900\n\n\n\nTest: BPT\n\n\n\n\n0.9266\n\n\nTest: SLJ\n\n\n\n\n0.9850\n\n\nTest: Star_r\n\n\n\n\n0.9873\n\n\nTest: Run\n\n\n\n\n0.9585\n\n\nTest: S20_r\n\n\n\n\n0.9816\n\n\nResidual\n0.0000\n\n\n\n\n\n\n\n\n\n\nm_cpx_0_SeqDiff = let\n  f_cpx_0 = @formula(\n    zScore ~ 1 + Test * a1 * Sex + (0 + Test | Child)\n  )\n  fit(MixedModel, f_cpx_0, dat; contrasts=contr1b)\nend\n\nMinimizing 2763      Time: 0:00:10 ( 3.97 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0119\n0.0141\n-0.84\n0.3981\n\n\n\nTest: Star-Run\n-0.0106\n0.0441\n-0.24\n0.8095\n\n\n\nTest: S20-Star\n0.0066\n0.0443\n0.15\n0.8818\n\n\n\nTest: SLJ-S20\n-0.0087\n0.0447\n-0.19\n0.8458\n\n\n\nTest: BPT-SLJ\n-0.0226\n0.0437\n-0.52\n0.6044\n\n\n\na1\n0.2504\n0.0483\n5.18\n&lt;1e-06\n\n\n\nSex: Boys\n0.2017\n0.0141\n14.33\n&lt;1e-45\n\n\n\nTest: Star-Run & a1\n0.2268\n0.1516\n1.50\n0.1346\n\n\n\nTest: S20-Star & a1\n-0.1246\n0.1548\n-0.80\n0.4208\n\n\n\nTest: SLJ-S20 & a1\n0.0246\n0.1533\n0.16\n0.8725\n\n\n\nTest: BPT-SLJ & a1\n0.5302\n0.1485\n3.57\n0.0004\n\n\n\nTest: Star-Run & Sex: Boys\n-0.1375\n0.0441\n-3.12\n0.0018\n\n\n\nTest: S20-Star & Sex: Boys\n0.0648\n0.0443\n1.46\n0.1431\n\n\n\nTest: SLJ-S20 & Sex: Boys\n-0.0055\n0.0447\n-0.12\n0.9021\n\n\n\nTest: BPT-SLJ & Sex: Boys\n0.1260\n0.0437\n2.89\n0.0039\n\n\n\na1 & Sex: Boys\n-0.0472\n0.0483\n-0.98\n0.3288\n\n\n\nTest: Star-Run & a1 & Sex: Boys\n-0.1572\n0.1516\n-1.04\n0.2996\n\n\n\nTest: S20-Star & a1 & Sex: Boys\n0.0993\n0.1548\n0.64\n0.5212\n\n\n\nTest: SLJ-S20 & a1 & Sex: Boys\n-0.0095\n0.1533\n-0.06\n0.9505\n\n\n\nTest: BPT-SLJ & a1 & Sex: Boys\n0.1571\n0.1485\n1.06\n0.2900\n\n\n\nTest: BPT\n\n\n\n\n0.9266\n\n\nTest: SLJ\n\n\n\n\n0.9850\n\n\nTest: Star_r\n\n\n\n\n0.9873\n\n\nTest: Run\n\n\n\n\n0.9585\n\n\nTest: S20_r\n\n\n\n\n0.9816\n\n\nResidual\n0.0000\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_cpx_0_SeqDiff)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\nChild\nTest: Run\n0.91865160\n0.95846314\n\n\n\n\n\n\n\nTest: Star_r\n0.97481037\n0.98732485\n+0.67\n\n\n\n\n\n\nTest: S20_r\n0.96346824\n0.98156418\n-0.12\n+0.62\n\n\n\n\n\nTest: SLJ\n0.97029733\n0.98503671\n+0.07\n+0.56\n+0.46\n\n\n\n\nTest: BPT\n0.85855574\n0.92658283\n+0.16\n+0.31\n+0.51\n-0.08\n\n\nResidual\n\n0.00000000\n0.00003387\n\n\n\n\n\n\n\n\n\n\nm_cpx_0_SeqDiff.PCA\n\n(Child = \nPrincipal components based on correlation matrix\n Test: Run      1.0     .      .      .      .\n Test: Star_r   0.67   1.0     .      .      .\n Test: S20_r   -0.12   0.62   1.0     .      .\n Test: SLJ      0.07   0.56   0.46   1.0     .\n Test: BPT      0.16   0.31   0.51  -0.08   1.0\n\nNormalized cumulative variances:\n[0.4782, 0.7238, 0.9438, 0.9988, 1.0]\n\nComponent loadings\n                 PC1    PC2    PC3    PC4    PC5\n Test: Run     -0.31   0.78  -0.16  -0.04  -0.52\n Test: Star_r  -0.61   0.24   0.07   0.33   0.68\n Test: S20_r   -0.5   -0.52  -0.04   0.48  -0.5\n Test: SLJ     -0.41  -0.13   0.66  -0.61  -0.1\n Test: BPT     -0.33  -0.23  -0.73  -0.53   0.12,)\n\n\n\nf_cpx_1 = @formula(\n  zScore ~ 1 + Test * a1 * Sex + (1 + Test | Child)\n)\nm_cpx_1_SeqDiff =\nfit(MixedModel, f_cpx_1, dat; contrasts=contr1b)\n\nMinimizing 2569      Time: 0:00:10 ( 3.98 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0119\n0.0141\n-0.84\n0.3993\n0.7017\n\n\nTest: Star-Run\n-0.0137\n0.0442\n-0.31\n0.7562\n0.8750\n\n\nTest: S20-Star\n0.0112\n0.0438\n0.26\n0.7984\n0.7477\n\n\nTest: SLJ-S20\n-0.0098\n0.0443\n-0.22\n0.8255\n0.6915\n\n\nTest: BPT-SLJ\n-0.0194\n0.0434\n-0.45\n0.6555\n1.0668\n\n\na1\n0.2507\n0.0484\n5.18\n&lt;1e-06\n\n\n\nSex: Boys\n0.2016\n0.0141\n14.29\n&lt;1e-45\n\n\n\nTest: Star-Run & a1\n0.2350\n0.1518\n1.55\n0.1216\n\n\n\nTest: S20-Star & a1\n-0.1233\n0.1529\n-0.81\n0.4201\n\n\n\nTest: SLJ-S20 & a1\n0.0192\n0.1515\n0.13\n0.8990\n\n\n\nTest: BPT-SLJ & a1\n0.5347\n0.1473\n3.63\n0.0003\n\n\n\nTest: Star-Run & Sex: Boys\n-0.1341\n0.0442\n-3.03\n0.0024\n\n\n\nTest: S20-Star & Sex: Boys\n0.0624\n0.0438\n1.43\n0.1537\n\n\n\nTest: SLJ-S20 & Sex: Boys\n-0.0079\n0.0443\n-0.18\n0.8585\n\n\n\nTest: BPT-SLJ & Sex: Boys\n0.1287\n0.0434\n2.97\n0.0030\n\n\n\na1 & Sex: Boys\n-0.0483\n0.0484\n-1.00\n0.3189\n\n\n\nTest: Star-Run & a1 & Sex: Boys\n-0.1666\n0.1518\n-1.10\n0.2725\n\n\n\nTest: S20-Star & a1 & Sex: Boys\n0.0979\n0.1529\n0.64\n0.5222\n\n\n\nTest: SLJ-S20 & a1 & Sex: Boys\n0.0106\n0.1515\n0.07\n0.9443\n\n\n\nTest: BPT-SLJ & a1 & Sex: Boys\n0.1409\n0.1473\n0.96\n0.3390\n\n\n\nResidual\n0.0000\n\n\n\n\n\n\n\n\n\n\nm_cpx_1_SeqDiff.PCA\n\n(Child = \nPrincipal components based on correlation matrix\n (Intercept)      1.0     .      .      .      .\n Test: Star-Run   0.13   1.0     .      .      .\n Test: S20-Star   0.08   0.23   1.0     .      .\n Test: SLJ-S20    0.01  -0.88   0.04   1.0     .\n Test: BPT-SLJ   -0.31  -0.12  -0.04  -0.29   1.0\n\nNormalized cumulative variances:\n[0.3835, 0.6643, 0.8582, 0.9984, 1.0]\n\nComponent loadings\n                   PC1    PC2    PC3    PC4    PC5\n (Intercept)     -0.07   0.62  -0.27  -0.73   0.0\n Test: Star-Run  -0.7    0.15  -0.02   0.21   0.67\n Test: S20-Star  -0.15   0.29   0.93  -0.07  -0.17\n Test: SLJ-S20    0.69   0.19   0.18   0.03   0.67\n Test: BPT-SLJ   -0.09  -0.68   0.2   -0.64   0.27,)\n\n\n\n\n2.4 PCA-based HypothesisCoding: contr4\nThe fourth set of contrasts uses HypothesisCoding to specify the set of contrasts implementing the loadings of the four principle components of the published LMM based on test scores, not test effects (contrasts) - coarse-grained, that is roughly according to their signs. This is actually a very interesting and plausible solution nobody had proposed a priori.\n\nPC1: BPT - Run_r\nPC2: (Star_r + S20_r + SLJ) - (BPT + Run_r)\nPC3: Star_r - (S20_r + SLJ)\nPC4: S20_r - SLJ\n\nPC1 contrasts the worst and the best indicator of physical health; PC2 contrasts these two against the core indicators of physical fitness; PC3 contrasts the cognitive and the physical tests within the narrow set of physical fitness components; and PC4, finally, contrasts two types of lower muscular fitness differing in speed and power.\n\ncontr4 = Dict(\n  :School =&gt; Grouping(),\n  :Child =&gt; Grouping(),\n  :Cohort =&gt; Grouping(),\n  :Sex =&gt; EffectsCoding(; levels=[\"Girls\", \"Boys\"]),\n  :Test =&gt; HypothesisCoding(\n    [\n      -1 0 0 0 +1\n      -3 +2 +2 +2 -3\n      0 +2 -1 -1 0\n      0 0 +1 -1 0\n    ];\n    levels=[\"Run\", \"Star_r\", \"S20_r\", \"SLJ\", \"BPT\"],\n    labels=[\"c5.1\", \"c234.15\", \"c2.34\", \"c3.4\"],\n  ),\n);\n\n\nm_cpx_1_PC = fit(MixedModel, f_cpx_1, dat; contrasts=contr4)\n\nMinimizing 1696      Time: 0:00:06 ( 4.06 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0122\n0.0141\n-0.87\n0.3855\n0.6734\n\n\nTest: c5.1\n-0.0333\n0.0432\n-0.77\n0.4410\n1.4119\n\n\nTest: c234.15\n0.0607\n0.1688\n0.36\n0.7191\n1.0799\n\n\nTest: c2.34\n0.0064\n0.0769\n0.08\n0.9340\n1.2841\n\n\nTest: c3.4\n0.0023\n0.0448\n0.05\n0.9583\n1.4905\n\n\na1\n0.2506\n0.0483\n5.18\n&lt;1e-06\n\n\n\nSex: Boys\n0.2021\n0.0141\n14.35\n&lt;1e-45\n\n\n\nTest: c5.1 & a1\n0.6479\n0.1474\n4.40\n&lt;1e-04\n\n\n\nTest: c234.15 & a1\n-1.0039\n0.5787\n-1.73\n0.0828\n\n\n\nTest: c2.34 & a1\n0.2316\n0.2669\n0.87\n0.3856\n\n\n\nTest: c3.4 & a1\n-0.0161\n0.1536\n-0.10\n0.9167\n\n\n\nTest: c5.1 & Sex: Boys\n0.0499\n0.0432\n1.15\n0.2484\n\n\n\nTest: c234.15 & Sex: Boys\n-0.7252\n0.1688\n-4.30\n&lt;1e-04\n\n\n\nTest: c2.34 & Sex: Boys\n-0.1339\n0.0769\n-1.74\n0.0818\n\n\n\nTest: c3.4 & Sex: Boys\n0.0088\n0.0448\n0.20\n0.8444\n\n\n\na1 & Sex: Boys\n-0.0496\n0.0483\n-1.02\n0.3054\n\n\n\nTest: c5.1 & a1 & Sex: Boys\n0.0721\n0.1474\n0.49\n0.6250\n\n\n\nTest: c234.15 & a1 & Sex: Boys\n-0.7707\n0.5787\n-1.33\n0.1829\n\n\n\nTest: c2.34 & a1 & Sex: Boys\n-0.1682\n0.2669\n-0.63\n0.5285\n\n\n\nTest: c3.4 & a1 & Sex: Boys\n0.0119\n0.1536\n0.08\n0.9381\n\n\n\nResidual\n0.0000\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_cpx_1_PC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\nChild\n(Intercept)\n0.45350800\n0.67343002\n\n\n\n\n\n\n\nTest: c5.1\n1.99346620\n1.41190163\n-0.20\n\n\n\n\n\n\nTest: c234.15\n1.16611374\n1.07986747\n+0.48\n-0.88\n\n\n\n\n\nTest: c2.34\n1.64888504\n1.28408919\n+0.54\n+0.33\n-0.35\n\n\n\n\nTest: c3.4\n2.22155769\n1.49048908\n-0.03\n+0.02\n+0.02\n-0.11\n\n\nResidual\n\n0.00000000\n0.00001425\n\n\n\n\n\n\n\n\n\n\nm_cpx_1_PC.PCA\n\n(Child = \nPrincipal components based on correlation matrix\n (Intercept)     1.0     .      .      .      .\n Test: c5.1     -0.2    1.0     .      .      .\n Test: c234.15   0.48  -0.88   1.0     .      .\n Test: c2.34     0.54   0.33  -0.35   1.0     .\n Test: c3.4     -0.03   0.02   0.02  -0.11   1.0\n\nNormalized cumulative variances:\n[0.4307, 0.744, 0.9422, 1.0, 1.0]\n\nComponent loadings\n                  PC1    PC2    PC3    PC4    PC5\n (Intercept)    -0.26  -0.7   -0.15   0.47   0.45\n Test: c5.1      0.63  -0.06  -0.08   0.64  -0.42\n Test: c234.15  -0.68  -0.06  -0.02   0.2   -0.71\n Test: c2.34     0.27  -0.69  -0.06  -0.57  -0.35\n Test: c3.4     -0.02   0.16  -0.98  -0.09  -0.0,)\n\n\nThere is a numerical interaction with a z-value &gt; 2.0 for the first PCA (i.e., BPT - Run_r). This interaction would really need to be replicated to be taken seriously. It is probably due to larger “unfitness” gains in boys than girls (i.e., in BPT) relative to the slightly larger health-related “fitness” gains of girls than boys (i.e., in Run_r).\n\ncontr4b = merge(\n  Dict(nm =&gt; Grouping() for nm in (:School, :Child, :Cohort)),\n  Dict(\n    :Sex =&gt; EffectsCoding(; levels=[\"Girls\", \"Boys\"]),\n    :Test =&gt; HypothesisCoding(\n      [\n        0.49 -0.04 0.20 0.03 -0.85\n        0.70 -0.56 -0.21 -0.13 0.37\n        0.31 0.68 -0.56 -0.35 0.00\n        0.04 0.08 0.61 -0.78 0.13\n      ];\n      levels=[\"Run\", \"Star_r\", \"S20_r\", \"SLJ\", \"BPT\"],\n      labels=[\"c5.1\", \"c234.15\", \"c12.34\", \"c3.4\"],\n    ),\n  ),\n);\n\n\nm_cpx_1_PC_2 = fit(MixedModel, f_cpx_1, dat; contrasts=contr4b)\n\nMinimizing 1472      Time: 0:00:05 ( 3.99 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0141\n0.0142\n-0.99\n0.3210\n0.6604\n\n\nTest: c5.1\n0.0302\n0.0305\n0.99\n0.3223\n1.0522\n\n\nTest: c234.15\n-0.0031\n0.0313\n-0.10\n0.9197\n0.9048\n\n\nTest: c12.34\n0.0023\n0.0312\n0.08\n0.9401\n0.6181\n\n\nTest: c3.4\n0.0046\n0.0316\n0.14\n0.8850\n0.6412\n\n\na1\n0.2375\n0.0488\n4.87\n&lt;1e-05\n\n\n\nSex: Boys\n0.1937\n0.0142\n13.62\n&lt;1e-41\n\n\n\nTest: c5.1 & a1\n-0.5156\n0.1046\n-4.93\n&lt;1e-06\n\n\n\nTest: c234.15 & a1\n0.0333\n0.1073\n0.31\n0.7559\n\n\n\nTest: c12.34 & a1\n0.0226\n0.1080\n0.21\n0.8343\n\n\n\nTest: c3.4 & a1\n0.0488\n0.1076\n0.45\n0.6504\n\n\n\nTest: c5.1 & Sex: Boys\n-0.0565\n0.0305\n-1.85\n0.0636\n\n\n\nTest: c234.15 & Sex: Boys\n0.1246\n0.0313\n3.99\n&lt;1e-04\n\n\n\nTest: c12.34 & Sex: Boys\n-0.0185\n0.0312\n-0.59\n0.5529\n\n\n\nTest: c3.4 & Sex: Boys\n0.0148\n0.0316\n0.47\n0.6394\n\n\n\na1 & Sex: Boys\n-0.0528\n0.0488\n-1.08\n0.2792\n\n\n\nTest: c5.1 & a1 & Sex: Boys\n-0.1026\n0.1046\n-0.98\n0.3267\n\n\n\nTest: c234.15 & a1 & Sex: Boys\n0.1577\n0.1073\n1.47\n0.1415\n\n\n\nTest: c12.34 & a1 & Sex: Boys\n-0.0492\n0.1080\n-0.46\n0.6484\n\n\n\nTest: c3.4 & a1 & Sex: Boys\n0.0192\n0.1076\n0.18\n0.8586\n\n\n\nResidual\n0.0000\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_cpx_1_PC_2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\nChild\n(Intercept)\n0.43607949\n0.66036315\n\n\n\n\n\n\n\nTest: c5.1\n1.10708777\n1.05218238\n+0.58\n\n\n\n\n\n\nTest: c234.15\n0.81874127\n0.90484323\n-0.39\n-0.47\n\n\n\n\n\nTest: c12.34\n0.38204908\n0.61810119\n+0.13\n-0.68\n+0.49\n\n\n\n\nTest: c3.4\n0.41110763\n0.64117675\n+0.03\n-0.28\n+0.48\n+0.43\n\n\nResidual\n\n0.00000000\n0.00002412\n\n\n\n\n\n\n\n\n\n\nm_cpx_1_PC_2.PCA\n\n(Child = \nPrincipal components based on correlation matrix\n (Intercept)     1.0     .      .      .      .\n Test: c5.1      0.58   1.0     .      .      .\n Test: c234.15  -0.39  -0.47   1.0     .      .\n Test: c12.34    0.13  -0.68   0.49   1.0     .\n Test: c3.4      0.03  -0.28   0.48   0.43   1.0\n\nNormalized cumulative variances:\n[0.5104, 0.766, 0.9142, 0.9986, 1.0]\n\nComponent loadings\n                  PC1    PC2    PC3    PC4    PC5\n (Intercept)    -0.28   0.77  -0.18   0.18  -0.51\n Test: c5.1     -0.54   0.24   0.44   0.31   0.6\n Test: c234.15   0.5   -0.03   0.41   0.73  -0.22\n Test: c12.34    0.48   0.4   -0.51   0.14   0.57\n Test: c3.4      0.38   0.43   0.58  -0.57   0.04,)\n\n\n\nf_zcp_1 = @formula(zScore ~ 1 + Test*a1*Sex + zerocorr(1 + Test | Child))\nm_zcp_1_PC_2 = fit(MixedModel, f_zcp_1, dat; contrasts=contr4b)\n\nMinimizing 711   Time: 0:00:02 ( 3.00 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0111\n0.0143\n-0.78\n0.4369\n0.7194\n\n\nTest: c5.1\n0.0264\n0.0304\n0.87\n0.3851\n0.6050\n\n\nTest: c234.15\n-0.0013\n0.0313\n-0.04\n0.9677\n0.7397\n\n\nTest: c12.34\n0.0037\n0.0314\n0.12\n0.9068\n0.7631\n\n\nTest: c3.4\n-0.0001\n0.0317\n-0.00\n0.9975\n0.7772\n\n\na1\n0.2287\n0.0489\n4.67\n&lt;1e-05\n\n\n\nSex: Boys\n0.1953\n0.0143\n13.70\n&lt;1e-41\n\n\n\nTest: c5.1 & a1\n-0.5273\n0.1044\n-5.05\n&lt;1e-06\n\n\n\nTest: c234.15 & a1\n0.0249\n0.1073\n0.23\n0.8163\n\n\n\nTest: c12.34 & a1\n0.0426\n0.1087\n0.39\n0.6955\n\n\n\nTest: c3.4 & a1\n0.0577\n0.1080\n0.53\n0.5934\n\n\n\nTest: c5.1 & Sex: Boys\n-0.0633\n0.0304\n-2.08\n0.0372\n\n\n\nTest: c234.15 & Sex: Boys\n0.1289\n0.0313\n4.12\n&lt;1e-04\n\n\n\nTest: c12.34 & Sex: Boys\n-0.0212\n0.0314\n-0.68\n0.4982\n\n\n\nTest: c3.4 & Sex: Boys\n0.0200\n0.0317\n0.63\n0.5274\n\n\n\na1 & Sex: Boys\n-0.0578\n0.0489\n-1.18\n0.2373\n\n\n\nTest: c5.1 & a1 & Sex: Boys\n-0.0692\n0.1044\n-0.66\n0.5070\n\n\n\nTest: c234.15 & a1 & Sex: Boys\n0.1539\n0.1073\n1.43\n0.1515\n\n\n\nTest: c12.34 & a1 & Sex: Boys\n-0.0493\n0.1087\n-0.45\n0.6502\n\n\n\nTest: c3.4 & a1 & Sex: Boys\n0.0065\n0.1080\n0.06\n0.9521\n\n\n\nResidual\n0.0000\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_zcp_1_PC_2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\nChild\n(Intercept)\n0.51748131\n0.71936174\n\n\n\n\n\n\n\nTest: c5.1\n0.36597682\n0.60496018\n.\n\n\n\n\n\n\nTest: c234.15\n0.54709482\n0.73965858\n.\n.\n\n\n\n\n\nTest: c12.34\n0.58232860\n0.76310458\n.\n.\n.\n\n\n\n\nTest: c3.4\n0.60399634\n0.77717202\n.\n.\n.\n.\n\n\nResidual\n\n0.00000000\n0.00001042\n\n\n\n\n\n\n\n\n\n\nMixedModels.likelihoodratiotest(m_zcp_1_PC_2, m_cpx_1_PC_2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + zerocorr(1 + Test | Child)\n26\n13326\n\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + (1 + Test | Child)\n36\n13358\n-32\n10\nNaN"
  },
  {
    "objectID": "contrasts_fggk21.html#other-topics",
    "href": "contrasts_fggk21.html#other-topics",
    "title": "Mixed Models Tutorial: Contrast Coding",
    "section": "3. Other topics",
    "text": "3. Other topics\n\n3.1 Contrasts are re-parameterizations of the same model\nThe choice of contrast does not affect the model objective, in other words, they all yield the same goodness of fit. It does not matter whether a contrast is orthogonal or not.\n\n[\n  objective(m_ovi_SeqDiff),\n  objective(m_ovi_Helmert),\n  objective(m_ovi_Hypo),\n]\n\n3-element Vector{Float64}:\n 13842.766095600226\n 13842.766095600227\n 13842.766095600227\n\n\n\n\n3.2 VCs and CPs depend on contrast coding\nTrivially, the meaning of a contrast depends on its definition. Consequently, the contrast specification has a big effect on the random-effect structure. As an illustration, we refit the LMMs with variance components (VCs) and correlation parameters (CPs) for Child-related contrasts of Test. Unfortunately, it is not easy, actually rather quite difficult, to grasp the meaning of correlations of contrast-based effects; they represent two-way interactions.\n\nbegin\n  f_Child = @formula zScore ~\n    1 + Test * a1 * Sex + (1 + Test | Child)\n  m_Child_SDC = fit(MixedModel, f_Child, dat; contrasts=contr1)\n  m_Child_HeC = fit(MixedModel, f_Child, dat; contrasts=contr2)\n  m_Child_HyC = fit(MixedModel, f_Child, dat; contrasts=contr3)\n  m_Child_PCA = fit(MixedModel, f_Child, dat; contrasts=contr4)\nend\n\nMinimizing 1696      Time: 0:00:06 ( 3.96 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0122\n0.0141\n-0.87\n0.3855\n0.6734\n\n\nTest: c5.1\n-0.0333\n0.0432\n-0.77\n0.4410\n1.4119\n\n\nTest: c234.15\n0.0607\n0.1688\n0.36\n0.7191\n1.0799\n\n\nTest: c2.34\n0.0064\n0.0769\n0.08\n0.9340\n1.2841\n\n\nTest: c3.4\n0.0023\n0.0448\n0.05\n0.9583\n1.4905\n\n\na1\n0.2506\n0.0483\n5.18\n&lt;1e-06\n\n\n\nSex: Boys\n0.2021\n0.0141\n14.35\n&lt;1e-45\n\n\n\nTest: c5.1 & a1\n0.6479\n0.1474\n4.40\n&lt;1e-04\n\n\n\nTest: c234.15 & a1\n-1.0039\n0.5787\n-1.73\n0.0828\n\n\n\nTest: c2.34 & a1\n0.2316\n0.2669\n0.87\n0.3856\n\n\n\nTest: c3.4 & a1\n-0.0161\n0.1536\n-0.10\n0.9167\n\n\n\nTest: c5.1 & Sex: Boys\n0.0499\n0.0432\n1.15\n0.2484\n\n\n\nTest: c234.15 & Sex: Boys\n-0.7252\n0.1688\n-4.30\n&lt;1e-04\n\n\n\nTest: c2.34 & Sex: Boys\n-0.1339\n0.0769\n-1.74\n0.0818\n\n\n\nTest: c3.4 & Sex: Boys\n0.0088\n0.0448\n0.20\n0.8444\n\n\n\na1 & Sex: Boys\n-0.0496\n0.0483\n-1.02\n0.3054\n\n\n\nTest: c5.1 & a1 & Sex: Boys\n0.0721\n0.1474\n0.49\n0.6250\n\n\n\nTest: c234.15 & a1 & Sex: Boys\n-0.7707\n0.5787\n-1.33\n0.1829\n\n\n\nTest: c2.34 & a1 & Sex: Boys\n-0.1682\n0.2669\n-0.63\n0.5285\n\n\n\nTest: c3.4 & a1 & Sex: Boys\n0.0119\n0.1536\n0.08\n0.9381\n\n\n\nResidual\n0.0000\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_Child_SDC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\nChild\n(Intercept)\n0.49505896\n0.70360426\n\n\n\n\n\n\n\nTest: Star_r\n0.75535191\n0.86910984\n+0.20\n\n\n\n\n\n\nTest: S20_r\n0.65106799\n0.80688784\n-0.12\n+0.00\n\n\n\n\n\nTest: SLJ\n0.48125969\n0.69372883\n+0.08\n-0.75\n+0.02\n\n\n\n\nTest: BPT\n1.25976895\n1.12239429\n-0.28\n+0.22\n-0.71\n+0.01\n\n\nResidual\n\n0.00000000\n0.00004273\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_Child_HeC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\nChild\n(Intercept)\n0.43649703\n0.66067922\n\n\n\n\n\n\n\nTest: Star_r\n0.20409201\n0.45176544\n+0.15\n\n\n\n\n\n\nTest: S20_r\n0.05827214\n0.24139622\n+0.05\n-0.08\n\n\n\n\n\nTest: SLJ\n0.03995357\n0.19988388\n-0.27\n+0.13\n+0.14\n\n\n\n\nTest: BPT\n0.06337337\n0.25174067\n-0.44\n+0.24\n-0.12\n-0.59\n\n\nResidual\n\n0.00000001\n0.00007338\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_Child_HyC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\nChild\n(Intercept)\n0.53076940\n0.72853922\n\n\n\n\n\n\n\nTest: BPT-other\n0.98100210\n0.99045550\n+1.00\n\n\n\n\n\n\nTest: Star-End\n0.75612081\n0.86955208\n+0.21\n+0.19\n\n\n\n\n\nTest: S20-Star\n1.26638622\n1.12533827\n-0.01\n-0.01\n-0.12\n\n\n\n\nTest: SLJ-S20\n0.65758037\n0.81091329\n-0.12\n-0.12\n-0.14\n-0.15\n\n\nResidual\n\n0.00000000\n0.00004519\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_Child_PCA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\nChild\n(Intercept)\n0.45350800\n0.67343002\n\n\n\n\n\n\n\nTest: c5.1\n1.99346620\n1.41190163\n-0.20\n\n\n\n\n\n\nTest: c234.15\n1.16611374\n1.07986747\n+0.48\n-0.88\n\n\n\n\n\nTest: c2.34\n1.64888504\n1.28408919\n+0.54\n+0.33\n-0.35\n\n\n\n\nTest: c3.4\n2.22155769\n1.49048908\n-0.03\n+0.02\n+0.02\n-0.11\n\n\nResidual\n\n0.00000000\n0.00001425\n\n\n\n\n\n\n\n\n\nThe CPs for the various contrasts are in line with expectations. For the SDC we observe substantial negative CPs between neighboring contrasts. For the orthogonal HeC, all CPs are small; they are uncorrelated. HyC contains some of the SDC contrasts and we observe again the negative CPs. The (roughly) PCA-based contrasts are small with one exception; there is a sizeable CP of +.41 between GM and the core of adjusted physical fitness (c234.15).\nDo these differences in CPs imply that we can move to zcpLMMs when we have orthogonal contrasts? We pursue this question with by refitting the four LMMs with zerocorr() and compare the goodness of fit.\n\nbegin\n  f_Child0 = @formula zScore ~\n    1 + Test * a1 * Sex + zerocorr(1 + Test | Child)\n  m_Child_SDC0 = fit(MixedModel, f_Child0, dat; contrasts=contr1)\n  m_Child_HeC0 = fit(MixedModel, f_Child0, dat; contrasts=contr2)\n  m_Child_HyC0 = fit(MixedModel, f_Child0, dat; contrasts=contr3)\n  m_Child_PCA0 = fit(MixedModel, f_Child0, dat; contrasts=contr4)\nend\n\nMinimizing 875   Time: 0:00:02 ( 2.98 ms/it)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_Child\n\n\n\n\n(Intercept)\n-0.0121\n0.0141\n-0.86\n0.3892\n0.7149\n\n\nTest: c5.1\n-0.0311\n0.0436\n-0.71\n0.4754\n1.2617\n\n\nTest: c234.15\n0.0421\n0.1691\n0.25\n0.8034\n0.8000\n\n\nTest: c2.34\n0.0040\n0.0764\n0.05\n0.9578\n1.9649\n\n\nTest: c3.4\n0.0030\n0.0445\n0.07\n0.9458\n1.1575\n\n\na1\n0.2502\n0.0484\n5.17\n&lt;1e-06\n\n\n\nSex: Boys\n0.2021\n0.0141\n14.33\n&lt;1e-45\n\n\n\nTest: c5.1 & a1\n0.6648\n0.1490\n4.46\n&lt;1e-05\n\n\n\nTest: c234.15 & a1\n-1.0173\n0.5796\n-1.76\n0.0792\n\n\n\nTest: c2.34 & a1\n0.2645\n0.2649\n1.00\n0.3180\n\n\n\nTest: c3.4 & a1\n-0.0175\n0.1526\n-0.11\n0.9088\n\n\n\nTest: c5.1 & Sex: Boys\n0.0546\n0.0436\n1.25\n0.2106\n\n\n\nTest: c234.15 & Sex: Boys\n-0.7345\n0.1691\n-4.34\n&lt;1e-04\n\n\n\nTest: c2.34 & Sex: Boys\n-0.1252\n0.0764\n-1.64\n0.1014\n\n\n\nTest: c3.4 & Sex: Boys\n0.0119\n0.0445\n0.27\n0.7899\n\n\n\na1 & Sex: Boys\n-0.0529\n0.0484\n-1.09\n0.2746\n\n\n\nTest: c5.1 & a1 & Sex: Boys\n0.0613\n0.1490\n0.41\n0.6807\n\n\n\nTest: c234.15 & a1 & Sex: Boys\n-0.7802\n0.5796\n-1.35\n0.1783\n\n\n\nTest: c2.34 & a1 & Sex: Boys\n-0.2048\n0.2649\n-0.77\n0.4393\n\n\n\nTest: c3.4 & a1 & Sex: Boys\n-0.0093\n0.1526\n-0.06\n0.9512\n\n\n\nResidual\n0.0000\n\n\n\n\n\n\n\n\n\n\nMixedModels.likelihoodratiotest(m_Child_SDC0, m_Child_SDC)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + zerocorr(1 + Test | Child)\n26\n13841\n\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + (1 + Test | Child)\n36\n13387\n453\n10\n&lt;1e-90\n\n\n\n\n\n\nMixedModels.likelihoodratiotest(m_Child_HeC0, m_Child_HeC)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + zerocorr(1 + Test | Child)\n26\n13289\n\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + (1 + Test | Child)\n36\n13407\n-118\n10\nNaN\n\n\n\n\n\n\nMixedModels.likelihoodratiotest(m_Child_HyC0, m_Child_HyC)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + zerocorr(1 + Test | Child)\n26\n13329\n\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + (1 + Test | Child)\n36\n13419\n-90\n10\nNaN\n\n\n\n\n\n\nMixedModels.likelihoodratiotest(m_Child_PCA0, m_Child_PCA)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel-dof\ndeviance\nχ²\nχ²-dof\nP(&gt;χ²)\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + zerocorr(1 + Test | Child)\n26\n13235\n\n\n\n\n\nzScore ~ 1 + Test + a1 + Sex + Test & a1 + Test & Sex + a1 & Sex + Test & a1 & Sex + (1 + Test | Child)\n36\n13340\n-105\n10\nNaN\n\n\n\n\n\nObviously, we can not drop CPs from any of the LMMs. The full LMMs all have the same objective, but we can compare the goodness-of-fit statistics of zcpLMMs more directly.\n\nbegin\n  zcpLMM = [\"SDC0\", \"HeC0\", \"HyC0\", \"PCA0\"]\n  mods = [m_Child_SDC0, m_Child_HeC0, m_Child_HyC0, m_Child_PCA0]\n  gof_summary = sort!(\n    DataFrame(;\n      zcpLMM=zcpLMM,\n      dof=dof.(mods),\n      deviance=deviance.(mods),\n      AIC=aic.(mods),\n      BIC=bic.(mods),\n    ),\n    :deviance,\n  )\nend\n\n4×5 DataFrame\n\n\n\nRow\nzcpLMM\ndof\ndeviance\nAIC\nBIC\n\n\n\nString\nInt64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\nPCA0\n26\n13235.2\n13287.2\n13456.7\n\n\n2\nHeC0\n26\n13289.3\n13341.3\n13510.8\n\n\n3\nHyC0\n26\n13329.3\n13381.3\n13550.8\n\n\n4\nSDC0\n26\n13840.5\n13892.5\n14062.0\n\n\n\n\n\n\nThe best fit was obtained for the PCA-based zcpLMM. Somewhat surprisingly the second best fit was obtained for the SDC. The relatively poor performance of HeC-based zcpLMM is puzzling to me. I thought it might be related to imbalance in design in the present data, but this does not appear to be the case. The same comparison of SequentialDifferenceCoding and Helmert Coding also showed a worse fit for the zcp-HeC LMM than the zcp-SDC LMM.\n\n\n3.3 VCs and CPs depend on random factor\nVCs and CPs resulting from a set of test contrasts can also be estimated for the random factor School. Of course, these VCs and CPs may look different from the ones we just estimated for Child.\nThe effect of age (i.e., developmental gain) varies within School. Therefore, we also include its VCs and CPs in this model; the school-related VC for Sex was not significant.\n\nf_School = @formula zScore ~\n  1 + Test * a1 * Sex + (1 + Test + a1 | School);\nm_School_SeqDiff = fit(MixedModel, f_School, dat; contrasts=contr1);\nm_School_Helmert = fit(MixedModel, f_School, dat; contrasts=contr2);\nm_School_Hypo = fit(MixedModel, f_School, dat; contrasts=contr3);\nm_School_PCA = fit(MixedModel, f_School, dat; contrasts=contr4);\n\nMinimizing 1168      Time: 0:00:00 ( 0.50 ms/it)\n  objective:  13782.325630527974\n\n\n\nVarCorr(m_School_SeqDiff)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\n\nSchool\n(Intercept)\n0.045100\n0.212368\n\n\n\n\n\n\n\n\nTest: Star_r\n0.155381\n0.394184\n+0.06\n\n\n\n\n\n\n\nTest: S20_r\n0.142465\n0.377445\n+0.05\n-0.56\n\n\n\n\n\n\nTest: SLJ\n0.108642\n0.329609\n+0.02\n-0.35\n-0.37\n\n\n\n\n\nTest: BPT\n0.116985\n0.342030\n-0.54\n+0.54\n+0.02\n-0.50\n\n\n\n\na1\n0.034445\n0.185594\n+0.84\n-0.21\n+0.26\n-0.22\n-0.51\n\n\nResidual\n\n0.835792\n0.914217\n\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_School_Helmert)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\n\nSchool\n(Intercept)\n0.0451176\n0.2124090\n\n\n\n\n\n\n\n\nTest: Star_r\n0.0388082\n0.1969980\n+0.07\n\n\n\n\n\n\n\nTest: S20_r\n0.0107716\n0.1037862\n+0.11\n-0.04\n\n\n\n\n\n\nTest: SLJ\n0.0038469\n0.0620231\n+0.11\n-0.50\n-0.03\n\n\n\n\n\nTest: BPT\n0.0042597\n0.0652662\n-0.50\n+0.26\n+0.36\n+0.17\n\n\n\n\na1\n0.0345119\n0.1857738\n+0.84\n-0.21\n+0.18\n-0.16\n-0.60\n\n\nResidual\n\n0.8354849\n0.9140486\n\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_School_Hypo)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\n\nSchool\n(Intercept)\n0.045131\n0.212441\n\n\n\n\n\n\n\n\nTest: BPT-other\n1.704103\n1.305413\n-0.50\n\n\n\n\n\n\n\nTest: Star-End\n0.155474\n0.394302\n+0.07\n+0.26\n\n\n\n\n\n\nTest: S20-Star\n0.140733\n0.375143\n+0.05\n+0.16\n-0.56\n\n\n\n\n\nTest: SLJ-S20\n0.107836\n0.328384\n+0.01\n-0.10\n-0.35\n-0.36\n\n\n\n\na1\n0.034550\n0.185876\n+0.84\n-0.60\n-0.21\n+0.26\n-0.23\n\n\nResidual\n\n0.835462\n0.914036\n\n\n\n\n\n\n\n\n\n\n\nVarCorr(m_School_PCA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nVariance\nStd.Dev\nCorr.\n\n\n\n\n\n\n\n\nSchool\n(Intercept)\n0.045122\n0.212418\n\n\n\n\n\n\n\n\nTest: c5.1\n0.210696\n0.459017\n-0.29\n\n\n\n\n\n\n\nTest: c234.15\n0.966730\n0.983224\n+0.66\n-0.13\n\n\n\n\n\n\nTest: c2.34\n0.492938\n0.702095\n-0.06\n+0.02\n+0.37\n\n\n\n\n\nTest: c3.4\n0.107821\n0.328361\n-0.01\n+0.26\n+0.36\n+0.08\n\n\n\n\na1\n0.034612\n0.186044\n+0.84\n-0.50\n+0.42\n-0.17\n+0.23\n\n\nResidual\n\n0.835471\n0.914041\n\n\n\n\n\n\n\n\n\n\nWe compare again how much of the fit resides in the CPs.\n\nbegin\n  f_School0 = @formula zScore ~\n    1 + Test * a1 * Sex + zerocorr(1 + Test + a1 | School)\n  m_School_SDC0 = fit(MixedModel, f_School0, dat; contrasts=contr1)\n  m_School_HeC0 = fit(MixedModel, f_School0, dat; contrasts=contr2)\n  m_School_HyC0 = fit(MixedModel, f_School0, dat; contrasts=contr3)\n  m_School_PCA0 = fit(MixedModel, f_School0, dat; contrasts=contr4)\n  #\n  zcpLMM2 = [\"SDC0\", \"HeC0\", \"HyC0\", \"PCA0\"]\n  mods2 = [\n    m_School_SDC0, m_School_HeC0, m_School_HyC0, m_School_PCA0\n  ]\n  gof_summary2 = sort!(\n    DataFrame(;\n      zcpLMM=zcpLMM2,\n      dof=dof.(mods2),\n      deviance=deviance.(mods2),\n      AIC=aic.(mods2),\n      BIC=bic.(mods2),\n    ),\n    :deviance,\n  )\nend\n\n4×5 DataFrame\n\n\n\nRow\nzcpLMM\ndof\ndeviance\nAIC\nBIC\n\n\n\nString\nInt64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\nPCA0\n27\n13800.4\n13854.4\n14030.3\n\n\n2\nHeC0\n27\n13803.3\n13857.3\n14033.2\n\n\n3\nSDC0\n27\n13812.0\n13866.0\n14042.0\n\n\n4\nHyC0\n27\n13813.0\n13867.0\n14043.0\n\n\n\n\n\n\nFor the random factor School the Helmert contrast, followed by PCA-based contrasts have least information in the CPs; SDC has the largest contribution from CPs. Interesting."
  },
  {
    "objectID": "contrasts_fggk21.html#thats-it",
    "href": "contrasts_fggk21.html#thats-it",
    "title": "Mixed Models Tutorial: Contrast Coding",
    "section": "5. That’s it",
    "text": "5. That’s it\nThat’s it for this tutorial. It is time to try your own contrast coding. You can use these data; there are many alternatives to set up hypotheses for the five tests. Of course and even better, code up some contrasts for data of your own.\nHave fun!"
  }
]